{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennethEnevoldsen/DaCy/blob/master/docs/tutorials/hate-speech.ipynb)\n",
    "\n",
    "[Hate speech] in text is often defined text that expresses hate or encourages violence towards a person or group based on\n",
    "something such as race, religion, sex, or sexual orientation.\n",
    "\n",
    "DaCy currently does not include its own tools for hate-speech analysis, but incorperates existing\n",
    "state-of-the-art models for Danish. The hate-speech model used in DaCy is\n",
    "trained by [DaNLP](https://github.com/alexandrainst/danlp). It exists of two models.\n",
    "One for detecting wether a text is hate speech laden and one for classifying the type\n",
    "of hate speech.\n",
    "\n",
    "[Hate speech]: https://en.wikipedia.org/wiki/Hate_speech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Name  | Creator   | Domain   | Output Type  | Model Type | \n",
    "|:---|:-------------|:------|:------|:------|\n",
    "| `dacy/hatespeech_detection` | [DaNLP](https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/hatespeech.md)  | Facebook  | `[\"not offensive\", \"offensive\"]` | [Ælæctra](https://huggingface.co/Maltehb/aelaectra-danish-electra-small-cased) | \n",
    "| `dacy/hatespeech_classification` | [DaNLP](https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/sentiment_analysis.md#bert-tone)  | Facebook  | `[\"særlig opmærksomhed\", \"personangreb\", \"sprogbrug\", \"spam & indhold\"]` | [Danish BERT by BotXO](https://huggingface.co/Maltehb/danish-bert-botxo) | \n",
    "\n",
    "\n",
    "```{admonition} Other models for Hate Speech detection\n",
    "There exist others models for Danish hate-speech detection. We have chosen the BERT\n",
    "offensive model as it obtains a reasonable trade-off between good [performance and speed]\n",
    "and includes a classification for classifying the type of hate-speech. The other models\n",
    "includes\n",
    "\n",
    "- [A&ttack]\n",
    "- [ELECTRA Offensive]\n",
    "- [BERT HateSpeech]\n",
    "- [Guscode/DKbert-hatespeech-detection].\n",
    "```\n",
    "\n",
    "[A&ttack]: https://github.com/ogtal/A-ttack\n",
    "[ELECTRA Offensive]: https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/hatespeech.md#-electra-offensive-electra\n",
    "[BERT HateSpeech]: https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/hatespeech.md#-bert-hatespeech-bertdr\n",
    "[Guscode/DKbert-hatespeech-detection]: https://huggingface.co/Guscode/DKbert-hatespeech-detection\n",
    "\n",
    "The hate speech model used in DaCy is trained by [DaNLP](https://github.com/alexandrainst/danlp). It exists of two models. One for detecting wether a text is hate speech laden and one for classifying the type of hate speech.\n",
    "\n",
    "### Usage\n",
    "\n",
    "To add the emotion models to your pipeline simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_wrap.pipeline_component_seq_clf.SequenceClassificationTransformer at 0x16c8c2860>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"da\") # create an empty pipeline\n",
    "\n",
    "# add the hate speech models\n",
    "nlp.add_pipe(\"dacy/hatespeech_detection\")\n",
    "nlp.add_pipe(\"dacy/hatespeech_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wil set the two extensions to the Doc object, `is_offensive` and `hate_speech_type`.\n",
    "These shows whether a text is emotionally laden and what emotion it contains.\n",
    "\n",
    "Both of these also come with `*_prob`-suffix if you want to examine the\n",
    "probabilites of the models.\n",
    "\n",
    "Let's look at an example using the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offensive\n",
      "\t sprogbrug\n",
      "not offensive\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"senile gamle idiot\", \n",
    "    \"hej har du haft en god dag\"\n",
    "]\n",
    "\n",
    "# apply the pipeline\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    # print model predictions\n",
    "    print(doc._.is_offensive)\n",
    "    # print type of hate-speech if it is hate-speech\n",
    "    if doc._.is_offensive == \"offensive\":\n",
    "        print(\"\\t\", doc._.hate_speech_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "b40b3901be4435b5a71cc3915f22553724b83a304e297d25655c4809f01488a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
