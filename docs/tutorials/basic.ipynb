{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KennethEnevoldsen/DaCy/blob/master/docs/tutorials/basic.ipynb)\n",
    "\n",
    "DaCy is built on [SpaCy] and uses the same pipeline structure. This means that if you are familiar with SpaCy\n",
    "using DaCy should be easy. It also allows you to use other SpaCy models and components with DaCy.\n",
    "Don't worry if you are not familiar with SpaCy using DaCy is still easy.\n",
    "\n",
    "\n",
    "Before we start we assume you have installed DaCy and SpaCy if not please check out the [installation] page.\n",
    "\n",
    "To use the model you first have to download either the small, medium or large model. To see a list\n",
    "of all available models:\n",
    "\n",
    "[spacy]: https://spacy.io/\n",
    "[installation]: https://centre-for-humanities-computing.github.io/DaCy/installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da_dacy_small_trf-0.2.0\n",
      "da_dacy_medium_trf-0.2.0\n",
      "da_dacy_large_trf-0.2.0\n",
      "small\n",
      "medium\n",
      "large\n",
      "da_dacy_small_ner_fine_grained-0.1.0\n",
      "da_dacy_medium_ner_fine_grained-0.1.0\n",
      "da_dacy_large_ner_fine_grained-0.1.0\n"
     ]
    }
   ],
   "source": [
    "import dacy\n",
    "for model in dacy.models():\n",
    "    print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The name of the indicated language (`da`), framework (`dacy`), model size (e.g.\n",
    "`small`), model type (`trf`), and model version (e.g. `0.1.0`). Using a larger model\n",
    "size will increase the accuracy of the model, but also increase the memory and\n",
    "time needed to run the model.\n",
    "```\n",
    "\n",
    "From here we can now download a model using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# get the latest medium model:\n",
    "nlp = dacy.load(\"small\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which will download the model and install the model. If the model is already downloaded the model will just be loaded in. Once loaded, DaCy works exactly like any other SpaCy model.\n",
    "\n",
    "Using this we can now apply DaCy to text with conventional SpaCy syntax where we pass the text through all the components of the `nlp` pipeline.\n",
    "\n",
    "\n",
    "```{seealso}\n",
    "DaCy is built using SpaCy, hence you will be able to find a lot of the required documentation for\n",
    "using the pipeline in their very well written [documentation](https://spacy.io).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"DaCy-pakken er en hurtig og effektiv pipeline til dansk sprogprocessering.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "Named Entity Recognition (NER) is the task of identifying named entities in a text. A named entity is a “real-world object” that's assigned a name - for example, a person, a country, a product or a book title. \n",
    "DaCy can recognize organizations, persons, and location, as well as other miscellaneous entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaCy-pakken : MISC\n",
      "dansk : MISC\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity, \":\", entity.label_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot these using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DaCy-pakken\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">NIL</a>\n",
       "</span>\n",
       "</mark>\n",
       " er en hurtig og effektiv pipeline til \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dansk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q35</a>\n",
       "</span>\n",
       "</mark>\n",
       " sprogprocessering.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While at the time of its release DaCy achieved state-of-the-art performance it has since been outperformed by the [NER model](https://huggingface.co/saattrupdan/nbailab-base-ner-scandi) by Dan Nielsen. To allow users to access the best model for their use-case DaCy allows you to easily\n",
    "switch the NER component to obtain a state-of-the-art model.\n",
    "\n",
    "To do this you can simply load the model using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_wrap.pipeline_component_tok_clf.TokenClassificationTransformer at 0x1758db040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the small dacy model excluding the NER component\n",
    "nlp = dacy.load(\"small\", exclude=[\"ner\"])\n",
    "# or use an empty spacy model if you only want to do NER\n",
    "# nlp = spacy.blank(\"da\")\n",
    "\n",
    "# add the ner component from the state-of-the-art model\n",
    "nlp.add_pipe(\"dacy/ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Denne \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NER\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " model er trænet af \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " fra \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alexandra Instituttet\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Denne NER model er trænet af Dan fra Alexandra Instituttet\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Note that this will add an additonal model to your pipeline, which will slow down the inference speed.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Linking\n",
    "As you probably already saw the named entities are annotated with a unique identifier. This is because DaCy also supports named entity linking.\n",
    "\n",
    "[Named entity linking](https://en.wikipedia.org/wiki/Entity_linking) is the task of linking a named entity to a knowledge base. This is done by assigning a unique identifier to each entity. This allows us to link entities to other entities and extract information from the knowledge base. For example, we can link the entity \"Barack Obama\" to the Wikipedia or wikidata page about Barack Obama. Named entity linking is also known as named entity disambiguation, though this term could also refer to the task of distinguishing between entities with the same name without linking to a knowledge base.\n",
    "\n",
    "```{admonition} Beta feature\n",
    "Named entity linking is currently in beta and is not yet fully tested. If you find any bugs please report them on [github](https://github.com/centre-for-humanities-computing/DaCy/issues).\n",
    "We are working on expanding the knowledge-base as well as correcting the annotations, which currently annotates unknown persons using the QID for the correspondig name. For instance in the sentence *Rutechef Ivan Madsen: \"Jeg ved ikke hvorfor...* the name *Ivan Madsen* is annotated using two QID's Q830350 (Ivan, male name) and Q16876242 (Madsen, family name), which we believe is incorrect as the person is not referring to the last name *Madsen*, but rather the person with the full name *Ivan Madsen*.\n",
    "The knowledge is also currently limited and thus while the links you do obtain are often correct the model will often not be able to link all entities to the knowledge base.\n",
    "```\n",
    "\n",
    "In DaCy the `small`, `medium`, and `large` model slhave a named entity linking component. This component uses a neural entity linking to match the entity to a specifc entity in the knowledge base. The knowledge base DaCy uses is currently a combination of Danish and English Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Danmarks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q35</a>\n",
       "</span>\n",
       "</mark>\n",
       " dronning bor i \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    København\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q1748</a>\n",
       "</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danmarks : Q35\n",
      "country in Northern Europe\n",
      "nordeuropæisk land\n",
      " \n",
      "København : Q1748\n",
      "capital city of Denmark\n",
      "Danmarks hovedstad\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from wikidata.client import Client\n",
    "\n",
    "nlp = dacy.load(\"small\")\n",
    "text = \"Danmarks dronning bor i København\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style=\"ent\")\n",
    "\n",
    "\n",
    "client = Client() # start wikidata client\n",
    "for entity in doc.ents:\n",
    "    print(entity, \":\", entity.kb_id_)\n",
    "\n",
    "    # print the short description derived from wikidata\n",
    "    wikidata_entry  = client.get(entity.kb_id_, load=True)\n",
    "    print(wikidata_entry.description.get(\"en\"))\n",
    "    print(wikidata_entry.description.get(\"da\"))\n",
    "    print(\" \")\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even do more things e.g. extract the information from the knowledge base such as images, associated wikipedia article and so on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-grained NER\n",
    "\n",
    "DaCy also features models with a more fine-grained Named Entity Recognition component.\n",
    "This has been trained on the [DANSK](https://huggingface.co/datasets/chcaa/DANSK).\n",
    "This allows for the detection of 18 classes - namely the following Named Entities:\n",
    "\n",
    "|  Tag        |             Description                                         |\n",
    "| -------- | ---------------------------------------------------- |\n",
    "| PERSON   | People, including fictional                          |\n",
    "| NORP     | Nationalities or religious or political groups       |\n",
    "| FACILITY | Building, airports, highways, bridges, etc.          |\n",
    "| ORGANIZATION | Companies, agencies, institutions, etc.              |\n",
    "| GPE      | Countries, cities, states.                           |\n",
    "| LOCATION | Non-GPE locations, mountain ranges, bodies of water  |\n",
    "| PRODUCT  | Vehicles, weapons, foods, etc. (not services)        |\n",
    "| EVENT    | Named hurricanes, battles, wars, sports events, etc. |\n",
    "| WORK OF ART | Titles of books, songs, etc.                         |\n",
    "| LAW      | Named documents made into laws                       |\n",
    "| LANGUAGE | Any named language                                   |\n",
    "\n",
    "As well as annotation for the following concepts:\n",
    "\n",
    "|   Tag       |   Description                                         |\n",
    "| -------- | ------------------------------------------- |\n",
    "| DATE     | Absolute or relative dates or periods       |\n",
    "| TIME     | Times smaller than a day                    |\n",
    "| PERCENT  | Percentage (including \"*\"%)                |\n",
    "| MONEY    | Monetary values, including unit             |\n",
    "| QUANTITY | Measurements, as of weight or distance      |\n",
    "| ORDINAL  | \"first\", \"second\"                           |\n",
    "| CARDINAL | Numerals that do no fall under another type |\n",
    "\n",
    "The fine-grained NER component may be utilized in an existing pipeline in the following fashion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.ner.EntityRecognizer at 0x177f79d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the small dacy model excluding the NER component\n",
    "nlp = dacy.load(\"small\", exclude=[\"ner\"])\n",
    "\n",
    "# add the ner component from the state-of-the-art fine-grained model\n",
    "nlp.add_pipe(\"dacy/ner-fine-grained\", config={\"size\": \"small\"})\n",
    "# or if you only want to do just NER\n",
    "# nlp = dacy.load(\"da_dacy_small_ner_fine_grained-0.1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Denne model samt \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " andre blev trænet \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    d. 7. marts\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " af \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Center for Humantities Computing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " i \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Aarhus kommune\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Denne model samt 3 andre blev trænet d. 7. marts af Center for Humantities Computing i Aarhus kommune\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts-of-speech Tagging\n",
    "[Part-of-speech tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging) (POS) is the task of assigning a part of speech to each word in a text. The part of speech is the grammatical role of a word in a sentence. For example, the word “run” is a verb, and the word “book” is a noun. \n",
    "\n",
    "After tokenization, DaCy can parse and tag a given Doc. This is where the trained pipeline and its statistical models come in, which enable spaCy to make predictions of which tag or label most likely applies in this context. A trained component includes data that is produced by showing a system enough examples for it to make predictions that generalize across the language – for example, a word following “the” in English is most likely a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token POS-tag\n",
      "Denne:\t DET\n",
      "model:\t NOUN\n",
      "samt:\t CCONJ\n",
      "3:\t NUM\n",
      "andre:\t PRON\n",
      "blev:\t AUX\n",
      "trænet:\t VERB\n",
      "d.:\t ADV\n",
      "7.:\t ADJ\n",
      "marts:\t NOUN\n",
      "af:\t ADP\n",
      "Center:\t NOUN\n",
      "for:\t ADP\n",
      "Humantities:\t PROPN\n",
      "Computing:\t PROPN\n",
      "i:\t ADP\n",
      "Aarhus:\t PROPN\n",
      "kommune:\t NOUN\n"
     ]
    }
   ],
   "source": [
    "print(\"Token POS-tag\")\n",
    "for token in doc:\n",
    "    print(f\"{token}:\\t {token.pos_}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "For more on Part-of-speech tagging see SpaCy's [documentation](https://spacy.io/usage/linguistic-features#pos-tagging).\n",
    "````\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing\n",
    "\n",
    "[Dependency parsing](https://en.wikipedia.org/wiki/Dependency_grammar) is the task of assigning syntactic dependencies between tokens, i.e. identifying the head word of a phrase and the relation between the head and the word. For example, in the sentence “The quick brown fox jumps over the lazy dog”, the word “jumps” is the head of the phrase “quick brown fox”, and the relation between them is “nsubj” (nominal subject).\n",
    "\n",
    "DaCy features a fast and accurate syntactic dependency parser. In DaCy this dependency parsing is also\n",
    "used for sentence segmentation and detecting noun chunks.\n",
    "\n",
    "You can see the dependency tree using:\n",
    "\n",
    "```{seealso}\n",
    "For more on Dependency parsing see SpaCy's [documentation](https://spacy.io/usage/linguistic-features#dependency-parse).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"da\" id=\"66d5b791ef05478889e96bb1fb3441cb-0\" class=\"displacy\" width=\"1450\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">DaCy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">er</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">en</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">effektiv</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">pipeline</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">til</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">dansk</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">fritekst.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 750.0,2.0 750.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-66d5b791ef05478889e96bb1fb3441cb-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-66d5b791ef05478889e96bb1fb3441cb-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"DaCy er en effektiv pipeline til dansk fritekst.\")\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Segmentation\n",
    "Sentence segmentation is the task of splitting a text into sentences. In DaCy this is done using the dependency parser. This makes it very accurate and allows for the detection of sentences that are not separated by a punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sætnings segmentering er en vigtig del af sprogprocessering\n",
      "- Det kan bl.a. benyttes til at opdele lange tekster i mindre bidder uden at miste meningen i hvert sætning.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Sætnings segmentering er en vigtig del af sprogprocessering - Det kan bl.a. benyttes til at opdele lange tekster i mindre bidder uden at miste meningen i hvert sætning.\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noun Chunks\n",
    "[Noun chunks](https://en.wikipedia.org/wiki/Noun_phrase) are \"base noun phrases\" – flat phrases that have a noun as their head. For example, \"the big yellow taxi\" and \"the quick brown fox\" are noun chunks. Noun chunks are \"noun-like\" words, such as a noun, a pronoun, a proper noun, or a noun phrase, that function as the head of a noun phrase.\n",
    "\n",
    "Noun chunks are for example used for information extraction, and for finding subjects and objects of verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaCy\n",
      "en hurtig og effektiv pipeline\n",
      "dansk sprogprocessering\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"DaCy er en hurtig og effektiv pipeline til dansk sprogprocessering.\")\n",
    "\n",
    "for nc in doc.noun_chunks:\n",
    "    print(nc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Lemmatization](https://en.wikipedia.org/wiki/Lemmatisation) is the task of grouping together the inflected forms of a word so they can be analysed as a single item. For example, the verb “to run” has the base form “run”, and the verb “ran” has the base form “run”.\n",
    "\n",
    "Lemmatization is for example used for text normalization before training a machine learning model to reduce the number of unique tokens in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisering Normalisering\n",
      "af af\n",
      "tekst tekst\n",
      "kan kunne\n",
      "være være\n",
      "en en\n",
      "god god\n",
      "idé idé\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Normalisering af tekst kan være en god idé.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.lemma_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Resolution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Coreference resolution](https://en.wikipedia.org/wiki/Coreference) is the task of finding all expressions that refer to the same entity in a text. For example, in the sentence “The dog chased the ball because it was shiny”, “it” is referring to the “ball”.\n",
    "\n",
    "\n",
    "Coreference resolution is for example used for question answering, summarization, conversational agents/chatbots and information extraction where such resolved references can lead to a better semantic representation.\n",
    "\n",
    "```{admonition} Beta feature\n",
    "Coreference resolution is currently an experimental feature from spaCy. This is thus only a beta feature in DaCy. We are currently working on improving the performance of the model.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreference clusters:\n",
      "{'coref_clusters_1': [minkavler Henning Christensen, han, han, hans]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Den 4. november 2020 fik minkavler Henning Christensen og hele familien et chok. Efter et pressemøde, fik han at vide at alle mink i Danmark skulle aflives. Dermed fik han fjernet hans livsgrundlag\"\n",
    "doc = nlp(text)\n",
    "print(\"Coreference clusters:\")\n",
    "print(doc.spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "b40b3901be4435b5a71cc3915f22553724b83a304e297d25655c4809f01488a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
