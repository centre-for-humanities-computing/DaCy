{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "\n",
    "This page examines the performance of competing models for Danish named entity recognition over multiple datasets. Performance is not limited to \n",
    "accuracy, but also includes domain generalization, biases and robustness. This page is also a notebook, which can be opened and run to replicate the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-Art comparison\n",
    "To our knowledge there exists three datasets for Danish named entity recognition;\n",
    "\n",
    "1) DaNE {cite}`hvingelby2020dane`, which uses the simple annotation scheme of CoNLL 2003 {cite}`sang2003introduction` with the entities; *person*, *location*, *organization*, and *miscellaneus*.\n",
    "2) [DANSK](https://huggingface.co/datasets/chcaa/DANSK), which uses the extensive annotation scheme similar to that of OntoNotes 5.0 {cite}`weischedel2013ontonotes` including more that 16 entity types.\n",
    "3) and DAN+ {cite}`plank2021dan+`, which also uses the annotation scheme of CoNLL 2003, but allows for nested entities for instance *Aarhus Universitet*, where *Aarhus* is a location and *Aarhus Universitet* is an organization.\n",
    "\n",
    "In this comparison we will be examing performance on DaNE and DANSK, but as no known models have been trained on Danish nested entities, we will not be comparing performance on DAN+.\n",
    "\n",
    "\n",
    "```{admonition} Measuring Performance\n",
    "Typically when measuring performance on these benchmark it is normal to feed the model the gold standard tokens. While this allows for easier comparisons of modules and architectures, it inflates the performance metrics. Further, it does not proberly reflect what you are really interested in:\n",
    "*the performance you can expect when you apply the model to data of a similar type*. Therefore we estimate the model is given no prior knowledge of the data, and only the raw text is fed to the model. Thus the performance metrics might be slightly different compared to e.g. DaNLP.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DaNE: Simple Named Entity Recognition\n",
    "As already stated DaNE uses an extraction from the CoNLL 2003 dataset, which is as follows {cite}`hvingelby2020dane`:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Entity | Description |\n",
    "|--------------|-------------|\n",
    "| LOC          | includes locations like cities, roads and mountains, as well as both public and commercial places like specific buildings or meeting points, but also abstract places. |\n",
    "| PERSON | consists of names of people, fictional characters, and animals. The names includes aliases. |\n",
    "| ORG | can be summarized as all sorts of organizations and collections of people, ranging from companies, brands, political movements, governmental bodies and clubs. |\n",
    "| MISC | is a broad category of e.g. events, languages, titles and religions, but this tag also includes words derived from one of the four tags as well as words for which one part is from one of the three other tags. |\n",
    "\n",
    "Here is an example from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"\"\"To kendte russiske historikere Andronik Mirganjan og Igor Klamkin tror ikke, at Rusland kan udvikles uden en \"jernnæve\".\"\"\"\n",
    "nlp = spacy.blank(\"da\")\n",
    "doc = nlp(text)\n",
    "doc.ents = [  # type: ignore\n",
    "    Span(doc, 2, 3, label=\"MISC\"),\n",
    "    Span(doc, 4, 6, label=\"PERSON\"),\n",
    "    Span(doc, 7, 9, label=\"PERSON\"),\n",
    "    Span(doc, 13, 14, label=\"LOC\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">To kendte \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    russiske\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " historikere \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Andronik Mirganjan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " og \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Igor Klamkin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " tror ikke, at \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rusland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " kan udvikles uden en &quot;jernnæve&quot;.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the performance of Danish language processing pipelines scored on the DaNE test set. The best scores in each category are highlighted with bold and the second best is underlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from evaluation.models import MODELS\n",
    "from evaluation.utils import apply_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dane (test): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "dane (test): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "dane (test): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "dane (test): Loading prediction for da_dacy_large_ner_fine_grained-0.1.0\n",
      "dane (test): Loading prediction for da_dacy_medium_ner_fine_grained-0.1.0\n",
      "dane (test): Loading prediction for da_dacy_small_ner_fine_grained-0.1.0\n",
      "dane (test): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "dane (test): Loading prediction for alexandrainst/da-ner-base\n",
      "dane (test): Loading prediction for da_core_news_trf-3.5.0\n",
      "dane (test): Loading prediction for da_core_news_lg-3.5.0\n",
      "dane (test): Loading prediction for da_core_news_md-3.5.0\n",
      "dane (test): Loading prediction for da_core_news_sm-3.5.0\n",
      "dane (test): Loading prediction for openai/gpt-3.5-turbo (02/05/23)\n",
      "dane (test): Running openai/gpt-4 (02/05/23)\n"
     ]
    }
   ],
   "source": [
    "dane = {}\n",
    "for mdl_name, model_getter in MODELS.items():\n",
    "    mdl_results = apply_models(mdl_name, model_getter, dataset=\"dane\", splits=[\"test\"])\n",
    "    dane[mdl_name] = mdl_results[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# normalize labels to match the dataset\n",
    "for mdl in dane:\n",
    "    if \"openai\" not in mdl:\n",
    "        continue\n",
    "    examples = dane[mdl][\"examples\"]\n",
    "    mapping = {\n",
    "        \"PERSON\": \"PER\",\n",
    "        \"ORGANISATION\": \"ORG\",\n",
    "        \"LOCATION\": \"LOC\",\n",
    "    }\n",
    "    for e in examples:\n",
    "        ents = e.x.ents\n",
    "        for ent in ents:\n",
    "            ent.label_ = mapping[ent.label_]\n",
    "\n",
    "        e.x.ents = ents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluation.utils import create_dataframe\n",
    "\n",
    "def highlight_max(s: pd.Series) -> list:\n",
    "    \"\"\"Highlight the maximum in a Series with bold text.\"\"\"\n",
    "    # convert to str for comparison\n",
    "    s = s.astype(str)\n",
    "    is_max = s == s.max()\n",
    "    return [\"font-weight: bold\" if v else \"\" for v in is_max]\n",
    "\n",
    "\n",
    "def underline_second_max(s: pd.Series) -> list:\n",
    "    \"\"\"Underline the second maximum in a Series.\"\"\"\n",
    "    is_second_max = s == s.sort_values(ascending=False).iloc[1]\n",
    "    return [\"text-decoration: underline\" if v else \"\" for v in is_second_max]\n",
    "\n",
    "\n",
    "def create_table(\n",
    "    df: pd.DataFrame,\n",
    "    caption=\"F1 score with 95% confidence interval calculated using bootstrapping with 100 samples.\",\n",
    "):\n",
    "    # replace index with range\n",
    "    df.index = range(len(df))  # type: ignore\n",
    "\n",
    "    col_names = [(\"\", \"Models\")] + [(\"F1\", col) for col in df.columns[1:]]\n",
    "    super_header = pd.MultiIndex.from_tuples(col_names)\n",
    "    df.columns = super_header\n",
    "\n",
    "    s = df.style.apply(highlight_max, axis=0, subset=df.columns[1:])\n",
    "    s = s.apply(underline_second_max, axis=0, subset=df.columns[1:])\n",
    "\n",
    "    # Add a caption\n",
    "    s = s.set_caption(caption)\n",
    "\n",
    "    # Center the header and left align the model names\n",
    "    s = s.set_properties(subset=df.columns[1:], **{\"text-align\": \"right\"})\n",
    "\n",
    "    super_header_style = [\n",
    "        {\"selector\": \".level0\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        {\"selector\": \".col_heading\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    ]\n",
    "    # Apply the CSS style to the styler\n",
    "    s = s.set_table_styles(super_header_style)  # type: ignore\n",
    "    s = s.set_properties(subset=[(\"\", \"Models\")], **{\"text-align\": \"left\"})\n",
    "    # remove the index\n",
    "    s = s.hide(axis=\"index\")\n",
    "\n",
    "    # smaller font size\n",
    "    s = s.set_table_attributes('style=\"font-size: 0.65em\"')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "with Pool(8) as p:\n",
    "    tables = p.starmap(\n",
    "        create_dataframe,\n",
    "        [(dane[mdl][\"examples\"], mdl, 1, 500) for mdl in dane if \"fine_grained\" not in mdl],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f48d8 .level0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f48d8 .col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f48d8_row0_col0, #T_f48d8_row1_col0, #T_f48d8_row2_col0, #T_f48d8_row3_col0, #T_f48d8_row4_col0, #T_f48d8_row5_col0, #T_f48d8_row6_col0, #T_f48d8_row7_col0, #T_f48d8_row8_col0, #T_f48d8_row9_col0, #T_f48d8_row10_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f48d8_row0_col1, #T_f48d8_row0_col4, #T_f48d8_row1_col3, #T_f48d8_row1_col5, #T_f48d8_row3_col2 {\n",
       "  text-decoration: underline;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_f48d8_row0_col2, #T_f48d8_row0_col5, #T_f48d8_row3_col1, #T_f48d8_row3_col3, #T_f48d8_row3_col4 {\n",
       "  font-weight: bold;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_f48d8_row0_col3, #T_f48d8_row1_col1, #T_f48d8_row1_col2, #T_f48d8_row1_col4, #T_f48d8_row2_col1, #T_f48d8_row2_col2, #T_f48d8_row2_col3, #T_f48d8_row2_col4, #T_f48d8_row2_col5, #T_f48d8_row3_col5, #T_f48d8_row4_col1, #T_f48d8_row4_col2, #T_f48d8_row4_col3, #T_f48d8_row4_col4, #T_f48d8_row4_col5, #T_f48d8_row5_col1, #T_f48d8_row5_col2, #T_f48d8_row5_col3, #T_f48d8_row5_col4, #T_f48d8_row5_col5, #T_f48d8_row6_col1, #T_f48d8_row6_col2, #T_f48d8_row6_col3, #T_f48d8_row6_col4, #T_f48d8_row6_col5, #T_f48d8_row7_col1, #T_f48d8_row7_col2, #T_f48d8_row7_col3, #T_f48d8_row7_col4, #T_f48d8_row7_col5, #T_f48d8_row8_col1, #T_f48d8_row8_col2, #T_f48d8_row8_col3, #T_f48d8_row8_col4, #T_f48d8_row8_col5, #T_f48d8_row9_col1, #T_f48d8_row9_col2, #T_f48d8_row9_col3, #T_f48d8_row9_col4, #T_f48d8_row9_col5, #T_f48d8_row10_col1, #T_f48d8_row10_col2, #T_f48d8_row10_col3, #T_f48d8_row10_col4, #T_f48d8_row10_col5 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f48d8\" style=\"font-size: 0.65em\">\n",
       "  <caption>F1 score with 95% confidence interval calculated using bootstrapping with 500 samples.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f48d8_level0_col0\" class=\"col_heading level0 col0\" ></th>\n",
       "      <th id=\"T_f48d8_level0_col1\" class=\"col_heading level0 col1\" colspan=\"5\">F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f48d8_level1_col0\" class=\"col_heading level1 col0\" >Models</th>\n",
       "      <th id=\"T_f48d8_level1_col1\" class=\"col_heading level1 col1\" >Average</th>\n",
       "      <th id=\"T_f48d8_level1_col2\" class=\"col_heading level1 col2\" >Location</th>\n",
       "      <th id=\"T_f48d8_level1_col3\" class=\"col_heading level1 col3\" >Person</th>\n",
       "      <th id=\"T_f48d8_level1_col4\" class=\"col_heading level1 col4\" >Organization</th>\n",
       "      <th id=\"T_f48d8_level1_col5\" class=\"col_heading level1 col5\" >Misc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row0_col0\" class=\"data row0 col0\" >da_dacy_large_trf-0.2.0</td>\n",
       "      <td id=\"T_f48d8_row0_col1\" class=\"data row0 col1\" >85.4 (81.2, 88.9)</td>\n",
       "      <td id=\"T_f48d8_row0_col2\" class=\"data row0 col2\" >89.5 (84.0, 94.7)</td>\n",
       "      <td id=\"T_f48d8_row0_col3\" class=\"data row0 col3\" >92.6 (89.0, 95.4)</td>\n",
       "      <td id=\"T_f48d8_row0_col4\" class=\"data row0 col4\" >79.0 (72.5, 84.6)</td>\n",
       "      <td id=\"T_f48d8_row0_col5\" class=\"data row0 col5\" >79.0 (70.8, 86.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row1_col0\" class=\"data row1 col0\" >da_dacy_medium_trf-0.2.0</td>\n",
       "      <td id=\"T_f48d8_row1_col1\" class=\"data row1 col1\" >84.9 (81.0, 88.5)</td>\n",
       "      <td id=\"T_f48d8_row1_col2\" class=\"data row1 col2\" >86.8 (81.2, 92.3)</td>\n",
       "      <td id=\"T_f48d8_row1_col3\" class=\"data row1 col3\" >92.7 (89.2, 95.6)</td>\n",
       "      <td id=\"T_f48d8_row1_col4\" class=\"data row1 col4\" >78.7 (71.8, 85.0)</td>\n",
       "      <td id=\"T_f48d8_row1_col5\" class=\"data row1 col5\" >78.7 (70.6, 86.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row2_col0\" class=\"data row2 col0\" >da_dacy_small_trf-0.2.0</td>\n",
       "      <td id=\"T_f48d8_row2_col1\" class=\"data row2 col1\" >82.7 (79.3, 85.9)</td>\n",
       "      <td id=\"T_f48d8_row2_col2\" class=\"data row2 col2\" >84.2 (78.3, 89.8)</td>\n",
       "      <td id=\"T_f48d8_row2_col3\" class=\"data row2 col3\" >92.2 (88.5, 95.1)</td>\n",
       "      <td id=\"T_f48d8_row2_col4\" class=\"data row2 col4\" >75.9 (69.3, 81.7)</td>\n",
       "      <td id=\"T_f48d8_row2_col5\" class=\"data row2 col5\" >75.7 (68.8, 81.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row3_col0\" class=\"data row3 col0\" >saattrupdan/nbailab-base-ner-scandi</td>\n",
       "      <td id=\"T_f48d8_row3_col1\" class=\"data row3 col1\" >86.3 (82.4, 89.7)</td>\n",
       "      <td id=\"T_f48d8_row3_col2\" class=\"data row3 col2\" >88.6 (83.0, 93.3)</td>\n",
       "      <td id=\"T_f48d8_row3_col3\" class=\"data row3 col3\" >95.1 (92.4, 97.8)</td>\n",
       "      <td id=\"T_f48d8_row3_col4\" class=\"data row3 col4\" >80.3 (73.6, 85.8)</td>\n",
       "      <td id=\"T_f48d8_row3_col5\" class=\"data row3 col5\" >78.6 (69.4, 86.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row4_col0\" class=\"data row4 col0\" >alexandrainst/da-ner-base</td>\n",
       "      <td id=\"T_f48d8_row4_col1\" class=\"data row4 col1\" >70.7 (66.2, 75.2)</td>\n",
       "      <td id=\"T_f48d8_row4_col2\" class=\"data row4 col2\" >84.8 (77.8, 91.0)</td>\n",
       "      <td id=\"T_f48d8_row4_col3\" class=\"data row4 col3\" >90.3 (86.3, 93.9)</td>\n",
       "      <td id=\"T_f48d8_row4_col4\" class=\"data row4 col4\" >64.7 (57.0, 71.3)</td>\n",
       "      <td id=\"T_f48d8_row4_col5\" class=\"data row4 col5\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row5_col0\" class=\"data row5 col0\" >da_core_news_trf-3.5.0</td>\n",
       "      <td id=\"T_f48d8_row5_col1\" class=\"data row5 col1\" >79.0 (75.1, 82.3)</td>\n",
       "      <td id=\"T_f48d8_row5_col2\" class=\"data row5 col2\" >82.1 (75.5, 88.5)</td>\n",
       "      <td id=\"T_f48d8_row5_col3\" class=\"data row5 col3\" >91.6 (88.2, 94.5)</td>\n",
       "      <td id=\"T_f48d8_row5_col4\" class=\"data row5 col4\" >68.0 (61.0, 75.2)</td>\n",
       "      <td id=\"T_f48d8_row5_col5\" class=\"data row5 col5\" >69.0 (61.1, 77.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row6_col0\" class=\"data row6 col0\" >da_core_news_lg-3.5.0</td>\n",
       "      <td id=\"T_f48d8_row6_col1\" class=\"data row6 col1\" >74.6 (70.8, 78.1)</td>\n",
       "      <td id=\"T_f48d8_row6_col2\" class=\"data row6 col2\" >81.6 (75.3, 88.2)</td>\n",
       "      <td id=\"T_f48d8_row6_col3\" class=\"data row6 col3\" >85.5 (81.1, 89.9)</td>\n",
       "      <td id=\"T_f48d8_row6_col4\" class=\"data row6 col4\" >62.7 (54.8, 70.3)</td>\n",
       "      <td id=\"T_f48d8_row6_col5\" class=\"data row6 col5\" >64.4 (55.9, 72.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row7_col0\" class=\"data row7 col0\" >da_core_news_md-3.5.0</td>\n",
       "      <td id=\"T_f48d8_row7_col1\" class=\"data row7 col1\" >71.2 (66.9, 75.2)</td>\n",
       "      <td id=\"T_f48d8_row7_col2\" class=\"data row7 col2\" >76.8 (69.9, 83.6)</td>\n",
       "      <td id=\"T_f48d8_row7_col3\" class=\"data row7 col3\" >82.6 (77.8, 87.0)</td>\n",
       "      <td id=\"T_f48d8_row7_col4\" class=\"data row7 col4\" >58.2 (49.6, 66.7)</td>\n",
       "      <td id=\"T_f48d8_row7_col5\" class=\"data row7 col5\" >61.8 (52.6, 70.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row8_col0\" class=\"data row8 col0\" >da_core_news_sm-3.5.0</td>\n",
       "      <td id=\"T_f48d8_row8_col1\" class=\"data row8 col1\" >64.4 (59.7, 68.5)</td>\n",
       "      <td id=\"T_f48d8_row8_col2\" class=\"data row8 col2\" >61.6 (52.2, 69.9)</td>\n",
       "      <td id=\"T_f48d8_row8_col3\" class=\"data row8 col3\" >80.1 (74.9, 85.1)</td>\n",
       "      <td id=\"T_f48d8_row8_col4\" class=\"data row8 col4\" >49.0 (39.0, 57.5)</td>\n",
       "      <td id=\"T_f48d8_row8_col5\" class=\"data row8 col5\" >58.4 (49.8, 67.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row9_col0\" class=\"data row9 col0\" >openai/gpt-3.5-turbo (02/05/23)</td>\n",
       "      <td id=\"T_f48d8_row9_col1\" class=\"data row9 col1\" >57.5 (52.3, 62.2)</td>\n",
       "      <td id=\"T_f48d8_row9_col2\" class=\"data row9 col2\" >50.7 (41.9, 59.2)</td>\n",
       "      <td id=\"T_f48d8_row9_col3\" class=\"data row9 col3\" >81.9 (76.8, 86.5)</td>\n",
       "      <td id=\"T_f48d8_row9_col4\" class=\"data row9 col4\" >55.7 (47.1, 63.7)</td>\n",
       "      <td id=\"T_f48d8_row9_col5\" class=\"data row9 col5\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f48d8_row10_col0\" class=\"data row10 col0\" >openai/gpt-4 (02/05/23)</td>\n",
       "      <td id=\"T_f48d8_row10_col1\" class=\"data row10 col1\" >70.1 (66.0, 74.3)</td>\n",
       "      <td id=\"T_f48d8_row10_col2\" class=\"data row10 col2\" >78.9 (71.5, 85.7)</td>\n",
       "      <td id=\"T_f48d8_row10_col3\" class=\"data row10 col3\" >85.3 (80.4, 89.5)</td>\n",
       "      <td id=\"T_f48d8_row10_col4\" class=\"data row10 col4\" >72.0 (65.4, 78.5)</td>\n",
       "      <td id=\"T_f48d8_row10_col5\" class=\"data row10 col5\" > </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2910f8580>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(tables)\n",
    "# sort columns\n",
    "df = df[[\"Models\", \"Average\", \"Location\", \"Person\", \"Organization\", \"Misc.\"]]\n",
    "df_average = df[\"Average\"]\n",
    "create_table(\n",
    "    df,\n",
    "    \"F1 score with 95% confidence interval calculated using bootstrapping with 500 samples.\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth mentioning that while the `da_dacy_large_trf-0.2.0` and `saattrupdan/nbailab-base-ner-scandi` performs similarly they have their independent strength and weaknesses. The large DaCy model is a multi-task model performing named-entity recognition as only one of its many tasks and thus if you wish to use one of those we would recommend that model. On the other hand the `nbailab-base-ner-scandi` is trained on multiple Scandinavian languages and thus might be ideal if your dataset might contain these languages as well. `saattrupdan/nbailab-base-ner-scandi` is available in DaCy using `nlp.add_pipe(\"dacy/ner\")`.\n",
    "\n",
    "```{admonition} You are missing a model\n",
    ":class: note\n",
    "\n",
    "These tables are continually updated and thus we try to limit the number of models to only the most relevant Danish models. Therefore models like Polyglot with strict requirements and consistently worse performance are excluded. If you want to see a specific model, please open an issue on GitHub.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DANSK: Fine-grained Named Entity Recognition\n",
    "\n",
    "DANSK is annotated from the Danish Gigaword Corpus {cite}`derczynski2021danish` and a wide variety of domains including conversational, legal, news, social media, web content,  wiki's and Books. Dansk follows includes the following labels:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|  Entity        |             Description                                         |\n",
    "| -------- | ---------------------------------------------------- |\n",
    "| PERSON   | People, including fictional                          |\n",
    "| NORP     | Nationalities or religious or political groups       |\n",
    "| FACILITY | Building, airports, highways, bridges, etc.          |\n",
    "| ORGANIZATION | Companies, agencies, institutions, etc.              |\n",
    "| GPE      | Countries, cities, states.                           |\n",
    "| LOCATION | Non-GPE locations, mountain ranges, bodies of water  |\n",
    "| PRODUCT  | Vehicles, weapons, foods, etc. (not services)        |\n",
    "| EVENT    | Named hurricanes, battles, wars, sports events, etc. |\n",
    "| WORK OF ART | Titles of books, songs, etc.                         |\n",
    "| LAW      | Named documents made into laws                       |\n",
    "| LANGUAGE | Any named language                                   |\n",
    "\n",
    "As well as annotation for the following concepts:\n",
    "\n",
    "|   Entity       |   Description                                         |\n",
    "| -------- | ------------------------------------------- |\n",
    "| DATE     | Absolute or relative dates or periods       |\n",
    "| TIME     | Times smaller than a day                    |\n",
    "| PERCENT  | Percentage (including \"*\"%)                |\n",
    "| MONEY    | Monetary values, including unit             |\n",
    "| QUANTITY | Measurements, as of weight or distance      |\n",
    "| ORDINAL  | \"first\", \"second\"                           |\n",
    "| CARDINAL | Numerals that do no fall under another type |\n",
    "\n",
    "\n",
    "We have here opted to create an interactive chart over a table as with the number of labels it quickly becomes unruly. The chart is interactive and you can select the label you want to compare the models on. You can also hover over the dots the see the exact values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from evaluation.models import openai_model_loader_fine_ner\n",
    "MODELS_ = MODELS.copy()\n",
    "MODELS_[\"openai/gpt-3.5-turbo (02/05/23)\"] = partial(openai_model_loader_fine_ner, model=\"gpt-3.5-turbo\")\n",
    "MODELS_[\"openai/gpt-4 (02/05/23)\"] = partial(openai_model_loader_fine_ner, model=\"gpt-4\")\n",
    "MODELS.pop(\"openai/gpt-3.5-turbo (02/05/23)\")\n",
    "MODELS.pop(\"openai/gpt-4 (02/05/23)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dansk (train): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "dansk (dev): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "dansk (test): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "dansk (train): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "dansk (dev): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "dansk (test): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "dansk (train): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "dansk (dev): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "dansk (test): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "dansk (train): Loading prediction for da_dacy_large_ner_fine_grained-0.1.0\n",
      "dansk (dev): Loading prediction for da_dacy_large_ner_fine_grained-0.1.0\n",
      "dansk (test): Loading prediction for da_dacy_large_ner_fine_grained-0.1.0\n",
      "dansk (train): Loading prediction for da_dacy_medium_ner_fine_grained-0.1.0\n",
      "dansk (dev): Loading prediction for da_dacy_medium_ner_fine_grained-0.1.0\n",
      "dansk (test): Loading prediction for da_dacy_medium_ner_fine_grained-0.1.0\n",
      "dansk (train): Loading prediction for da_dacy_small_ner_fine_grained-0.1.0\n",
      "dansk (dev): Loading prediction for da_dacy_small_ner_fine_grained-0.1.0\n",
      "dansk (test): Loading prediction for da_dacy_small_ner_fine_grained-0.1.0\n",
      "dansk (train): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "dansk (dev): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "dansk (test): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "dansk (train): Loading prediction for alexandrainst/da-ner-base\n",
      "dansk (dev): Loading prediction for alexandrainst/da-ner-base\n",
      "dansk (test): Loading prediction for alexandrainst/da-ner-base\n",
      "dansk (train): Loading prediction for da_core_news_trf-3.5.0\n",
      "dansk (dev): Loading prediction for da_core_news_trf-3.5.0\n",
      "dansk (test): Loading prediction for da_core_news_trf-3.5.0\n",
      "dansk (train): Loading prediction for da_core_news_lg-3.5.0\n",
      "dansk (dev): Loading prediction for da_core_news_lg-3.5.0\n",
      "dansk (test): Loading prediction for da_core_news_lg-3.5.0\n",
      "dansk (train): Loading prediction for da_core_news_md-3.5.0\n",
      "dansk (dev): Loading prediction for da_core_news_md-3.5.0\n",
      "dansk (test): Loading prediction for da_core_news_md-3.5.0\n",
      "dansk (train): Loading prediction for da_core_news_sm-3.5.0\n",
      "dansk (dev): Loading prediction for da_core_news_sm-3.5.0\n",
      "dansk (test): Loading prediction for da_core_news_sm-3.5.0\n",
      "dansk (test): Running openai/gpt-3.5-turbo (02/05/23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-8622a47955f5c4cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-8622a47955f5c4cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-8622a47955f5c4cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dansk (test): Running openai/gpt-4 (02/05/23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-8622a47955f5c4cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-8622a47955f5c4cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-8622a47955f5c4cb/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x152a0ba30>: Failed to resolve 'api.openai.com' ([Errno 8] nodename nor servname provided, or not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connection.py:200\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    201\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    202\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    203\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    204\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m LocationParseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connection.py:604\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 604\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    605\u001b[0m server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connection.py:207\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x152a0ba30>: Failed to resolve 'api.openai.com' ([Errno 8] nodename nor servname provided, or not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x152a0ba30>: Failed to resolve 'api.openai.com' ([Errno 8] nodename nor servname provided, or not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     splits\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdev\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m mdl_results \u001b[39m=\u001b[39m apply_models(\n\u001b[1;32m      8\u001b[0m     mdl_name, model_getter, dataset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdansk\u001b[39;49m\u001b[39m\"\u001b[39;49m, splits\u001b[39m=\u001b[39;49msplits\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m dansk[mdl_name] \u001b[39m=\u001b[39m mdl_results\n",
      "File \u001b[0;32m~/Github/DaCy/docs/evaluation/utils.py:177\u001b[0m, in \u001b[0;36mapply_models\u001b[0;34m(mdl_name, mdl_getter, dataset, splits, cache)\u001b[0m\n\u001b[1;32m    175\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m    176\u001b[0m docs \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mpipe(example\u001b[39m.\u001b[39mreference\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m examples)\n\u001b[0;32m--> 177\u001b[0m \u001b[39mfor\u001b[39;00m doc, example \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(docs, examples):\n\u001b[1;32m    178\u001b[0m     example\u001b[39m.\u001b[39mpredicted \u001b[39m=\u001b[39m doc\n\u001b[1;32m    179\u001b[0m end \u001b[39m=\u001b[39m time()\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy/language.py:1574\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1572\u001b[0m     \u001b[39mfor\u001b[39;00m pipe \u001b[39min\u001b[39;00m pipes:\n\u001b[1;32m   1573\u001b[0m         docs \u001b[39m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1574\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs:\n\u001b[1;32m   1575\u001b[0m     \u001b[39myield\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy/util.py:1670\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe\u001b[39m(\n\u001b[1;32m   1661\u001b[0m     docs: Iterable[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1662\u001b[0m     proc: \u001b[39m\"\u001b[39m\u001b[39mPipeCallable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1667\u001b[0m     kwargs: Mapping[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m   1668\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m\"\u001b[39m\u001b[39mDoc\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m   1669\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mpipe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1670\u001b[0m         \u001b[39myield from\u001b[39;00m proc\u001b[39m.\u001b[39mpipe(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1671\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1672\u001b[0m         \u001b[39m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m         kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/pipeline/llm.py:140\u001b[0m, in \u001b[0;36mLLMWrapper.pipe\u001b[0;34m(self, stream, batch_size)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_docs(doc_batch))\n\u001b[1;32m    139\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 140\u001b[0m     error_handler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, \u001b[39mself\u001b[39;49m, doc_batch, e)\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy/util.py:1689\u001b[0m, in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[0;32m-> 1689\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/pipeline/llm.py:138\u001b[0m, in \u001b[0;36mLLMWrapper.pipe\u001b[0;34m(self, stream, batch_size)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mfor\u001b[39;00m doc_batch \u001b[39min\u001b[39;00m spacy\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mminibatch(stream, batch_size):\n\u001b[1;32m    137\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_docs(doc_batch))\n\u001b[1;32m    139\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    140\u001b[0m         error_handler(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, \u001b[39mself\u001b[39m, doc_batch, e)\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/pipeline/llm.py:152\u001b[0m, in \u001b[0;36mLLMWrapper._process_docs\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    150\u001b[0m noncached_doc_batch \u001b[39m=\u001b[39m [doc \u001b[39mfor\u001b[39;00m i, doc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(docs) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cached[i]]\n\u001b[1;32m    151\u001b[0m prompts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task\u001b[39m.\u001b[39mgenerate_prompts(noncached_doc_batch)\n\u001b[0;32m--> 152\u001b[0m responses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend(prompts)\n\u001b[1;32m    153\u001b[0m modified_docs \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task\u001b[39m.\u001b[39mparse_responses(noncached_doc_batch, responses))\n\u001b[1;32m    154\u001b[0m final_docs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/backends/rest/backend/openai.py:140\u001b[0m, in \u001b[0;36mOpenAIBackend.__call__\u001b[0;34m(self, prompts)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m url \u001b[39m==\u001b[39m Endpoints\u001b[39m.\u001b[39mCHAT:\n\u001b[1;32m    138\u001b[0m     \u001b[39m# The OpenAI API doesn't support batching for /chat/completions yet, so we have to send individual requests.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m--> 140\u001b[0m         responses \u001b[39m=\u001b[39m _request(\n\u001b[1;32m    141\u001b[0m             {\u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: [{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}]}\n\u001b[1;32m    142\u001b[0m         )\n\u001b[1;32m    143\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m responses:\n\u001b[1;32m    144\u001b[0m             \u001b[39mreturn\u001b[39;00m responses[\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/backends/rest/backend/openai.py:111\u001b[0m, in \u001b[0;36mOpenAIBackend.__call__.<locals>._request\u001b[0;34m(json_data)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request\u001b[39m(json_data: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 111\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretry(\n\u001b[1;32m    112\u001b[0m         call_method\u001b[39m=\u001b[39;49mrequests\u001b[39m.\u001b[39;49mpost,\n\u001b[1;32m    113\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    114\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    115\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mjson_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config},\n\u001b[1;32m    116\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_request_time,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    118\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m         r\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/backends/rest/backend/base.py:121\u001b[0m, in \u001b[0;36mBackend.retry\u001b[0;34m(self, call_method, url, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_tries \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    118\u001b[0m     response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m _HTTPRetryErrorCodes\u001b[39m.\u001b[39mhas(response\u001b[39m.\u001b[39mstatus_code)\n\u001b[1;32m    119\u001b[0m ):\n\u001b[1;32m    120\u001b[0m     time\u001b[39m.\u001b[39msleep(interval)\n\u001b[0;32m--> 121\u001b[0m     response \u001b[39m=\u001b[39m _call_api(i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    123\u001b[0m     \u001b[39m# Increase timeout everytime you retry\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/spacy_llm/backends/rest/backend/base.py:101\u001b[0m, in \u001b[0;36mBackend.retry.<locals>._call_api\u001b[0;34m(attempt)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls API with given timeout.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mattempt (int): Reflects the how many-th try at reaching the API this is. If attempt < self._max_tries and\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m    the call fails, None is returned. If attempt == self._max_tries and the call fails, a TimeoutError is\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    raised.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mRETURNS (Optional[requests.Response]): Response object.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m call_method(url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    102\u001b[0m \u001b[39mexcept\u001b[39;00m (ConnectTimeout, ReadTimeout, \u001b[39mTimeoutError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m attempt \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_tries:\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.virtualenvs/dacy/lib/python3.10/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x152a0ba30>: Failed to resolve 'api.openai.com' ([Errno 8] nodename nor servname provided, or not known)\"))"
     ]
    }
   ],
   "source": [
    "dansk = {}\n",
    "for mdl_name, model_getter in MODELS_.items():\n",
    "    if \"openai\" in mdl_name:\n",
    "        splits=[\"test\"]\n",
    "    else:\n",
    "        splits=[\"train\", \"dev\", \"test\"]\n",
    "    mdl_results = apply_models(\n",
    "        mdl_name, model_getter, dataset=\"dansk\", splits=splits\n",
    "    )\n",
    "    dansk[mdl_name] = mdl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "with Pool(8) as p:\n",
    "    tables = p.starmap(\n",
    "        create_dataframe,\n",
    "        [(dansk[mdl][\"test\"][\"examples\"], mdl, 1, 100, 2000) for mdl in dansk if \"fine_grained\" in mdl],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "def create_dansk_viz(df: pd.DataFrame):\n",
    "    plot_df = df.melt(\n",
    "        id_vars=[\"Models\"],\n",
    "        var_name=\"Label\",\n",
    "        value_name=\"F1 string\",\n",
    "    )\n",
    "\n",
    "    # Convert the score value to a float\n",
    "    plot_df[\"F1\"] = plot_df[\"F1 string\"].apply(\n",
    "        lambda x: float(x.split()[0]) if not isinstance(x, float) else x\n",
    "    )\n",
    "    plot_df[\"CI Lower\"] = plot_df[\"F1 string\"].apply(\n",
    "        lambda x: float(x.split(\"(\")[1].split(\",\")[0])\n",
    "    )\n",
    "    plot_df[\"CI Upper\"] = plot_df[\"F1 string\"].apply(\n",
    "        lambda x: float(x.split(\",\")[1].split(\")\")[0])\n",
    "    )\n",
    "\n",
    "    selection = alt.selection_point(\n",
    "        fields=[\"Label\"],\n",
    "        bind=\"legend\",\n",
    "        value=[{\"Label\": \"Average\"}],\n",
    "    )\n",
    "\n",
    "    base = (\n",
    "        alt.Chart(plot_df)\n",
    "        .mark_point(filled=True, size=100)\n",
    "        .encode(\n",
    "            x=alt.X(\"F1\", title=\"F1\"),\n",
    "            y=\"Models\",\n",
    "            color=\"Label\",\n",
    "            tooltip=[\n",
    "                \"Models\",\n",
    "                \"Label\",\n",
    "                alt.Tooltip(\"F1 string\", title=\"F1\"),\n",
    "            ],\n",
    "            opacity=alt.condition(selection, alt.value(1), alt.value(0.0)),\n",
    "            # only show the tooltip when when the label is selected\n",
    "        )\n",
    "    )\n",
    "    error_bars = (\n",
    "        alt.Chart(plot_df)\n",
    "        .mark_errorbar(ticks=False)\n",
    "        .encode(\n",
    "            x=alt.X(\"CI Lower\", title=\"F1\"),\n",
    "            x2=\"CI Upper\",\n",
    "            y=\"Models\",\n",
    "            color=\"Label\",\n",
    "            opacity=alt.condition(selection, alt.value(1), alt.value(0.0)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    chart = base + error_bars\n",
    "\n",
    "    return chart.add_params(selection).properties(width=400, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a65206bbd8d8455388d4e821c2ffa6c0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a65206bbd8d8455388d4e821c2ffa6c0.vega-embed details,\n",
       "  #altair-viz-a65206bbd8d8455388d4e821c2ffa6c0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a65206bbd8d8455388d4e821c2ffa6c0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a65206bbd8d8455388d4e821c2ffa6c0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a65206bbd8d8455388d4e821c2ffa6c0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"point\", \"filled\": true, \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"Label\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_1\", \"value\": 1}, \"value\": 0.0}, \"tooltip\": [{\"field\": \"Models\", \"type\": \"nominal\"}, {\"field\": \"Label\", \"type\": \"nominal\"}, {\"field\": \"F1 string\", \"title\": \"F1\", \"type\": \"nominal\"}], \"x\": {\"field\": \"F1\", \"title\": \"F1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Models\", \"type\": \"nominal\"}}, \"name\": \"view_1\"}, {\"mark\": {\"type\": \"errorbar\", \"ticks\": false}, \"encoding\": {\"color\": {\"field\": \"Label\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_1\", \"value\": 1}, \"value\": 0.0}, \"x\": {\"field\": \"CI Lower\", \"title\": \"F1\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"CI Upper\"}, \"y\": {\"field\": \"Models\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-fb3a3f7660e577e82d7e98bc93f4bc12\"}, \"height\": 300, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"point\", \"fields\": [\"Label\"]}, \"bind\": \"legend\", \"value\": [{\"Label\": \"Average\"}], \"views\": [\"view_1\"]}], \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-fb3a3f7660e577e82d7e98bc93f4bc12\": [{\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Average\", \"F1 string\": \"80.1 (78.2, 81.9)\", \"F1\": 80.1, \"CI Lower\": 78.2, \"CI Upper\": 81.9}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Average\", \"F1 string\": \"79.7 (77.7, 81.5)\", \"F1\": 79.7, \"CI Lower\": 77.7, \"CI Upper\": 81.5}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Average\", \"F1 string\": \"78.4 (76.3, 80.4)\", \"F1\": 78.4, \"CI Lower\": 76.3, \"CI Upper\": 80.4}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Language\", \"F1 string\": \"74.5 (60.0, 83.3)\", \"F1\": 74.5, \"CI Lower\": 60.0, \"CI Upper\": 83.3}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Language\", \"F1 string\": \"51.9 (23.3, 100.0)\", \"F1\": 51.9, \"CI Lower\": 23.3, \"CI Upper\": 100.0}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Language\", \"F1 string\": \"45.9 (13.3, 93.3)\", \"F1\": 45.9, \"CI Lower\": 13.3, \"CI Upper\": 93.3}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Product\", \"F1 string\": \"62.4 (53.9, 72.0)\", \"F1\": 62.4, \"CI Lower\": 53.9, \"CI Upper\": 72.0}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Product\", \"F1 string\": \"62.6 (53.9, 71.6)\", \"F1\": 62.6, \"CI Lower\": 53.9, \"CI Upper\": 71.6}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Product\", \"F1 string\": \"59.5 (48.9, 67.9)\", \"F1\": 59.5, \"CI Lower\": 48.9, \"CI Upper\": 67.9}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Organization\", \"F1 string\": \"79.5 (74.9, 83.1)\", \"F1\": 79.5, \"CI Lower\": 74.9, \"CI Upper\": 83.1}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Organization\", \"F1 string\": \"80.5 (78.1, 84.2)\", \"F1\": 80.5, \"CI Lower\": 78.1, \"CI Upper\": 84.2}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Organization\", \"F1 string\": \"79.1 (75.7, 82.3)\", \"F1\": 79.1, \"CI Lower\": 75.7, \"CI Upper\": 82.3}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Cardinal\", \"F1 string\": \"87.0 (82.8, 90.3)\", \"F1\": 87.0, \"CI Lower\": 82.8, \"CI Upper\": 90.3}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Cardinal\", \"F1 string\": \"80.5 (77.0, 84.4)\", \"F1\": 80.5, \"CI Lower\": 77.0, \"CI Upper\": 84.4}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Cardinal\", \"F1 string\": \"89.2 (86.0, 91.7)\", \"F1\": 89.2, \"CI Lower\": 86.0, \"CI Upper\": 91.7}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Quantity\", \"F1 string\": \"78.6 (59.8, 93.8)\", \"F1\": 78.6, \"CI Lower\": 59.8, \"CI Upper\": 93.8}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Quantity\", \"F1 string\": \"76.9 (63.9, 89.9)\", \"F1\": 76.9, \"CI Lower\": 63.9, \"CI Upper\": 89.9}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Quantity\", \"F1 string\": \"71.3 (50.0, 91.1)\", \"F1\": 71.3, \"CI Lower\": 50.0, \"CI Upper\": 91.1}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Work of Art\", \"F1 string\": \"39.3 (25.5, 50.3)\", \"F1\": 39.3, \"CI Lower\": 25.5, \"CI Upper\": 50.3}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Work of Art\", \"F1 string\": \"58.4 (48.7, 69.1)\", \"F1\": 58.4, \"CI Lower\": 48.7, \"CI Upper\": 69.1}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Work of Art\", \"F1 string\": \"46.6 (36.2, 56.9)\", \"F1\": 46.6, \"CI Lower\": 36.2, \"CI Upper\": 56.9}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Location\", \"F1 string\": \"75.3 (66.9, 83.8)\", \"F1\": 75.3, \"CI Lower\": 66.9, \"CI Upper\": 83.8}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Location\", \"F1 string\": \"72.5 (62.1, 80.8)\", \"F1\": 72.5, \"CI Lower\": 62.1, \"CI Upper\": 80.8}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Location\", \"F1 string\": \"65.6 (55.4, 74.1)\", \"F1\": 65.6, \"CI Lower\": 55.4, \"CI Upper\": 74.1}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"NORP\", \"F1 string\": \"84.8 (76.9, 90.8)\", \"F1\": 84.8, \"CI Lower\": 76.9, \"CI Upper\": 90.8}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"NORP\", \"F1 string\": \"78.2 (68.6, 85.8)\", \"F1\": 78.2, \"CI Lower\": 68.6, \"CI Upper\": 85.8}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"NORP\", \"F1 string\": \"73.3 (62.9, 81.5)\", \"F1\": 73.3, \"CI Lower\": 62.9, \"CI Upper\": 81.5}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Date\", \"F1 string\": \"77.3 (71.6, 81.8)\", \"F1\": 77.3, \"CI Lower\": 71.6, \"CI Upper\": 81.8}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Date\", \"F1 string\": \"77.6 (72.8, 82.2)\", \"F1\": 77.6, \"CI Lower\": 72.8, \"CI Upper\": 82.2}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Date\", \"F1 string\": \"78.8 (73.9, 83.4)\", \"F1\": 78.8, \"CI Lower\": 73.9, \"CI Upper\": 83.4}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Percent\", \"F1 string\": \"100.0 (100.0, 100.0)\", \"F1\": 100.0, \"CI Lower\": 100.0, \"CI Upper\": 100.0}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Percent\", \"F1 string\": \"100.0 (100.0, 100.0)\", \"F1\": 100.0, \"CI Lower\": 100.0, \"CI Upper\": 100.0}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Percent\", \"F1 string\": \"100.0 (100.0, 100.0)\", \"F1\": 100.0, \"CI Lower\": 100.0, \"CI Upper\": 100.0}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Money\", \"F1 string\": \"99.3 (97.9, 100.0)\", \"F1\": 99.3, \"CI Lower\": 97.9, \"CI Upper\": 100.0}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Money\", \"F1 string\": \"98.6 (97.2, 100.0)\", \"F1\": 98.6, \"CI Lower\": 97.2, \"CI Upper\": 100.0}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Money\", \"F1 string\": \"95.2 (90.0, 98.2)\", \"F1\": 95.2, \"CI Lower\": 90.0, \"CI Upper\": 98.2}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Person\", \"F1 string\": \"85.9 (82.7, 88.8)\", \"F1\": 85.9, \"CI Lower\": 82.7, \"CI Upper\": 88.8}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Person\", \"F1 string\": \"84.8 (80.6, 88.2)\", \"F1\": 84.8, \"CI Lower\": 80.6, \"CI Upper\": 88.2}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Person\", \"F1 string\": \"86.8 (83.2, 90.1)\", \"F1\": 86.8, \"CI Lower\": 83.2, \"CI Upper\": 90.1}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Time\", \"F1 string\": \"90.9 (83.8, 96.7)\", \"F1\": 90.9, \"CI Lower\": 83.8, \"CI Upper\": 96.7}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Time\", \"F1 string\": \"85.1 (74.0, 93.7)\", \"F1\": 85.1, \"CI Lower\": 74.0, \"CI Upper\": 93.7}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Time\", \"F1 string\": \"83.4 (68.0, 95.6)\", \"F1\": 83.4, \"CI Lower\": 68.0, \"CI Upper\": 95.6}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"GPE\", \"F1 string\": \"90.6 (87.2, 93.1)\", \"F1\": 90.6, \"CI Lower\": 87.2, \"CI Upper\": 93.1}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"GPE\", \"F1 string\": \"88.0 (82.7, 92.1)\", \"F1\": 88.0, \"CI Lower\": 82.7, \"CI Upper\": 92.1}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"GPE\", \"F1 string\": \"79.6 (73.0, 84.6)\", \"F1\": 79.6, \"CI Lower\": 73.0, \"CI Upper\": 84.6}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Event\", \"F1 string\": \"43.5 (27.0, 56.0)\", \"F1\": 43.5, \"CI Lower\": 27.0, \"CI Upper\": 56.0}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Event\", \"F1 string\": \"64.2 (50.0, 79.4)\", \"F1\": 64.2, \"CI Lower\": 50.0, \"CI Upper\": 79.4}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Event\", \"F1 string\": \"46.1 (27.8, 62.4)\", \"F1\": 46.1, \"CI Lower\": 27.8, \"CI Upper\": 62.4}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Law\", \"F1 string\": \"54.2 (38.1, 72.5)\", \"F1\": 54.2, \"CI Lower\": 38.1, \"CI Upper\": 72.5}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Law\", \"F1 string\": \"59.3 (37.4, 77.3)\", \"F1\": 59.3, \"CI Lower\": 37.4, \"CI Upper\": 77.3}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Law\", \"F1 string\": \"57.6 (39.6, 75.1)\", \"F1\": 57.6, \"CI Lower\": 39.6, \"CI Upper\": 75.1}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Facility\", \"F1 string\": \"69.8 (54.3, 84.4)\", \"F1\": 69.8, \"CI Lower\": 54.3, \"CI Upper\": 84.4}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Facility\", \"F1 string\": \"72.3 (56.2, 84.6)\", \"F1\": 72.3, \"CI Lower\": 56.2, \"CI Upper\": 84.6}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Facility\", \"F1 string\": \"55.5 (36.2, 70.5)\", \"F1\": 55.5, \"CI Lower\": 36.2, \"CI Upper\": 70.5}, {\"Models\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Label\": \"Ordinal\", \"F1 string\": \"37.8 (22.5, 51.2)\", \"F1\": 37.8, \"CI Lower\": 22.5, \"CI Upper\": 51.2}, {\"Models\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Label\": \"Ordinal\", \"F1 string\": \"68.7 (49.1, 82.6)\", \"F1\": 68.7, \"CI Lower\": 49.1, \"CI Upper\": 82.6}, {\"Models\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Label\": \"Ordinal\", \"F1 string\": \"68.5 (47.6, 83.1)\", \"F1\": 68.5, \"CI Lower\": 47.6, \"CI Upper\": 83.1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dansk_df = pd.concat(tables)\n",
    "create_dansk_viz(dansk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "_df = dansk_df\n",
    "_df = _df.set_index(\"Models\")\n",
    "ent_columns = sorted(\n",
    "    [\n",
    "        \"Event\",\n",
    "        \"Organization\",\n",
    "        \"Language\",\n",
    "        \"Person\",\n",
    "        \"Ordinal\",\n",
    "        \"NORP\",\n",
    "        \"Work of Art\",\n",
    "        \"Facility\",\n",
    "        \"Law\",\n",
    "        \"Location\",\n",
    "        \"Product\",\n",
    "        \"GPE\",\n",
    "    ]\n",
    ")\n",
    "non_ent_columns = sorted([\"Cardinal\", \"Date\", \"Money\", \"Percent\", \"Quantity\", \"Time\"])\n",
    "columns_to_keep = ent_columns + non_ent_columns + [\"Average\"]\n",
    "\n",
    "_df = _df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "table = _df.T\n",
    "iidx = pd.MultiIndex.from_arrays(\n",
    "    [\n",
    "        [\"Entities\"] * len(ent_columns)\n",
    "        + [\"Non-Entities\"] * len(non_ent_columns)\n",
    "        + [\"Average\"],\n",
    "        ent_columns + non_ent_columns + [\"Average\"],\n",
    "    ]\n",
    ")\n",
    "table.index = iidx\n",
    "\n",
    "mdl_names = [\"Large 0.1.0\", \"Medium 0.1.0\", \"Small 0.1.0\"]\n",
    "header = pd.MultiIndex.from_arrays(\n",
    "    [[\"Fine-grained Models\"] * len(mdl_names), mdl_names]\n",
    ")\n",
    "table.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_05512 .level0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_05512 .col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_05512_row0_col1, #T_05512_row1_col1, #T_05512_row2_col0, #T_05512_row3_col0, #T_05512_row4_col1, #T_05512_row5_col0, #T_05512_row6_col0, #T_05512_row7_col1, #T_05512_row8_col1, #T_05512_row9_col2, #T_05512_row10_col1, #T_05512_row11_col1, #T_05512_row12_col2, #T_05512_row13_col2, #T_05512_row14_col0, #T_05512_row16_col0, #T_05512_row17_col0, #T_05512_row18_col0 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_05512_row0_col2, #T_05512_row1_col0, #T_05512_row2_col1, #T_05512_row3_col1, #T_05512_row4_col2, #T_05512_row5_col1, #T_05512_row6_col1, #T_05512_row7_col2, #T_05512_row8_col0, #T_05512_row9_col0, #T_05512_row10_col0, #T_05512_row11_col2, #T_05512_row12_col0, #T_05512_row13_col1, #T_05512_row14_col1, #T_05512_row16_col1, #T_05512_row17_col1, #T_05512_row18_col1 {\n",
       "  font-style: italic;\n",
       "}\n",
       "#T_05512_row15_col0, #T_05512_row15_col1, #T_05512_row15_col2 {\n",
       "  font-weight: bold;\n",
       "  font-style: normal;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_05512\" style=\"font-size: 0.8em\">\n",
       "  <caption>F1 score with 95% confidence interval calculated using bootstrapping with 100 samples.</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_05512_level0_col0\" class=\"col_heading level0 col0\" colspan=\"3\">Fine-grained Models</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_05512_level1_col0\" class=\"col_heading level1 col0\" >Large 0.1.0</th>\n",
       "      <th id=\"T_05512_level1_col1\" class=\"col_heading level1 col1\" >Medium 0.1.0</th>\n",
       "      <th id=\"T_05512_level1_col2\" class=\"col_heading level1 col2\" >Small 0.1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"12\">Entities</th>\n",
       "      <th id=\"T_05512_level1_row0\" class=\"row_heading level1 row0\" >Event</th>\n",
       "      <td id=\"T_05512_row0_col0\" class=\"data row0 col0\" >43.5 (27.0, 56.0)</td>\n",
       "      <td id=\"T_05512_row0_col1\" class=\"data row0 col1\" >64.2 (50.0, 79.4)</td>\n",
       "      <td id=\"T_05512_row0_col2\" class=\"data row0 col2\" >46.1 (27.8, 62.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row1\" class=\"row_heading level1 row1\" >Facility</th>\n",
       "      <td id=\"T_05512_row1_col0\" class=\"data row1 col0\" >69.8 (54.3, 84.4)</td>\n",
       "      <td id=\"T_05512_row1_col1\" class=\"data row1 col1\" >72.3 (56.2, 84.6)</td>\n",
       "      <td id=\"T_05512_row1_col2\" class=\"data row1 col2\" >55.5 (36.2, 70.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row2\" class=\"row_heading level1 row2\" >GPE</th>\n",
       "      <td id=\"T_05512_row2_col0\" class=\"data row2 col0\" >90.6 (87.2, 93.1)</td>\n",
       "      <td id=\"T_05512_row2_col1\" class=\"data row2 col1\" >88.0 (82.7, 92.1)</td>\n",
       "      <td id=\"T_05512_row2_col2\" class=\"data row2 col2\" >79.6 (73.0, 84.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row3\" class=\"row_heading level1 row3\" >Language</th>\n",
       "      <td id=\"T_05512_row3_col0\" class=\"data row3 col0\" >74.5 (60.0, 83.3)</td>\n",
       "      <td id=\"T_05512_row3_col1\" class=\"data row3 col1\" >51.9 (23.3, 100.0)</td>\n",
       "      <td id=\"T_05512_row3_col2\" class=\"data row3 col2\" >45.9 (13.3, 93.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row4\" class=\"row_heading level1 row4\" >Law</th>\n",
       "      <td id=\"T_05512_row4_col0\" class=\"data row4 col0\" >54.2 (38.1, 72.5)</td>\n",
       "      <td id=\"T_05512_row4_col1\" class=\"data row4 col1\" >59.3 (37.4, 77.3)</td>\n",
       "      <td id=\"T_05512_row4_col2\" class=\"data row4 col2\" >57.6 (39.6, 75.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row5\" class=\"row_heading level1 row5\" >Location</th>\n",
       "      <td id=\"T_05512_row5_col0\" class=\"data row5 col0\" >75.3 (66.9, 83.8)</td>\n",
       "      <td id=\"T_05512_row5_col1\" class=\"data row5 col1\" >72.5 (62.1, 80.8)</td>\n",
       "      <td id=\"T_05512_row5_col2\" class=\"data row5 col2\" >65.6 (55.4, 74.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row6\" class=\"row_heading level1 row6\" >NORP</th>\n",
       "      <td id=\"T_05512_row6_col0\" class=\"data row6 col0\" >84.8 (76.9, 90.8)</td>\n",
       "      <td id=\"T_05512_row6_col1\" class=\"data row6 col1\" >78.2 (68.6, 85.8)</td>\n",
       "      <td id=\"T_05512_row6_col2\" class=\"data row6 col2\" >73.3 (62.9, 81.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row7\" class=\"row_heading level1 row7\" >Ordinal</th>\n",
       "      <td id=\"T_05512_row7_col0\" class=\"data row7 col0\" >37.8 (22.5, 51.2)</td>\n",
       "      <td id=\"T_05512_row7_col1\" class=\"data row7 col1\" >68.7 (49.1, 82.6)</td>\n",
       "      <td id=\"T_05512_row7_col2\" class=\"data row7 col2\" >68.5 (47.6, 83.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row8\" class=\"row_heading level1 row8\" >Organization</th>\n",
       "      <td id=\"T_05512_row8_col0\" class=\"data row8 col0\" >79.5 (74.9, 83.1)</td>\n",
       "      <td id=\"T_05512_row8_col1\" class=\"data row8 col1\" >80.5 (78.1, 84.2)</td>\n",
       "      <td id=\"T_05512_row8_col2\" class=\"data row8 col2\" >79.1 (75.7, 82.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row9\" class=\"row_heading level1 row9\" >Person</th>\n",
       "      <td id=\"T_05512_row9_col0\" class=\"data row9 col0\" >85.9 (82.7, 88.8)</td>\n",
       "      <td id=\"T_05512_row9_col1\" class=\"data row9 col1\" >84.8 (80.6, 88.2)</td>\n",
       "      <td id=\"T_05512_row9_col2\" class=\"data row9 col2\" >86.8 (83.2, 90.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row10\" class=\"row_heading level1 row10\" >Product</th>\n",
       "      <td id=\"T_05512_row10_col0\" class=\"data row10 col0\" >62.4 (53.9, 72.0)</td>\n",
       "      <td id=\"T_05512_row10_col1\" class=\"data row10 col1\" >62.6 (53.9, 71.6)</td>\n",
       "      <td id=\"T_05512_row10_col2\" class=\"data row10 col2\" >59.5 (48.9, 67.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row11\" class=\"row_heading level1 row11\" >Work of Art</th>\n",
       "      <td id=\"T_05512_row11_col0\" class=\"data row11 col0\" >39.3 (25.5, 50.3)</td>\n",
       "      <td id=\"T_05512_row11_col1\" class=\"data row11 col1\" >58.4 (48.7, 69.1)</td>\n",
       "      <td id=\"T_05512_row11_col2\" class=\"data row11 col2\" >46.6 (36.2, 56.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level0_row12\" class=\"row_heading level0 row12\" rowspan=\"6\">Non-Entities</th>\n",
       "      <th id=\"T_05512_level1_row12\" class=\"row_heading level1 row12\" >Cardinal</th>\n",
       "      <td id=\"T_05512_row12_col0\" class=\"data row12 col0\" >87.0 (82.8, 90.3)</td>\n",
       "      <td id=\"T_05512_row12_col1\" class=\"data row12 col1\" >80.5 (77.0, 84.4)</td>\n",
       "      <td id=\"T_05512_row12_col2\" class=\"data row12 col2\" >89.2 (86.0, 91.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row13\" class=\"row_heading level1 row13\" >Date</th>\n",
       "      <td id=\"T_05512_row13_col0\" class=\"data row13 col0\" >77.3 (71.6, 81.8)</td>\n",
       "      <td id=\"T_05512_row13_col1\" class=\"data row13 col1\" >77.6 (72.8, 82.2)</td>\n",
       "      <td id=\"T_05512_row13_col2\" class=\"data row13 col2\" >78.8 (73.9, 83.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row14\" class=\"row_heading level1 row14\" >Money</th>\n",
       "      <td id=\"T_05512_row14_col0\" class=\"data row14 col0\" >99.3 (97.9, 100.0)</td>\n",
       "      <td id=\"T_05512_row14_col1\" class=\"data row14 col1\" >98.6 (97.2, 100.0)</td>\n",
       "      <td id=\"T_05512_row14_col2\" class=\"data row14 col2\" >95.2 (90.0, 98.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row15\" class=\"row_heading level1 row15\" >Percent</th>\n",
       "      <td id=\"T_05512_row15_col0\" class=\"data row15 col0\" >100.0 (100.0, 100.0)</td>\n",
       "      <td id=\"T_05512_row15_col1\" class=\"data row15 col1\" >100.0 (100.0, 100.0)</td>\n",
       "      <td id=\"T_05512_row15_col2\" class=\"data row15 col2\" >100.0 (100.0, 100.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row16\" class=\"row_heading level1 row16\" >Quantity</th>\n",
       "      <td id=\"T_05512_row16_col0\" class=\"data row16 col0\" >78.6 (59.8, 93.8)</td>\n",
       "      <td id=\"T_05512_row16_col1\" class=\"data row16 col1\" >76.9 (63.9, 89.9)</td>\n",
       "      <td id=\"T_05512_row16_col2\" class=\"data row16 col2\" >71.3 (50.0, 91.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level1_row17\" class=\"row_heading level1 row17\" >Time</th>\n",
       "      <td id=\"T_05512_row17_col0\" class=\"data row17 col0\" >90.9 (83.8, 96.7)</td>\n",
       "      <td id=\"T_05512_row17_col1\" class=\"data row17 col1\" >85.1 (74.0, 93.7)</td>\n",
       "      <td id=\"T_05512_row17_col2\" class=\"data row17 col2\" >83.4 (68.0, 95.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05512_level0_row18\" class=\"row_heading level0 row18\" >Average</th>\n",
       "      <th id=\"T_05512_level1_row18\" class=\"row_heading level1 row18\" >Average</th>\n",
       "      <td id=\"T_05512_row18_col0\" class=\"data row18 col0\" >80.1 (78.2, 81.9)</td>\n",
       "      <td id=\"T_05512_row18_col1\" class=\"data row18 col1\" >79.7 (77.7, 81.5)</td>\n",
       "      <td id=\"T_05512_row18_col2\" class=\"data row18 col2\" >78.4 (76.3, 80.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17847cd30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to latex using styler\n",
    "style = table.style.format_index(escape=\"latex\", axis=1).format_index(\n",
    "    escape=\"latex\", axis=0\n",
    ")\n",
    "\n",
    "\n",
    "# highlight the maximum\n",
    "def italicize_second_max(s: pd.Series) -> list:\n",
    "    \"\"\"Italicize the second maximum in a Series.\"\"\"\n",
    "    is_second_max = s == s.sort_values(ascending=False).iloc[1]\n",
    "    # check if the second maximum is the same as the maximum\n",
    "    same_as_max = s == s.max()\n",
    "\n",
    "    if same_as_max.sum() > 1:\n",
    "        # if there are more than one maximum, don't italicize\n",
    "        return [\"font-style: normal\" for v in is_second_max]\n",
    "    return [\"font-style: italic\" if v else \"\" for v in is_second_max]\n",
    "\n",
    "\n",
    "style = style.apply(highlight_max, axis=1)\n",
    "# style = style.apply(underline_second_max, axis=1)\n",
    "style = style.apply(italicize_second_max, axis=1)\n",
    "\n",
    "# apply the CSS style\n",
    "super_header_style = [\n",
    "    {\"selector\": \".level0\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    {\"selector\": \".col_heading\", \"props\": [(\"text-align\", \"center\")]},\n",
    "]\n",
    "style = style.set_table_styles(super_header_style)  # type: ignore\n",
    "\n",
    "\n",
    "# add caption\n",
    "caption = \"F1 score with 95% confidence interval calculated using bootstrapping with 100 samples.\"\n",
    "style = style.set_caption(caption)\n",
    "# font size\n",
    "style = style.set_table_attributes('style=\"font-size: 0.8em\"')\n",
    "style\n",
    "\n",
    "# latex = style.to_latex(\n",
    "#         hrules=True,\n",
    "#         convert_css=True,\n",
    "#     )\n",
    "\n",
    "# print(latex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Generalization\n",
    "For the domains generalization benchmark we utilize the [DANSK](https://huggingface.co/datasets/chcaa/DANSK) dataset. This dataset is annotated across many different domains including fiction, web content, social media, wikis, news, legal and conversational data.\n",
    "As some models are trained on DANSK (`da_dacy_{size}_ner_fine_grained-{version}`) these models are tested on the test set using all of the\n",
    "labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from evaluation.utils import evaluate_generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "tables = []\n",
    "for mdl_name in dansk:\n",
    "    if \"fine_grained\" not in mdl_name:\n",
    "        continue\n",
    "\n",
    "    table = evaluate_generalization(examples=dansk[mdl_name][\"test\"][\"examples\"], mdl_name=mdl_name, n_rep=100, n_samples=1000)\n",
    "    tables.append(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.concat(tables)\n",
    "df = df[df[\"Domain\"] != \"dannet\"]\n",
    "df = df[df[\"Domain\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ab74447a07bd43b493eb9af490258f99.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ab74447a07bd43b493eb9af490258f99.vega-embed details,\n",
       "  #altair-viz-ab74447a07bd43b493eb9af490258f99.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ab74447a07bd43b493eb9af490258f99\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ab74447a07bd43b493eb9af490258f99\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ab74447a07bd43b493eb9af490258f99\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"point\", \"filled\": true}, \"encoding\": {\"color\": {\"field\": \"Domain\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_2\", \"value\": 1}, \"value\": 0.0}, \"size\": {\"condition\": {\"param\": \"param_3\", \"field\": \"Number of docs\", \"legend\": null}, \"value\": 100}, \"tooltip\": [{\"field\": \"Model\", \"type\": \"nominal\"}, {\"field\": \"Domain\", \"type\": \"nominal\"}, {\"field\": \"Average F1\", \"type\": \"nominal\"}], \"x\": {\"field\": \"Average\", \"scale\": {\"domain\": [0.0, 1.0]}, \"title\": \"F1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Model\", \"sort\": [\"saattrupdan/nbailab-base-ner-scandi\", \"da_dacy_large_trf-0.2.0\", \"da_dacy_medium_trf-0.2.0\", \"da_dacy_small_trf-0.2.0\", \"da_dacy_large_ner_fine_grained-0.1.0\", \"da_dacy_medium_ner_fine_grained-0.1.0\", \"da_dacy_small_ner_fine_grained-0.1.0\", \"alexandrainst/da-ner-base\", \"da_core_news_trf-3.5.0\", \"da_core_news_lg-3.5.0\", \"da_core_news_md-3.5.0\", \"da_core_news_sm-3.5.0\"], \"type\": \"nominal\"}}, \"name\": \"view_2\"}, {\"mark\": {\"type\": \"errorbar\", \"ticks\": false}, \"encoding\": {\"color\": {\"field\": \"Domain\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_2\", \"value\": 1}, \"value\": 0.0}, \"x\": {\"field\": \"Average Lower CI\", \"title\": \"F1\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"Average Upper CI\"}, \"y\": {\"field\": \"Model\", \"sort\": [\"saattrupdan/nbailab-base-ner-scandi\", \"da_dacy_large_trf-0.2.0\", \"da_dacy_medium_trf-0.2.0\", \"da_dacy_small_trf-0.2.0\", \"da_dacy_large_ner_fine_grained-0.1.0\", \"da_dacy_medium_ner_fine_grained-0.1.0\", \"da_dacy_small_ner_fine_grained-0.1.0\", \"alexandrainst/da-ner-base\", \"da_core_news_trf-3.5.0\", \"da_core_news_lg-3.5.0\", \"da_core_news_md-3.5.0\", \"da_core_news_sm-3.5.0\"], \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-f41e944fb77a7a56152b17a7560d7b9e\"}, \"height\": 300, \"params\": [{\"name\": \"param_2\", \"select\": {\"type\": \"point\", \"fields\": [\"Domain\"]}, \"bind\": \"legend\", \"value\": [{\"Domain\": \"All\"}], \"views\": [\"view_2\"]}, {\"name\": \"param_3\", \"bind\": {\"input\": \"checkbox\", \"name\": \"Scale point size by number of documents: \"}}], \"title\": \"DANSK test set performance\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-f41e944fb77a7a56152b17a7560d7b9e\": [{\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"Web\", \"Average\": 0.8101067602127482, \"Average Lower CI\": 0.7841651487553125, \"Average Upper CI\": 0.830900900900901, \"Average F1\": \"0.81 (0.78, 0.83)\", \"Number of docs\": 783}, {\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"Legal\", \"Average\": 0.8663320350050492, \"Average Lower CI\": 0.8419256402801457, \"Average Upper CI\": 0.8887819496820972, \"Average F1\": \"0.87 (0.84, 0.89)\", \"Number of docs\": 239}, {\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"Conversation\", \"Average\": 0.7641179934708223, \"Average Lower CI\": 0.7337162907078971, \"Average Upper CI\": 0.7902515430981282, \"Average F1\": \"0.76 (0.73, 0.79)\", \"Number of docs\": 168}, {\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.7220179014224088, \"Average Lower CI\": 0.6878643801132788, \"Average Upper CI\": 0.762446517440944, \"Average F1\": \"0.72 (0.69, 0.76)\", \"Number of docs\": 182}, {\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"News\", \"Average\": 0.823329124708956, \"Average Lower CI\": 0.7975750707209395, \"Average Upper CI\": 0.8467087702231627, \"Average F1\": \"0.82 (0.80, 0.85)\", \"Number of docs\": 39}, {\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"Social Media\", \"Average\": 0.5842981151577813, \"Average Lower CI\": 0.5411082722470623, \"Average Upper CI\": 0.6276502609352638, \"Average F1\": \"0.58 (0.54, 0.63)\", \"Number of docs\": 64}, {\"Model\": \"da_dacy_large_ner_fine_grained-0.1.0\", \"Domain\": \"All\", \"Average\": 0.8012382615583585, \"Average Lower CI\": 0.7773314556164734, \"Average Upper CI\": 0.8290060904096623, \"Average F1\": \"0.80 (0.78, 0.83)\", \"Number of docs\": 1500}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"Web\", \"Average\": 0.8069059577346168, \"Average Lower CI\": 0.7792190204698447, \"Average Upper CI\": 0.8320044217003898, \"Average F1\": \"0.81 (0.78, 0.83)\", \"Number of docs\": 783}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"Legal\", \"Average\": 0.8792798287165162, \"Average Lower CI\": 0.860279516303508, \"Average Upper CI\": 0.8961524325753569, \"Average F1\": \"0.88 (0.86, 0.90)\", \"Number of docs\": 239}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"Conversation\", \"Average\": 0.6636923028744094, \"Average Lower CI\": 0.6349232630707509, \"Average Upper CI\": 0.6883207901715027, \"Average F1\": \"0.66 (0.63, 0.69)\", \"Number of docs\": 168}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.7937488810814491, \"Average Lower CI\": 0.7653571428571427, \"Average Upper CI\": 0.8218744746115128, \"Average F1\": \"0.79 (0.77, 0.82)\", \"Number of docs\": 182}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"News\", \"Average\": 0.6966281148220598, \"Average Lower CI\": 0.6733559377459511, \"Average Upper CI\": 0.7196226874856663, \"Average F1\": \"0.70 (0.67, 0.72)\", \"Number of docs\": 39}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"Social Media\", \"Average\": 0.6944594484094899, \"Average Lower CI\": 0.6478237984608682, \"Average Upper CI\": 0.7331416617609958, \"Average F1\": \"0.69 (0.65, 0.73)\", \"Number of docs\": 64}, {\"Model\": \"da_dacy_medium_ner_fine_grained-0.1.0\", \"Domain\": \"All\", \"Average\": 0.7954568921751537, \"Average Lower CI\": 0.7682324162204714, \"Average Upper CI\": 0.825265478923979, \"Average F1\": \"0.80 (0.77, 0.83)\", \"Number of docs\": 1500}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"Web\", \"Average\": 0.7781528937111613, \"Average Lower CI\": 0.7453085067542898, \"Average Upper CI\": 0.7999058473736373, \"Average F1\": \"0.78 (0.75, 0.80)\", \"Number of docs\": 783}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"Legal\", \"Average\": 0.9090202269126079, \"Average Lower CI\": 0.8905576809510362, \"Average Upper CI\": 0.9278187376371155, \"Average F1\": \"0.91 (0.89, 0.93)\", \"Number of docs\": 239}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"Conversation\", \"Average\": 0.7369381979372508, \"Average Lower CI\": 0.7024462244622447, \"Average Upper CI\": 0.7668525088402879, \"Average F1\": \"0.74 (0.70, 0.77)\", \"Number of docs\": 168}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.7414870979112445, \"Average Lower CI\": 0.711301648812756, \"Average Upper CI\": 0.774739456390258, \"Average F1\": \"0.74 (0.71, 0.77)\", \"Number of docs\": 182}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"News\", \"Average\": 0.7978561822955089, \"Average Lower CI\": 0.7712527545212747, \"Average Upper CI\": 0.8215780291306777, \"Average F1\": \"0.80 (0.77, 0.82)\", \"Number of docs\": 39}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"Social Media\", \"Average\": 0.707274819499705, \"Average Lower CI\": 0.6689111635220126, \"Average Upper CI\": 0.7518443992428864, \"Average F1\": \"0.71 (0.67, 0.75)\", \"Number of docs\": 64}, {\"Model\": \"da_dacy_small_ner_fine_grained-0.1.0\", \"Domain\": \"All\", \"Average\": 0.7842946502544421, \"Average Lower CI\": 0.7563924902895867, \"Average Upper CI\": 0.8127158179241442, \"Average F1\": \"0.78 (0.76, 0.81)\", \"Number of docs\": 1500}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create altair viz\n",
    "selection = alt.selection_point(\n",
    "    fields=[\"Domain\"],\n",
    "    bind=\"legend\",\n",
    "    value=[{\"Domain\": \"All\"}],\n",
    ")\n",
    "bind_checkbox = alt.binding_checkbox(\n",
    "    name=\"Scale point size by number of documents: \",\n",
    ")\n",
    "param_checkbox = alt.param(bind=bind_checkbox)\n",
    "\n",
    "sort_order = list(dansk.keys())\n",
    "\n",
    "base = (\n",
    "    alt.Chart(df)\n",
    "    .mark_point(filled=True)\n",
    "    .encode(\n",
    "        x=alt.X(\"Average\", title=\"F1\", scale=alt.Scale(domain=[0.0, 1.0])),\n",
    "        y=alt.Y(\"Model\", sort=sort_order),\n",
    "        color=\"Domain\",\n",
    "        size=alt.condition(\n",
    "            param_checkbox, \"Number of docs\", alt.value(100), legend=None\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"Model\",\n",
    "            \"Domain\",\n",
    "            \"Average F1\",\n",
    "        ],\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.0)),\n",
    "    )\n",
    ")\n",
    "error_bars = (\n",
    "    alt.Chart(df)\n",
    "    .mark_errorbar(ticks=False)\n",
    "    .encode(\n",
    "        x=alt.X(\"Average Lower CI\", title=\"F1\"),\n",
    "        x2=\"Average Upper CI\",\n",
    "        y=alt.Y(\"Model\", sort=sort_order),\n",
    "        color=\"Domain\",\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.0)),\n",
    "    )\n",
    ")\n",
    "\n",
    "chart = base + error_bars\n",
    "\n",
    "chart = chart.add_params(selection, param_checkbox).properties(\n",
    "    title=\"DANSK test set performance\",\n",
    ")\n",
    "\n",
    "\n",
    "chart.properties(width=400, height=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Domain generalization using CoNLL-2003 format\n",
    "To test the generalization we here convert the annotations to the CoNLL-2003 format using the labels `Person`, `Location`, `Organization`. As CoNLL-2003, `Location` includes cities, roads, mountains, abstract places, specific buildings, and meeting points. Thus the `GPE` (geo-political entity) were converted to `Location`. The `MISC` category in CoNLL-2003 is a diverse category meant to denote all names not in other categories (encapsulating both e.g. events and adjectives such as ”2004 World Cup” and ”Italian”), and is therefore not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from evaluation.utils import convert_to_conll_2003, create_row_conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "tables = []\n",
    "for mdl_name in dansk:\n",
    "    if \"fine_grained\" in mdl_name:\n",
    "        continue\n",
    "    examples = dansk[mdl_name][\"test\"][\"examples\"]\n",
    "    examples += dansk[mdl_name][\"dev\"][\"examples\"]\n",
    "    examples += dansk[mdl_name][\"train\"][\"examples\"]\n",
    "\n",
    "    \n",
    "    examples = convert_to_conll_2003(examples)\n",
    "    table = evaluate_generalization(mdl_name, examples, n_rep=100, n_samples=1000, create_row_fn=create_row_conll2003)\n",
    "    tables.append(table)\n",
    "\n",
    "tables = pd.concat(tables, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df = tables\n",
    "df = df[df[\"Domain\"] != \"dannet\"]   # type: ignore\n",
    "df = df[df[\"Domain\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-15ce44fa180d4c9db32ce47daf4b14e4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-15ce44fa180d4c9db32ce47daf4b14e4.vega-embed details,\n",
       "  #altair-viz-15ce44fa180d4c9db32ce47daf4b14e4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-15ce44fa180d4c9db32ce47daf4b14e4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-15ce44fa180d4c9db32ce47daf4b14e4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-15ce44fa180d4c9db32ce47daf4b14e4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"point\", \"filled\": true}, \"encoding\": {\"color\": {\"field\": \"Domain\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_4\", \"value\": 1}, \"value\": 0.0}, \"size\": {\"condition\": {\"param\": \"param_5\", \"field\": \"Number of docs\", \"legend\": null}, \"value\": 100}, \"tooltip\": [{\"field\": \"Model\", \"type\": \"nominal\"}, {\"field\": \"Domain\", \"type\": \"nominal\"}, {\"field\": \"Average F1\", \"type\": \"nominal\"}, {\"field\": \"Person F1\", \"type\": \"nominal\"}, {\"field\": \"Location F1\", \"type\": \"nominal\"}, {\"field\": \"Organization F1\", \"type\": \"nominal\"}], \"x\": {\"field\": \"Average\", \"scale\": {\"domain\": [0.0, 1.0]}, \"title\": \"F1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Model\", \"sort\": [\"saattrupdan/nbailab-base-ner-scandi\", \"da_dacy_large_trf-0.2.0\", \"da_dacy_medium_trf-0.2.0\", \"da_dacy_small_trf-0.2.0\", \"da_dacy_large_ner_fine_grained-0.1.0\", \"da_dacy_medium_ner_fine_grained-0.1.0\", \"da_dacy_small_ner_fine_grained-0.1.0\", \"alexandrainst/da-ner-base\", \"da_core_news_trf-3.5.0\", \"da_core_news_lg-3.5.0\", \"da_core_news_md-3.5.0\", \"da_core_news_sm-3.5.0\"], \"type\": \"nominal\"}}, \"name\": \"view_3\"}, {\"mark\": {\"type\": \"errorbar\", \"ticks\": false}, \"encoding\": {\"color\": {\"field\": \"Domain\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_4\", \"value\": 1}, \"value\": 0.0}, \"x\": {\"field\": \"Average Lower CI\", \"title\": \"F1\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"Average Upper CI\"}, \"y\": {\"field\": \"Model\", \"sort\": [\"saattrupdan/nbailab-base-ner-scandi\", \"da_dacy_large_trf-0.2.0\", \"da_dacy_medium_trf-0.2.0\", \"da_dacy_small_trf-0.2.0\", \"da_dacy_large_ner_fine_grained-0.1.0\", \"da_dacy_medium_ner_fine_grained-0.1.0\", \"da_dacy_small_ner_fine_grained-0.1.0\", \"alexandrainst/da-ner-base\", \"da_core_news_trf-3.5.0\", \"da_core_news_lg-3.5.0\", \"da_core_news_md-3.5.0\", \"da_core_news_sm-3.5.0\"], \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-290b8a00f13b86923ad85bd2d9a5337f\"}, \"height\": 300, \"params\": [{\"name\": \"param_4\", \"select\": {\"type\": \"point\", \"fields\": [\"Domain\"]}, \"bind\": \"legend\", \"value\": [{\"Domain\": \"All\"}], \"views\": [\"view_3\"]}, {\"name\": \"param_5\", \"bind\": {\"input\": \"checkbox\", \"name\": \"Scale point size by number of documents: \"}}], \"title\": \"Generalization to Unseen Domains\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-290b8a00f13b86923ad85bd2d9a5337f\": [{\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"Web\", \"Average\": 0.6320979667934344, \"Average Lower CI\": 0.5772940747683015, \"Average Upper CI\": 0.6807455174059502, \"Average F1\": \"0.63 (0.58, 0.68)\", \"Person F1\": \"0.76 (0.70, 0.82)\", \"Organization F1\": \"0.44 (0.34, 0.53)\", \"Location F1\": \"0.71 (0.61, 0.80)\", \"Number of docs\": 8270}, {\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"Legal\", \"Average\": 0.6091491463766007, \"Average Lower CI\": 0.5561125604518662, \"Average Upper CI\": 0.6694873582948897, \"Average F1\": \"0.61 (0.56, 0.67)\", \"Person F1\": \"0.64 (0.54, 0.74)\", \"Organization F1\": \"0.57 (0.51, 0.64)\", \"Location F1\": \"0.70 (0.56, 0.83)\", \"Number of docs\": 2163}, {\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"Conversation\", \"Average\": 0.6868105414946557, \"Average Lower CI\": 0.6288968945167018, \"Average Upper CI\": 0.733696412560472, \"Average F1\": \"0.69 (0.63, 0.73)\", \"Person F1\": \"0.45 (0.34, 0.53)\", \"Organization F1\": \"0.68 (0.56, 0.80)\", \"Location F1\": \"0.91 (0.86, 0.95)\", \"Number of docs\": 1649}, {\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"Wiki & Books\", \"Average\": 0.7071938816537304, \"Average Lower CI\": 0.6478843311160384, \"Average Upper CI\": 0.7605586293923509, \"Average F1\": \"0.71 (0.65, 0.76)\", \"Person F1\": \"0.65 (0.54, 0.73)\", \"Organization F1\": \"0.62 (0.46, 0.74)\", \"Location F1\": \"0.77 (0.70, 0.84)\", \"Number of docs\": 1709}, {\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"News\", \"Average\": 0.6930174636150015, \"Average Lower CI\": 0.6646859011292303, \"Average Upper CI\": 0.7221996681383499, \"Average F1\": \"0.69 (0.66, 0.72)\", \"Person F1\": \"0.78 (0.74, 0.82)\", \"Organization F1\": \"0.62 (0.57, 0.68)\", \"Location F1\": \"0.65 (0.60, 0.70)\", \"Number of docs\": 421}, {\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"Social Media\", \"Average\": 0.7146932414144532, \"Average Lower CI\": 0.6727417628443784, \"Average Upper CI\": 0.7635720331809718, \"Average F1\": \"0.71 (0.67, 0.76)\", \"Person F1\": \"0.82 (0.76, 0.87)\", \"Organization F1\": \"0.39 (0.29, 0.48)\", \"Location F1\": \"0.80 (0.73, 0.86)\", \"Number of docs\": 554}, {\"Model\": \"saattrupdan/nbailab-base-ner-scandi\", \"Domain\": \"All\", \"Average\": 0.6399846068221187, \"Average Lower CI\": 0.5913243276585245, \"Average Upper CI\": 0.6863364795832064, \"Average F1\": \"0.64 (0.59, 0.69)\", \"Person F1\": \"0.70 (0.63, 0.76)\", \"Organization F1\": \"0.49 (0.40, 0.58)\", \"Location F1\": \"0.74 (0.62, 0.81)\", \"Number of docs\": 15062}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"Web\", \"Average\": 0.6622299878444764, \"Average Lower CI\": 0.6067156841323254, \"Average Upper CI\": 0.7040365031143719, \"Average F1\": \"0.66 (0.61, 0.70)\", \"Person F1\": \"0.79 (0.72, 0.84)\", \"Organization F1\": \"0.46 (0.39, 0.53)\", \"Location F1\": \"0.77 (0.70, 0.83)\", \"Number of docs\": 8270}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"Legal\", \"Average\": 0.6705098767100004, \"Average Lower CI\": 0.6259144053402851, \"Average Upper CI\": 0.7092298537220516, \"Average F1\": \"0.67 (0.63, 0.71)\", \"Person F1\": \"0.75 (0.67, 0.83)\", \"Organization F1\": \"0.62 (0.56, 0.68)\", \"Location F1\": \"0.74 (0.60, 0.84)\", \"Number of docs\": 2163}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"Conversation\", \"Average\": 0.6542176020229208, \"Average Lower CI\": 0.6019818043008016, \"Average Upper CI\": 0.7140041741204531, \"Average F1\": \"0.65 (0.60, 0.71)\", \"Person F1\": \"0.48 (0.36, 0.57)\", \"Organization F1\": \"0.46 (0.31, 0.59)\", \"Location F1\": \"0.92 (0.88, 0.96)\", \"Number of docs\": 1649}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.6542573239405536, \"Average Lower CI\": 0.5965014245014245, \"Average Upper CI\": 0.7100683431310761, \"Average F1\": \"0.65 (0.60, 0.71)\", \"Person F1\": \"0.60 (0.50, 0.69)\", \"Organization F1\": \"0.43 (0.31, 0.52)\", \"Location F1\": \"0.82 (0.74, 0.87)\", \"Number of docs\": 1709}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"News\", \"Average\": 0.6919175862990398, \"Average Lower CI\": 0.6616499275837584, \"Average Upper CI\": 0.7227475950526797, \"Average F1\": \"0.69 (0.66, 0.72)\", \"Person F1\": \"0.76 (0.73, 0.81)\", \"Organization F1\": \"0.56 (0.51, 0.61)\", \"Location F1\": \"0.73 (0.69, 0.79)\", \"Number of docs\": 421}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"Social Media\", \"Average\": 0.7549612024929343, \"Average Lower CI\": 0.7119168127463809, \"Average Upper CI\": 0.7917034827948499, \"Average F1\": \"0.75 (0.71, 0.79)\", \"Person F1\": \"0.83 (0.79, 0.88)\", \"Organization F1\": \"0.45 (0.38, 0.53)\", \"Location F1\": \"0.90 (0.85, 0.95)\", \"Number of docs\": 554}, {\"Model\": \"da_dacy_large_trf-0.2.0\", \"Domain\": \"All\", \"Average\": 0.664953725293192, \"Average Lower CI\": 0.6217947060344624, \"Average Upper CI\": 0.7064397860593513, \"Average F1\": \"0.66 (0.62, 0.71)\", \"Person F1\": \"0.74 (0.67, 0.79)\", \"Organization F1\": \"0.50 (0.42, 0.56)\", \"Location F1\": \"0.79 (0.72, 0.85)\", \"Number of docs\": 15062}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"Web\", \"Average\": 0.5429015929539475, \"Average Lower CI\": 0.48955164757226394, \"Average Upper CI\": 0.600878112968197, \"Average F1\": \"0.54 (0.49, 0.60)\", \"Person F1\": \"0.66 (0.58, 0.73)\", \"Organization F1\": \"0.37 (0.31, 0.46)\", \"Location F1\": \"0.63 (0.51, 0.71)\", \"Number of docs\": 8270}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"Legal\", \"Average\": 0.5958256886871834, \"Average Lower CI\": 0.5559941357868662, \"Average Upper CI\": 0.6406445244706698, \"Average F1\": \"0.60 (0.56, 0.64)\", \"Person F1\": \"0.74 (0.64, 0.82)\", \"Organization F1\": \"0.48 (0.42, 0.55)\", \"Location F1\": \"0.79 (0.68, 0.89)\", \"Number of docs\": 2163}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"Conversation\", \"Average\": 0.6168235305503006, \"Average Lower CI\": 0.5622598708645221, \"Average Upper CI\": 0.6705878502225713, \"Average F1\": \"0.62 (0.56, 0.67)\", \"Person F1\": \"0.39 (0.30, 0.47)\", \"Organization F1\": \"0.50 (0.37, 0.61)\", \"Location F1\": \"0.92 (0.88, 0.96)\", \"Number of docs\": 1649}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.6013171286772022, \"Average Lower CI\": 0.5419592074592074, \"Average Upper CI\": 0.6513982076552458, \"Average F1\": \"0.60 (0.54, 0.65)\", \"Person F1\": \"0.59 (0.49, 0.68)\", \"Organization F1\": \"0.32 (0.22, 0.43)\", \"Location F1\": \"0.75 (0.67, 0.81)\", \"Number of docs\": 1709}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"News\", \"Average\": 0.5916103793988399, \"Average Lower CI\": 0.5514664353215447, \"Average Upper CI\": 0.6284386551663439, \"Average F1\": \"0.59 (0.55, 0.63)\", \"Person F1\": \"0.66 (0.61, 0.71)\", \"Organization F1\": \"0.57 (0.51, 0.63)\", \"Location F1\": \"0.53 (0.48, 0.59)\", \"Number of docs\": 421}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"Social Media\", \"Average\": 0.6229443114860667, \"Average Lower CI\": 0.5669289935014807, \"Average Upper CI\": 0.6692543941862644, \"Average F1\": \"0.62 (0.57, 0.67)\", \"Person F1\": \"0.65 (0.58, 0.72)\", \"Organization F1\": \"0.41 (0.33, 0.49)\", \"Location F1\": \"0.80 (0.74, 0.86)\", \"Number of docs\": 554}, {\"Model\": \"da_dacy_medium_trf-0.2.0\", \"Domain\": \"All\", \"Average\": 0.5569509457639416, \"Average Lower CI\": 0.49619818542368543, \"Average Upper CI\": 0.6100553940441581, \"Average F1\": \"0.56 (0.50, 0.61)\", \"Person F1\": \"0.62 (0.54, 0.70)\", \"Organization F1\": \"0.40 (0.31, 0.47)\", \"Location F1\": \"0.68 (0.57, 0.77)\", \"Number of docs\": 15062}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"Web\", \"Average\": 0.5461978061161671, \"Average Lower CI\": 0.5069639110204845, \"Average Upper CI\": 0.5969669409344694, \"Average F1\": \"0.55 (0.51, 0.60)\", \"Person F1\": \"0.73 (0.66, 0.78)\", \"Organization F1\": \"0.33 (0.26, 0.41)\", \"Location F1\": \"0.64 (0.57, 0.71)\", \"Number of docs\": 8270}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"Legal\", \"Average\": 0.536429517680482, \"Average Lower CI\": 0.4824591818015043, \"Average Upper CI\": 0.5958867300943556, \"Average F1\": \"0.54 (0.48, 0.60)\", \"Person F1\": \"0.52 (0.38, 0.64)\", \"Organization F1\": \"0.56 (0.49, 0.62)\", \"Location F1\": \"0.44 (0.26, 0.59)\", \"Number of docs\": 2163}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"Conversation\", \"Average\": 0.6268520454467161, \"Average Lower CI\": 0.5757813428401664, \"Average Upper CI\": 0.6786188472541147, \"Average F1\": \"0.63 (0.58, 0.68)\", \"Person F1\": \"0.43 (0.30, 0.51)\", \"Organization F1\": \"0.48 (0.37, 0.58)\", \"Location F1\": \"0.89 (0.84, 0.93)\", \"Number of docs\": 1649}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.46992430120737955, \"Average Lower CI\": 0.41995114847401627, \"Average Upper CI\": 0.51962931735553, \"Average F1\": \"0.47 (0.42, 0.52)\", \"Person F1\": \"0.52 (0.41, 0.61)\", \"Organization F1\": \"0.23 (0.15, 0.30)\", \"Location F1\": \"0.56 (0.50, 0.63)\", \"Number of docs\": 1709}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"News\", \"Average\": 0.6758817829004726, \"Average Lower CI\": 0.6382040892047133, \"Average Upper CI\": 0.707565011820331, \"Average F1\": \"0.68 (0.64, 0.71)\", \"Person F1\": \"0.76 (0.72, 0.80)\", \"Organization F1\": \"0.54 (0.48, 0.60)\", \"Location F1\": \"0.69 (0.64, 0.73)\", \"Number of docs\": 421}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"Social Media\", \"Average\": 0.6894082728405587, \"Average Lower CI\": 0.6451891646489103, \"Average Upper CI\": 0.725898249488777, \"Average F1\": \"0.69 (0.65, 0.73)\", \"Person F1\": \"0.83 (0.77, 0.87)\", \"Organization F1\": \"0.45 (0.35, 0.57)\", \"Location F1\": \"0.66 (0.56, 0.73)\", \"Number of docs\": 554}, {\"Model\": \"da_dacy_small_trf-0.2.0\", \"Domain\": \"All\", \"Average\": 0.5444872004098057, \"Average Lower CI\": 0.4915802185619259, \"Average Upper CI\": 0.5935406545573487, \"Average F1\": \"0.54 (0.49, 0.59)\", \"Person F1\": \"0.64 (0.56, 0.72)\", \"Organization F1\": \"0.38 (0.30, 0.46)\", \"Location F1\": \"0.65 (0.56, 0.72)\", \"Number of docs\": 15062}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"Web\", \"Average\": 0.6409070653617142, \"Average Lower CI\": 0.5889088534921868, \"Average Upper CI\": 0.693482868803189, \"Average F1\": \"0.64 (0.59, 0.69)\", \"Person F1\": \"0.76 (0.70, 0.82)\", \"Organization F1\": \"0.44 (0.37, 0.55)\", \"Location F1\": \"0.71 (0.64, 0.79)\", \"Number of docs\": 8270}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"Legal\", \"Average\": 0.7598117588210556, \"Average Lower CI\": 0.7161917167009288, \"Average Upper CI\": 0.7983702763026245, \"Average F1\": \"0.76 (0.72, 0.80)\", \"Person F1\": \"0.76 (0.67, 0.83)\", \"Organization F1\": \"0.75 (0.71, 0.80)\", \"Location F1\": \"0.81 (0.67, 0.90)\", \"Number of docs\": 2163}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"Conversation\", \"Average\": 0.6593392586208562, \"Average Lower CI\": 0.5947191641011913, \"Average Upper CI\": 0.7285752473593345, \"Average F1\": \"0.66 (0.59, 0.73)\", \"Person F1\": \"0.47 (0.36, 0.56)\", \"Organization F1\": \"0.49 (0.29, 0.62)\", \"Location F1\": \"0.92 (0.88, 0.96)\", \"Number of docs\": 1649}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"Wiki & Books\", \"Average\": 0.7018148381144313, \"Average Lower CI\": 0.6321812888672114, \"Average Upper CI\": 0.7556884494815529, \"Average F1\": \"0.70 (0.63, 0.76)\", \"Person F1\": \"0.68 (0.59, 0.76)\", \"Organization F1\": \"0.41 (0.24, 0.55)\", \"Location F1\": \"0.81 (0.75, 0.86)\", \"Number of docs\": 1709}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"News\", \"Average\": 0.7094609467638066, \"Average Lower CI\": 0.6772939111022244, \"Average Upper CI\": 0.7341493750609626, \"Average F1\": \"0.71 (0.68, 0.73)\", \"Person F1\": \"0.77 (0.73, 0.81)\", \"Organization F1\": \"0.62 (0.56, 0.67)\", \"Location F1\": \"0.70 (0.65, 0.74)\", \"Number of docs\": 421}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"Social Media\", \"Average\": 0.7396773181136647, \"Average Lower CI\": 0.6929453672293987, \"Average Upper CI\": 0.785763293310463, \"Average F1\": \"0.74 (0.69, 0.79)\", \"Person F1\": \"0.81 (0.75, 0.86)\", \"Organization F1\": \"0.47 (0.37, 0.57)\", \"Location F1\": \"0.83 (0.77, 0.90)\", \"Number of docs\": 554}, {\"Model\": \"alexandrainst/da-ner-base\", \"Domain\": \"All\", \"Average\": 0.6644254866827842, \"Average Lower CI\": 0.6035380314277451, \"Average Upper CI\": 0.7188656810176565, \"Average F1\": \"0.66 (0.60, 0.72)\", \"Person F1\": \"0.72 (0.65, 0.78)\", \"Organization F1\": \"0.52 (0.41, 0.61)\", \"Location F1\": \"0.76 (0.68, 0.83)\", \"Number of docs\": 15062}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"Web\", \"Average\": 0.5717369198343648, \"Average Lower CI\": 0.5082934413798914, \"Average Upper CI\": 0.624909837855705, \"Average F1\": \"0.57 (0.51, 0.62)\", \"Person F1\": \"0.66 (0.60, 0.73)\", \"Organization F1\": \"0.37 (0.29, 0.47)\", \"Location F1\": \"0.69 (0.60, 0.77)\", \"Number of docs\": 8270}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"Legal\", \"Average\": 0.6762522405192257, \"Average Lower CI\": 0.6271914294898971, \"Average Upper CI\": 0.722508563135951, \"Average F1\": \"0.68 (0.63, 0.72)\", \"Person F1\": \"0.71 (0.62, 0.79)\", \"Organization F1\": \"0.63 (0.58, 0.69)\", \"Location F1\": \"0.80 (0.67, 0.91)\", \"Number of docs\": 2163}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"Conversation\", \"Average\": 0.6234100285427392, \"Average Lower CI\": 0.567126906271783, \"Average Upper CI\": 0.6840985610092647, \"Average F1\": \"0.62 (0.57, 0.68)\", \"Person F1\": \"0.44 (0.33, 0.55)\", \"Organization F1\": \"0.40 (0.24, 0.52)\", \"Location F1\": \"0.89 (0.85, 0.93)\", \"Number of docs\": 1649}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.6148739675696991, \"Average Lower CI\": 0.5642660339813256, \"Average Upper CI\": 0.6703068610254237, \"Average F1\": \"0.61 (0.56, 0.67)\", \"Person F1\": \"0.58 (0.50, 0.67)\", \"Organization F1\": \"0.26 (0.12, 0.38)\", \"Location F1\": \"0.76 (0.69, 0.82)\", \"Number of docs\": 1709}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"News\", \"Average\": 0.691160431800026, \"Average Lower CI\": 0.6555163417138534, \"Average Upper CI\": 0.7208689637826962, \"Average F1\": \"0.69 (0.66, 0.72)\", \"Person F1\": \"0.71 (0.68, 0.76)\", \"Organization F1\": \"0.55 (0.46, 0.61)\", \"Location F1\": \"0.77 (0.71, 0.81)\", \"Number of docs\": 421}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"Social Media\", \"Average\": 0.7107722551142583, \"Average Lower CI\": 0.671195919335157, \"Average Upper CI\": 0.7532407407407407, \"Average F1\": \"0.71 (0.67, 0.75)\", \"Person F1\": \"0.76 (0.71, 0.81)\", \"Organization F1\": \"0.45 (0.36, 0.54)\", \"Location F1\": \"0.83 (0.76, 0.89)\", \"Number of docs\": 554}, {\"Model\": \"da_core_news_trf-3.5.0\", \"Domain\": \"All\", \"Average\": 0.5941779959127065, \"Average Lower CI\": 0.5375469336670838, \"Average Upper CI\": 0.6430959568288406, \"Average F1\": \"0.59 (0.54, 0.64)\", \"Person F1\": \"0.63 (0.54, 0.71)\", \"Organization F1\": \"0.43 (0.34, 0.52)\", \"Location F1\": \"0.73 (0.63, 0.80)\", \"Number of docs\": 15062}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"Web\", \"Average\": 0.4859487847315235, \"Average Lower CI\": 0.43429190757967623, \"Average Upper CI\": 0.5372173263110323, \"Average F1\": \"0.49 (0.43, 0.54)\", \"Person F1\": \"0.65 (0.58, 0.73)\", \"Organization F1\": \"0.29 (0.21, 0.38)\", \"Location F1\": \"0.56 (0.45, 0.64)\", \"Number of docs\": 8270}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"Legal\", \"Average\": 0.5568956849585586, \"Average Lower CI\": 0.49839034509529123, \"Average Upper CI\": 0.608655303030303, \"Average F1\": \"0.56 (0.50, 0.61)\", \"Person F1\": \"0.71 (0.62, 0.83)\", \"Organization F1\": \"0.44 (0.38, 0.52)\", \"Location F1\": \"0.71 (0.59, 0.83)\", \"Number of docs\": 2163}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"Conversation\", \"Average\": 0.6077738474778475, \"Average Lower CI\": 0.5579258733398409, \"Average Upper CI\": 0.6628561064019317, \"Average F1\": \"0.61 (0.56, 0.66)\", \"Person F1\": \"0.36 (0.26, 0.47)\", \"Organization F1\": \"0.52 (0.39, 0.65)\", \"Location F1\": \"0.89 (0.84, 0.94)\", \"Number of docs\": 1649}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.5171714580214156, \"Average Lower CI\": 0.442906976744186, \"Average Upper CI\": 0.5804834955564959, \"Average F1\": \"0.52 (0.44, 0.58)\", \"Person F1\": \"0.45 (0.36, 0.54)\", \"Organization F1\": \"0.25 (0.13, 0.34)\", \"Location F1\": \"0.70 (0.63, 0.76)\", \"Number of docs\": 1709}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"News\", \"Average\": 0.6154821004039736, \"Average Lower CI\": 0.5746965811965812, \"Average Upper CI\": 0.6540876498287672, \"Average F1\": \"0.62 (0.57, 0.65)\", \"Person F1\": \"0.69 (0.65, 0.74)\", \"Organization F1\": \"0.46 (0.40, 0.54)\", \"Location F1\": \"0.64 (0.59, 0.70)\", \"Number of docs\": 421}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"Social Media\", \"Average\": 0.5774874698174104, \"Average Lower CI\": 0.5310012956286616, \"Average Upper CI\": 0.6240742887424237, \"Average F1\": \"0.58 (0.53, 0.62)\", \"Person F1\": \"0.65 (0.57, 0.71)\", \"Organization F1\": \"0.34 (0.24, 0.43)\", \"Location F1\": \"0.66 (0.58, 0.75)\", \"Number of docs\": 554}, {\"Model\": \"da_core_news_lg-3.5.0\", \"Domain\": \"All\", \"Average\": 0.5069216754168929, \"Average Lower CI\": 0.44735545946565103, \"Average Upper CI\": 0.5651739638258565, \"Average F1\": \"0.51 (0.45, 0.57)\", \"Person F1\": \"0.60 (0.51, 0.68)\", \"Organization F1\": \"0.32 (0.24, 0.40)\", \"Location F1\": \"0.63 (0.53, 0.72)\", \"Number of docs\": 15062}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"Web\", \"Average\": 0.4745033261598815, \"Average Lower CI\": 0.4263456721228215, \"Average Upper CI\": 0.5215018656716418, \"Average F1\": \"0.47 (0.43, 0.52)\", \"Person F1\": \"0.64 (0.56, 0.71)\", \"Organization F1\": \"0.26 (0.21, 0.34)\", \"Location F1\": \"0.58 (0.46, 0.68)\", \"Number of docs\": 8270}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"Legal\", \"Average\": 0.5748506490376031, \"Average Lower CI\": 0.5140775267241071, \"Average Upper CI\": 0.6232807901440448, \"Average F1\": \"0.57 (0.51, 0.62)\", \"Person F1\": \"0.65 (0.55, 0.74)\", \"Organization F1\": \"0.50 (0.43, 0.56)\", \"Location F1\": \"0.77 (0.61, 0.86)\", \"Number of docs\": 2163}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"Conversation\", \"Average\": 0.6129605060379099, \"Average Lower CI\": 0.5610351926912437, \"Average Upper CI\": 0.6640061306614093, \"Average F1\": \"0.61 (0.56, 0.66)\", \"Person F1\": \"0.37 (0.27, 0.46)\", \"Organization F1\": \"0.53 (0.40, 0.66)\", \"Location F1\": \"0.87 (0.81, 0.92)\", \"Number of docs\": 1649}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.48662621172654597, \"Average Lower CI\": 0.41378571428571426, \"Average Upper CI\": 0.5387693288697593, \"Average F1\": \"0.49 (0.41, 0.54)\", \"Person F1\": \"0.44 (0.35, 0.53)\", \"Organization F1\": \"0.22 (0.12, 0.30)\", \"Location F1\": \"0.66 (0.58, 0.73)\", \"Number of docs\": 1709}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"News\", \"Average\": 0.5823902691260386, \"Average Lower CI\": 0.5451603700806806, \"Average Upper CI\": 0.6201576245460397, \"Average F1\": \"0.58 (0.55, 0.62)\", \"Person F1\": \"0.61 (0.56, 0.66)\", \"Organization F1\": \"0.40 (0.34, 0.47)\", \"Location F1\": \"0.68 (0.62, 0.73)\", \"Number of docs\": 421}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"Social Media\", \"Average\": 0.5930123182295732, \"Average Lower CI\": 0.5490975059454845, \"Average Upper CI\": 0.6368166593854666, \"Average F1\": \"0.59 (0.55, 0.64)\", \"Person F1\": \"0.69 (0.63, 0.74)\", \"Organization F1\": \"0.30 (0.20, 0.39)\", \"Location F1\": \"0.70 (0.63, 0.78)\", \"Number of docs\": 554}, {\"Model\": \"da_core_news_md-3.5.0\", \"Domain\": \"All\", \"Average\": 0.498074458954352, \"Average Lower CI\": 0.43267572996741643, \"Average Upper CI\": 0.5507352130044973, \"Average F1\": \"0.50 (0.43, 0.55)\", \"Person F1\": \"0.59 (0.51, 0.67)\", \"Organization F1\": \"0.31 (0.24, 0.39)\", \"Location F1\": \"0.63 (0.51, 0.73)\", \"Number of docs\": 15062}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"Web\", \"Average\": 0.2920643226833033, \"Average Lower CI\": 0.2502204729525964, \"Average Upper CI\": 0.3343973227045257, \"Average F1\": \"0.29 (0.25, 0.33)\", \"Person F1\": \"0.35 (0.28, 0.41)\", \"Organization F1\": \"0.15 (0.08, 0.19)\", \"Location F1\": \"0.39 (0.30, 0.49)\", \"Number of docs\": 8270}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"Legal\", \"Average\": 0.4928129111150733, \"Average Lower CI\": 0.42574027160596367, \"Average Upper CI\": 0.5437918445517297, \"Average F1\": \"0.49 (0.43, 0.54)\", \"Person F1\": \"0.53 (0.41, 0.65)\", \"Organization F1\": \"0.46 (0.39, 0.52)\", \"Location F1\": \"0.53 (0.39, 0.65)\", \"Number of docs\": 2163}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"Conversation\", \"Average\": 0.4988902152023031, \"Average Lower CI\": 0.4402202471024494, \"Average Upper CI\": 0.552027665980754, \"Average F1\": \"0.50 (0.44, 0.55)\", \"Person F1\": \"0.24 (0.16, 0.33)\", \"Organization F1\": \"0.31 (0.17, 0.43)\", \"Location F1\": \"0.80 (0.74, 0.87)\", \"Number of docs\": 1649}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"Wiki & Books\", \"Average\": 0.33443918532217004, \"Average Lower CI\": 0.2861951798136416, \"Average Upper CI\": 0.3820397022332506, \"Average F1\": \"0.33 (0.29, 0.38)\", \"Person F1\": \"0.26 (0.19, 0.34)\", \"Organization F1\": \"0.14 (0.07, 0.23)\", \"Location F1\": \"0.48 (0.41, 0.56)\", \"Number of docs\": 1709}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"News\", \"Average\": 0.5051741121845459, \"Average Lower CI\": 0.45972088749306494, \"Average Upper CI\": 0.5399541337759082, \"Average F1\": \"0.51 (0.46, 0.54)\", \"Person F1\": \"0.51 (0.47, 0.56)\", \"Organization F1\": \"0.29 (0.23, 0.36)\", \"Location F1\": \"0.64 (0.58, 0.69)\", \"Number of docs\": 421}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"Social Media\", \"Average\": 0.39286038498567044, \"Average Lower CI\": 0.3438957174909765, \"Average Upper CI\": 0.4500212449543233, \"Average F1\": \"0.39 (0.34, 0.45)\", \"Person F1\": \"0.45 (0.38, 0.53)\", \"Organization F1\": \"0.18 (0.09, 0.25)\", \"Location F1\": \"0.47 (0.36, 0.55)\", \"Number of docs\": 554}, {\"Model\": \"da_core_news_sm-3.5.0\", \"Domain\": \"All\", \"Average\": 0.3418451669912897, \"Average Lower CI\": 0.2815761105612794, \"Average Upper CI\": 0.395188156070509, \"Average F1\": \"0.34 (0.28, 0.40)\", \"Person F1\": \"0.36 (0.27, 0.45)\", \"Organization F1\": \"0.22 (0.14, 0.27)\", \"Location F1\": \"0.46 (0.37, 0.55)\", \"Number of docs\": 15062}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create altair viz\n",
    "selection = alt.selection_point(\n",
    "    fields=[\"Domain\"],\n",
    "    bind=\"legend\",\n",
    "    value=[{\"Domain\": \"All\"}],\n",
    ")\n",
    "bind_checkbox = alt.binding_checkbox(\n",
    "    name=\"Scale point size by number of documents: \",\n",
    ")\n",
    "param_checkbox = alt.param(bind=bind_checkbox)\n",
    "\n",
    "sort_order = list(dansk.keys())\n",
    "\n",
    "base = (\n",
    "    alt.Chart(df)\n",
    "    .mark_point(filled=True)\n",
    "    .encode(\n",
    "        x=alt.X(\"Average\", title=\"F1\", scale=alt.Scale(domain=[0.0, 1.0])),\n",
    "        y=alt.Y(\"Model\", sort=sort_order),\n",
    "        color=\"Domain\",\n",
    "        size=alt.condition(\n",
    "            param_checkbox, \"Number of docs\", alt.value(100), legend=None\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"Model\",\n",
    "            \"Domain\",\n",
    "            \"Average F1\",\n",
    "            \"Person F1\",\n",
    "            \"Location F1\",\n",
    "            \"Organization F1\",\n",
    "        ],\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.0)),\n",
    "    )\n",
    ")\n",
    "error_bars = (\n",
    "    alt.Chart(df)\n",
    "    .mark_errorbar(ticks=False)\n",
    "    .encode(\n",
    "        x=alt.X(\"Average Lower CI\", title=\"F1\"),\n",
    "        x2=\"Average Upper CI\",\n",
    "        y=alt.Y(\"Model\", sort=sort_order),\n",
    "        color=\"Domain\",\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.0)),\n",
    "    )\n",
    ")\n",
    "\n",
    "chart = base + error_bars\n",
    "\n",
    "chart = chart.add_params(selection, param_checkbox).properties(\n",
    "    width=400, height=300,\n",
    "    title=\"Generalization to Unseen Domains\",\n",
    ")\n",
    "\n",
    "\n",
    "chart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases\n",
    "\n",
    "To examine the biases in Danish models we use augmentation to replace names in the Danish dataset DaNE {cite}`hvingelby2020dane`, this approach\n",
    "is similar to that introduced in the initial DaCy paper {cite}`enevoldsen2021dacy`.\n",
    "\n",
    "Here is a short example of how the augmentation might look like:\n",
    "\n",
    "\n",
    "````{admonition} Example\n",
    "\n",
    "```{admonition} Original\n",
    ":class: note\n",
    "\n",
    "\n",
    "Peter Schmeichel mener også, at det danske landshold anno 2021 tilhører verdenstoppen og kan vinde den kommende kamp mod England.\n",
    "```\n",
    "\n",
    "```{admonition} Female name augmentation\n",
    ":class: important\n",
    "\n",
    "Anne Østergaard mener også, at det danske landshold anno 2021 tilhører verdenstoppen og kan vinde den kommende kamp mod England.\n",
    "```\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_bias_dane (test): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "gender_bias_dane (test): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "gender_bias_dane (test): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "gender_bias_dane (test): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "gender_bias_dane (test): Loading prediction for alexandrainst/da-ner-base\n",
      "gender_bias_dane (test): Loading prediction for da_core_news_trf-3.5.0\n",
      "gender_bias_dane (test): Loading prediction for da_core_news_lg-3.5.0\n",
      "gender_bias_dane (test): Loading prediction for da_core_news_md-3.5.0\n",
      "gender_bias_dane (test): Loading prediction for da_core_news_sm-3.5.0\n"
     ]
    }
   ],
   "source": [
    "gbiases = {}\n",
    "for mdl_name, model_getter in MODELS.items():\n",
    "    if \"fine_grained\" in mdl_name:\n",
    "        continue\n",
    "    mdl_results = apply_models(\n",
    "        mdl_name, model_getter, dataset=\"gender_bias_dane\", splits=[\"test\"]\n",
    "    )\n",
    "    gbiases[mdl_name] = mdl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def augmentation_specific_examples(examples):\n",
    "    aug_group = defaultdict(list)\n",
    "    for example in examples:\n",
    "        aug_name = example.y._.meta[\"augmenter\"]\n",
    "        aug_group[aug_name].append(example)\n",
    "    return aug_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saattrupdan/nbailab-base-ner-scandi\n",
      "da_dacy_large_trf-0.2.0\n",
      "da_dacy_medium_trf-0.2.0\n",
      "da_dacy_small_trf-0.2.0\n",
      "alexandrainst/da-ner-base\n",
      "da_core_news_trf-3.5.0\n",
      "da_core_news_lg-3.5.0\n",
      "da_core_news_md-3.5.0\n",
      "da_core_news_sm-3.5.0\n"
     ]
    }
   ],
   "source": [
    "tables = []\n",
    "for mdl in gbiases:\n",
    "    print(mdl)\n",
    "    examples = gbiases[mdl][\"test\"][\"examples\"]\n",
    "\n",
    "    aug_group = augmentation_specific_examples(examples)\n",
    "    for aug_name, _examples in aug_group.items():\n",
    "        _examples = convert_to_conll_2003(_examples) # also removes misc.\n",
    "        table = create_dataframe(_examples, mdl, n_rep=100, n_samples=1000)\n",
    "        table[\"Augmentation\"] = aug_name\n",
    "        tables.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.concat(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# create the table\n",
    "def create_table(df, model_order: list[str], baseline=df_average):\n",
    "\n",
    "    table_df = df[[\"Models\", \"Augmentation\", \"Average\"]]\n",
    "\n",
    "    table_df = table_df.pivot(index=\"Models\", columns=\"Augmentation\", values=\"Average\")\n",
    "\n",
    "    # order the models column\n",
    "    table_df = table_df.reindex(model_order)\n",
    "\n",
    "    # add baseline\n",
    "    table_df[\"Baseline\"] = list(baseline)\n",
    "    # order the columns\n",
    "    table_df = table_df[[\"Baseline\"] + list(table_df.columns[:-1])]\n",
    "\n",
    "\n",
    "    # create augmentation superheader\n",
    "\n",
    "    aug_superheader = [(\"\", \"Baseline\")]\n",
    "    for aug_name in table_df.columns[1:]:\n",
    "        aug_superheader.append((\"Augmentation\", aug_name))\n",
    "\n",
    "    aug_superheader = pd.MultiIndex.from_tuples(aug_superheader)\n",
    "    table_df.columns = aug_superheader\n",
    "    df = table_df.reset_index()\n",
    "    s = df.style.apply(highlight_max, axis=0, subset=df.columns[1:])\n",
    "    s = s.apply(underline_second_max, axis=0, subset=df.columns[1:])\n",
    "\n",
    "    # Add a caption\n",
    "    s = s.set_caption(\"F1 score for each augmentation with 95% confidence interval calculated over 100 repetitions\")\n",
    "\n",
    "    # Center the header and left align the model names\n",
    "    s = s.set_properties(subset=df.columns[1:], **{\"text-align\": \"right\"})\n",
    "\n",
    "    super_header_style = [\n",
    "        {\"selector\": \".level0\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        {\"selector\": \".col_heading\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    ]\n",
    "    # Apply the CSS style to the styler\n",
    "    s = s.set_table_styles(super_header_style)  # type: ignore\n",
    "    # s = s.set_properties(subset=[(\"\", \"Models\")],\n",
    "    #                       **{\"text-align\": \"left\"})\n",
    "    # remove the index\n",
    "    s = s.hide(axis=\"index\")\n",
    "    # smaller font\n",
    "    s = s.set_table_attributes('style=\"font-size: 0.65em\"')\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1ce53 .level0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_1ce53 .col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_1ce53_row0_col1, #T_1ce53_row0_col2, #T_1ce53_row0_col3, #T_1ce53_row0_col4, #T_1ce53_row0_col5 {\n",
       "  font-weight: bold;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_1ce53_row1_col1, #T_1ce53_row1_col2, #T_1ce53_row1_col3, #T_1ce53_row1_col4, #T_1ce53_row1_col5 {\n",
       "  text-decoration: underline;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_1ce53_row2_col1, #T_1ce53_row2_col2, #T_1ce53_row2_col3, #T_1ce53_row2_col4, #T_1ce53_row2_col5, #T_1ce53_row3_col1, #T_1ce53_row3_col2, #T_1ce53_row3_col3, #T_1ce53_row3_col4, #T_1ce53_row3_col5, #T_1ce53_row4_col1, #T_1ce53_row4_col2, #T_1ce53_row4_col3, #T_1ce53_row4_col4, #T_1ce53_row4_col5, #T_1ce53_row5_col1, #T_1ce53_row5_col2, #T_1ce53_row5_col3, #T_1ce53_row5_col4, #T_1ce53_row5_col5, #T_1ce53_row6_col1, #T_1ce53_row6_col2, #T_1ce53_row6_col3, #T_1ce53_row6_col4, #T_1ce53_row6_col5, #T_1ce53_row7_col1, #T_1ce53_row7_col2, #T_1ce53_row7_col3, #T_1ce53_row7_col4, #T_1ce53_row7_col5, #T_1ce53_row8_col1, #T_1ce53_row8_col2, #T_1ce53_row8_col3, #T_1ce53_row8_col4, #T_1ce53_row8_col5 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1ce53\" style=\"font-size: 0.65em\">\n",
       "  <caption>F1 score for each augmentation with 95% confidence interval calculated over 100 repetitions</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_1ce53_level0_col0\" class=\"col_heading level0 col0\" >Models</th>\n",
       "      <th id=\"T_1ce53_level0_col1\" class=\"col_heading level0 col1\" ></th>\n",
       "      <th id=\"T_1ce53_level0_col2\" class=\"col_heading level0 col2\" colspan=\"4\">Augmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ce53_level1_col0\" class=\"col_heading level1 col0\" ></th>\n",
       "      <th id=\"T_1ce53_level1_col1\" class=\"col_heading level1 col1\" >Baseline</th>\n",
       "      <th id=\"T_1ce53_level1_col2\" class=\"col_heading level1 col2\" >Danish Names</th>\n",
       "      <th id=\"T_1ce53_level1_col3\" class=\"col_heading level1 col3\" >Female Names</th>\n",
       "      <th id=\"T_1ce53_level1_col4\" class=\"col_heading level1 col4\" >Male Names</th>\n",
       "      <th id=\"T_1ce53_level1_col5\" class=\"col_heading level1 col5\" >Muslim Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row0_col0\" class=\"data row0 col0\" >saattrupdan/nbailab-base-ner-scandi</td>\n",
       "      <td id=\"T_1ce53_row0_col1\" class=\"data row0 col1\" >86.3 (82.4, 89.7)</td>\n",
       "      <td id=\"T_1ce53_row0_col2\" class=\"data row0 col2\" >89.0 (86.8, 91.1)</td>\n",
       "      <td id=\"T_1ce53_row0_col3\" class=\"data row0 col3\" >88.9 (86.9, 91.1)</td>\n",
       "      <td id=\"T_1ce53_row0_col4\" class=\"data row0 col4\" >88.9 (86.9, 91.1)</td>\n",
       "      <td id=\"T_1ce53_row0_col5\" class=\"data row0 col5\" >88.1 (85.9, 90.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row1_col0\" class=\"data row1 col0\" >da_dacy_large_trf-0.2.0</td>\n",
       "      <td id=\"T_1ce53_row1_col1\" class=\"data row1 col1\" >85.4 (81.2, 88.9)</td>\n",
       "      <td id=\"T_1ce53_row1_col2\" class=\"data row1 col2\" >87.7 (85.2, 90.4)</td>\n",
       "      <td id=\"T_1ce53_row1_col3\" class=\"data row1 col3\" >87.8 (85.2, 90.2)</td>\n",
       "      <td id=\"T_1ce53_row1_col4\" class=\"data row1 col4\" >87.5 (84.3, 90.3)</td>\n",
       "      <td id=\"T_1ce53_row1_col5\" class=\"data row1 col5\" >85.6 (82.9, 88.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row2_col0\" class=\"data row2 col0\" >da_dacy_medium_trf-0.2.0</td>\n",
       "      <td id=\"T_1ce53_row2_col1\" class=\"data row2 col1\" >84.9 (81.0, 88.5)</td>\n",
       "      <td id=\"T_1ce53_row2_col2\" class=\"data row2 col2\" >86.2 (83.9, 88.8)</td>\n",
       "      <td id=\"T_1ce53_row2_col3\" class=\"data row2 col3\" >86.1 (83.8, 89.1)</td>\n",
       "      <td id=\"T_1ce53_row2_col4\" class=\"data row2 col4\" >86.1 (83.6, 89.2)</td>\n",
       "      <td id=\"T_1ce53_row2_col5\" class=\"data row2 col5\" >84.2 (81.7, 87.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row3_col0\" class=\"data row3 col0\" >da_dacy_small_trf-0.2.0</td>\n",
       "      <td id=\"T_1ce53_row3_col1\" class=\"data row3 col1\" >82.7 (79.3, 85.9)</td>\n",
       "      <td id=\"T_1ce53_row3_col2\" class=\"data row3 col2\" >82.4 (79.6, 85.3)</td>\n",
       "      <td id=\"T_1ce53_row3_col3\" class=\"data row3 col3\" >82.2 (79.9, 84.7)</td>\n",
       "      <td id=\"T_1ce53_row3_col4\" class=\"data row3 col4\" >82.1 (79.2, 85.2)</td>\n",
       "      <td id=\"T_1ce53_row3_col5\" class=\"data row3 col5\" >81.2 (78.6, 83.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row4_col0\" class=\"data row4 col0\" >alexandrainst/da-ner-base</td>\n",
       "      <td id=\"T_1ce53_row4_col1\" class=\"data row4 col1\" >70.7 (66.2, 75.2)</td>\n",
       "      <td id=\"T_1ce53_row4_col2\" class=\"data row4 col2\" >81.5 (78.2, 84.4)</td>\n",
       "      <td id=\"T_1ce53_row4_col3\" class=\"data row4 col3\" >81.6 (78.3, 84.4)</td>\n",
       "      <td id=\"T_1ce53_row4_col4\" class=\"data row4 col4\" >81.5 (78.2, 84.4)</td>\n",
       "      <td id=\"T_1ce53_row4_col5\" class=\"data row4 col5\" >79.8 (76.7, 82.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row5_col0\" class=\"data row5 col0\" >da_core_news_trf-3.5.0</td>\n",
       "      <td id=\"T_1ce53_row5_col1\" class=\"data row5 col1\" >79.0 (75.1, 82.3)</td>\n",
       "      <td id=\"T_1ce53_row5_col2\" class=\"data row5 col2\" >80.7 (77.2, 83.1)</td>\n",
       "      <td id=\"T_1ce53_row5_col3\" class=\"data row5 col3\" >80.9 (78.1, 83.8)</td>\n",
       "      <td id=\"T_1ce53_row5_col4\" class=\"data row5 col4\" >80.6 (77.3, 83.8)</td>\n",
       "      <td id=\"T_1ce53_row5_col5\" class=\"data row5 col5\" >78.7 (75.8, 81.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row6_col0\" class=\"data row6 col0\" >da_core_news_lg-3.5.0</td>\n",
       "      <td id=\"T_1ce53_row6_col1\" class=\"data row6 col1\" >74.6 (70.8, 78.1)</td>\n",
       "      <td id=\"T_1ce53_row6_col2\" class=\"data row6 col2\" >78.3 (75.5, 80.7)</td>\n",
       "      <td id=\"T_1ce53_row6_col3\" class=\"data row6 col3\" >78.5 (75.9, 81.1)</td>\n",
       "      <td id=\"T_1ce53_row6_col4\" class=\"data row6 col4\" >78.4 (75.4, 81.2)</td>\n",
       "      <td id=\"T_1ce53_row6_col5\" class=\"data row6 col5\" >68.2 (65.4, 71.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row7_col0\" class=\"data row7 col0\" >da_core_news_md-3.5.0</td>\n",
       "      <td id=\"T_1ce53_row7_col1\" class=\"data row7 col1\" >71.2 (66.9, 75.2)</td>\n",
       "      <td id=\"T_1ce53_row7_col2\" class=\"data row7 col2\" >75.7 (71.9, 78.7)</td>\n",
       "      <td id=\"T_1ce53_row7_col3\" class=\"data row7 col3\" >75.6 (72.2, 79.1)</td>\n",
       "      <td id=\"T_1ce53_row7_col4\" class=\"data row7 col4\" >75.5 (72.3, 78.9)</td>\n",
       "      <td id=\"T_1ce53_row7_col5\" class=\"data row7 col5\" >64.6 (60.5, 68.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1ce53_row8_col0\" class=\"data row8 col0\" >da_core_news_sm-3.5.0</td>\n",
       "      <td id=\"T_1ce53_row8_col1\" class=\"data row8 col1\" >64.4 (59.7, 68.5)</td>\n",
       "      <td id=\"T_1ce53_row8_col2\" class=\"data row8 col2\" >58.8 (55.5, 62.0)</td>\n",
       "      <td id=\"T_1ce53_row8_col3\" class=\"data row8 col3\" >59.1 (56.2, 62.6)</td>\n",
       "      <td id=\"T_1ce53_row8_col4\" class=\"data row8 col4\" >59.1 (56.4, 62.3)</td>\n",
       "      <td id=\"T_1ce53_row8_col5\" class=\"data row8 col5\" >53.4 (50.2, 56.4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17bc48e50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table(df, model_order=list(gbiases.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper *'DaCy: A Unified Framework for Danish NLP'* {cite}`enevoldsen2021dacy` we conducted a series on augmentation on the DaNE test set to estimate the robustness and biases of DaCy and other Danish language processing pipelines. This page represents only parts of the paper. We recommend reading the paper for a more thorough and nuanced overview.\n",
    "\n",
    "The augmentation we will be using in this test are performed on the DaNE test set and include the following:\n",
    "\n",
    "- **Spelling Error**: Intended to similar domains with inconsistent spelling, OCR errors, conversational data, etc.. The augmentation includes a series of smaller augmentation:\n",
    "  - Keystroke error: The augmentation is used to introduce errors by replacing a character with a character that is close on the keyboard.\n",
    "  - Character swap: The augmentation is used to introduce errors by swapping two neighboring characters.\n",
    "  - Token swap: The augmentation is used to introduce errors by swapping two neighboring tokens.\n",
    "- **Inconsistent Casing**: This augmentation is used to simulate inconsistent casing in the language and uses two different methods by either randomly capitalizing or lowercasing tokens.\n",
    "- **Synonym Augmentation**: This augmentation is used to simulate the variation and slight grammatical errors in the language and uses two different methods:\n",
    "  - Wordnet Synonym replacement: The augmentation replaces a token with a synonym in WordNet while respecting its syntactic role.\n",
    "  - Embedding Synonym replacement: This augmentation replaces a token with a synonym which tends to appear in similar contexts.\n",
    "- **Inconsistent Spacing**: This augmentation is used to simulate inconsistent spacing in the language and uses two different methods by either randomly adding or removing spaces.\n",
    "- **Historical Spelling**: This augmentation is used to simulate historical spelling in Danish including ASCII spellings of the letters Æ (Ae), Ø (Oe), and Å (Aa) as well as uppercasing nouns.\n",
    "\n",
    "For all of the augmentations the probability of an augmentation is set to augment 5% of the spaces where the targeted augmentation can take place. The augmentations are performed using the [augmenty](https://kennethenevoldsen.github.io/augmenty/index.html).\n",
    "\n",
    "The underlying assumption of making these augmentations is that the annotations of the tokens do not change with augmentation. This can naturally sometimes be the case. A single letter *\"hun læste gåden\"* (*she read the puzzle*) and *\"hun løste gåden\"* (*she solved the puzzle*) have quite a different meaning. So while we expect the performance to drop the degree of the drop is interesting to examine and often in comparison to the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robustness_dane (test): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "robustness_dane (test): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "robustness_dane (test): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "robustness_dane (test): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "robustness_dane (test): Loading prediction for alexandrainst/da-ner-base\n",
      "robustness_dane (test): Loading prediction for da_core_news_trf-3.5.0\n",
      "robustness_dane (test): Loading prediction for da_core_news_lg-3.5.0\n",
      "robustness_dane (test): Loading prediction for da_core_news_md-3.5.0\n",
      "robustness_dane (test): Loading prediction for da_core_news_sm-3.5.0\n"
     ]
    }
   ],
   "source": [
    "robustness = {}\n",
    "for mdl_name, model_getter in MODELS.items():\n",
    "    if \"fine_grained\" in mdl_name:\n",
    "        continue\n",
    "    mdl_results = apply_models(\n",
    "        mdl_name, model_getter, dataset=\"robustness_dane\", splits=[\"test\"]\n",
    "    )\n",
    "    robustness[mdl_name] = mdl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saattrupdan/nbailab-base-ner-scandi\n",
      "da_dacy_large_trf-0.2.0\n",
      "da_dacy_medium_trf-0.2.0\n",
      "da_dacy_small_trf-0.2.0\n",
      "alexandrainst/da-ner-base\n",
      "da_core_news_trf-3.5.0\n",
      "da_core_news_lg-3.5.0\n",
      "da_core_news_md-3.5.0\n",
      "da_core_news_sm-3.5.0\n"
     ]
    }
   ],
   "source": [
    "tables = []\n",
    "for mdl in robustness:\n",
    "    print(mdl)\n",
    "    examples = robustness[mdl][\"test\"][\"examples\"]\n",
    "\n",
    "    aug_group = augmentation_specific_examples(examples)\n",
    "    for aug_name, _examples in aug_group.items():\n",
    "        _examples = convert_to_conll_2003(_examples) # also removes misc.\n",
    "        table = create_dataframe(_examples, mdl, n_rep=100, n_samples=1000)\n",
    "        table[\"Augmentation\"] = aug_name\n",
    "        tables.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0a31 .level0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f0a31 .col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f0a31_row0_col1, #T_f0a31_row0_col4, #T_f0a31_row0_col5, #T_f0a31_row0_col6, #T_f0a31_row1_col2, #T_f0a31_row1_col3 {\n",
       "  font-weight: bold;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_f0a31_row0_col2, #T_f0a31_row0_col3, #T_f0a31_row1_col1, #T_f0a31_row1_col6, #T_f0a31_row2_col4, #T_f0a31_row2_col5 {\n",
       "  text-decoration: underline;\n",
       "  text-align: right;\n",
       "}\n",
       "#T_f0a31_row1_col4, #T_f0a31_row1_col5, #T_f0a31_row2_col1, #T_f0a31_row2_col2, #T_f0a31_row2_col3, #T_f0a31_row2_col6, #T_f0a31_row3_col1, #T_f0a31_row3_col2, #T_f0a31_row3_col3, #T_f0a31_row3_col4, #T_f0a31_row3_col5, #T_f0a31_row3_col6, #T_f0a31_row4_col1, #T_f0a31_row4_col2, #T_f0a31_row4_col3, #T_f0a31_row4_col4, #T_f0a31_row4_col5, #T_f0a31_row4_col6, #T_f0a31_row5_col1, #T_f0a31_row5_col2, #T_f0a31_row5_col3, #T_f0a31_row5_col4, #T_f0a31_row5_col5, #T_f0a31_row5_col6, #T_f0a31_row6_col1, #T_f0a31_row6_col2, #T_f0a31_row6_col3, #T_f0a31_row6_col4, #T_f0a31_row6_col5, #T_f0a31_row6_col6, #T_f0a31_row7_col1, #T_f0a31_row7_col2, #T_f0a31_row7_col3, #T_f0a31_row7_col4, #T_f0a31_row7_col5, #T_f0a31_row7_col6, #T_f0a31_row8_col1, #T_f0a31_row8_col2, #T_f0a31_row8_col3, #T_f0a31_row8_col4, #T_f0a31_row8_col5, #T_f0a31_row8_col6 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0a31\" style=\"font-size: 0.65em\">\n",
       "  <caption>F1 score for each augmentation with 95% confidence interval calculated over 100 repetitions</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a31_level0_col0\" class=\"col_heading level0 col0\" >Models</th>\n",
       "      <th id=\"T_f0a31_level0_col1\" class=\"col_heading level0 col1\" ></th>\n",
       "      <th id=\"T_f0a31_level0_col2\" class=\"col_heading level0 col2\" colspan=\"5\">Augmentation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a31_level1_col0\" class=\"col_heading level1 col0\" ></th>\n",
       "      <th id=\"T_f0a31_level1_col1\" class=\"col_heading level1 col1\" >Baseline</th>\n",
       "      <th id=\"T_f0a31_level1_col2\" class=\"col_heading level1 col2\" >Historical Spelling</th>\n",
       "      <th id=\"T_f0a31_level1_col3\" class=\"col_heading level1 col3\" >Inconsistent Casing</th>\n",
       "      <th id=\"T_f0a31_level1_col4\" class=\"col_heading level1 col4\" >Inconsistent Spacing</th>\n",
       "      <th id=\"T_f0a31_level1_col5\" class=\"col_heading level1 col5\" >Spelling Error</th>\n",
       "      <th id=\"T_f0a31_level1_col6\" class=\"col_heading level1 col6\" >Synonym replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row0_col0\" class=\"data row0 col0\" >saattrupdan/nbailab-base-ner-scandi</td>\n",
       "      <td id=\"T_f0a31_row0_col1\" class=\"data row0 col1\" >86.3 (82.4, 89.7)</td>\n",
       "      <td id=\"T_f0a31_row0_col2\" class=\"data row0 col2\" >81.9 (79.1, 85.0)</td>\n",
       "      <td id=\"T_f0a31_row0_col3\" class=\"data row0 col3\" >86.5 (84.4, 89.0)</td>\n",
       "      <td id=\"T_f0a31_row0_col4\" class=\"data row0 col4\" >78.8 (75.7, 81.6)</td>\n",
       "      <td id=\"T_f0a31_row0_col5\" class=\"data row0 col5\" >73.3 (69.9, 76.8)</td>\n",
       "      <td id=\"T_f0a31_row0_col6\" class=\"data row0 col6\" >87.1 (84.9, 89.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row1_col0\" class=\"data row1 col0\" >da_dacy_large_trf-0.2.0</td>\n",
       "      <td id=\"T_f0a31_row1_col1\" class=\"data row1 col1\" >85.4 (81.2, 88.9)</td>\n",
       "      <td id=\"T_f0a31_row1_col2\" class=\"data row1 col2\" >86.0 (82.8, 88.9)</td>\n",
       "      <td id=\"T_f0a31_row1_col3\" class=\"data row1 col3\" >86.9 (83.9, 89.4)</td>\n",
       "      <td id=\"T_f0a31_row1_col4\" class=\"data row1 col4\" >69.7 (66.4, 72.4)</td>\n",
       "      <td id=\"T_f0a31_row1_col5\" class=\"data row1 col5\" >59.7 (56.4, 63.9)</td>\n",
       "      <td id=\"T_f0a31_row1_col6\" class=\"data row1 col6\" >85.9 (82.9, 88.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row2_col0\" class=\"data row2 col0\" >da_dacy_medium_trf-0.2.0</td>\n",
       "      <td id=\"T_f0a31_row2_col1\" class=\"data row2 col1\" >84.9 (81.0, 88.5)</td>\n",
       "      <td id=\"T_f0a31_row2_col2\" class=\"data row2 col2\" >69.6 (66.7, 72.1)</td>\n",
       "      <td id=\"T_f0a31_row2_col3\" class=\"data row2 col3\" >83.7 (81.3, 86.3)</td>\n",
       "      <td id=\"T_f0a31_row2_col4\" class=\"data row2 col4\" >70.5 (66.6, 74.0)</td>\n",
       "      <td id=\"T_f0a31_row2_col5\" class=\"data row2 col5\" >65.4 (62.6, 68.5)</td>\n",
       "      <td id=\"T_f0a31_row2_col6\" class=\"data row2 col6\" >85.1 (82.5, 88.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row3_col0\" class=\"data row3 col0\" >da_dacy_small_trf-0.2.0</td>\n",
       "      <td id=\"T_f0a31_row3_col1\" class=\"data row3 col1\" >82.7 (79.3, 85.9)</td>\n",
       "      <td id=\"T_f0a31_row3_col2\" class=\"data row3 col2\" >51.7 (49.1, 54.6)</td>\n",
       "      <td id=\"T_f0a31_row3_col3\" class=\"data row3 col3\" >81.1 (78.6, 83.5)</td>\n",
       "      <td id=\"T_f0a31_row3_col4\" class=\"data row3 col4\" >64.3 (60.4, 67.2)</td>\n",
       "      <td id=\"T_f0a31_row3_col5\" class=\"data row3 col5\" >63.1 (59.9, 66.5)</td>\n",
       "      <td id=\"T_f0a31_row3_col6\" class=\"data row3 col6\" >83.4 (81.0, 85.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row4_col0\" class=\"data row4 col0\" >alexandrainst/da-ner-base</td>\n",
       "      <td id=\"T_f0a31_row4_col1\" class=\"data row4 col1\" >70.7 (66.2, 75.2)</td>\n",
       "      <td id=\"T_f0a31_row4_col2\" class=\"data row4 col2\" >78.7 (75.3, 81.6)</td>\n",
       "      <td id=\"T_f0a31_row4_col3\" class=\"data row4 col3\" >80.8 (77.6, 83.2)</td>\n",
       "      <td id=\"T_f0a31_row4_col4\" class=\"data row4 col4\" >63.4 (59.4, 66.3)</td>\n",
       "      <td id=\"T_f0a31_row4_col5\" class=\"data row4 col5\" >49.9 (47.3, 53.6)</td>\n",
       "      <td id=\"T_f0a31_row4_col6\" class=\"data row4 col6\" >80.1 (77.1, 82.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row5_col0\" class=\"data row5 col0\" >da_core_news_trf-3.5.0</td>\n",
       "      <td id=\"T_f0a31_row5_col1\" class=\"data row5 col1\" >79.0 (75.1, 82.3)</td>\n",
       "      <td id=\"T_f0a31_row5_col2\" class=\"data row5 col2\" >75.1 (72.4, 77.3)</td>\n",
       "      <td id=\"T_f0a31_row5_col3\" class=\"data row5 col3\" >81.3 (78.5, 84.1)</td>\n",
       "      <td id=\"T_f0a31_row5_col4\" class=\"data row5 col4\" >58.9 (55.8, 62.3)</td>\n",
       "      <td id=\"T_f0a31_row5_col5\" class=\"data row5 col5\" >41.2 (38.5, 44.0)</td>\n",
       "      <td id=\"T_f0a31_row5_col6\" class=\"data row5 col6\" >80.4 (77.6, 83.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row6_col0\" class=\"data row6 col0\" >da_core_news_lg-3.5.0</td>\n",
       "      <td id=\"T_f0a31_row6_col1\" class=\"data row6 col1\" >74.6 (70.8, 78.1)</td>\n",
       "      <td id=\"T_f0a31_row6_col2\" class=\"data row6 col2\" >47.0 (44.5, 49.7)</td>\n",
       "      <td id=\"T_f0a31_row6_col3\" class=\"data row6 col3\" >74.5 (71.6, 77.7)</td>\n",
       "      <td id=\"T_f0a31_row6_col4\" class=\"data row6 col4\" >51.1 (48.1, 53.8)</td>\n",
       "      <td id=\"T_f0a31_row6_col5\" class=\"data row6 col5\" >44.9 (42.0, 47.9)</td>\n",
       "      <td id=\"T_f0a31_row6_col6\" class=\"data row6 col6\" >76.3 (73.6, 79.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row7_col0\" class=\"data row7 col0\" >da_core_news_md-3.5.0</td>\n",
       "      <td id=\"T_f0a31_row7_col1\" class=\"data row7 col1\" >71.2 (66.9, 75.2)</td>\n",
       "      <td id=\"T_f0a31_row7_col2\" class=\"data row7 col2\" >48.7 (45.7, 51.6)</td>\n",
       "      <td id=\"T_f0a31_row7_col3\" class=\"data row7 col3\" >71.6 (68.2, 75.4)</td>\n",
       "      <td id=\"T_f0a31_row7_col4\" class=\"data row7 col4\" >51.1 (47.6, 54.3)</td>\n",
       "      <td id=\"T_f0a31_row7_col5\" class=\"data row7 col5\" >41.8 (38.8, 44.7)</td>\n",
       "      <td id=\"T_f0a31_row7_col6\" class=\"data row7 col6\" >72.8 (69.2, 76.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f0a31_row8_col0\" class=\"data row8 col0\" >da_core_news_sm-3.5.0</td>\n",
       "      <td id=\"T_f0a31_row8_col1\" class=\"data row8 col1\" >64.4 (59.7, 68.5)</td>\n",
       "      <td id=\"T_f0a31_row8_col2\" class=\"data row8 col2\" >31.9 (29.6, 34.1)</td>\n",
       "      <td id=\"T_f0a31_row8_col3\" class=\"data row8 col3\" >61.5 (58.1, 64.6)</td>\n",
       "      <td id=\"T_f0a31_row8_col4\" class=\"data row8 col4\" >46.6 (43.7, 50.4)</td>\n",
       "      <td id=\"T_f0a31_row8_col5\" class=\"data row8 col5\" >49.6 (46.5, 53.0)</td>\n",
       "      <td id=\"T_f0a31_row8_col6\" class=\"data row8 col6\" >64.8 (61.4, 68.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f49c7cd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_df = pd.concat(tables)\n",
    "\n",
    "create_table(robustness_df, model_order=list(robustness.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Speed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While performance naturally is important is it also important to know why you might choose one model over another. One of the main reasons for choosing a smaller model is inference speed. The following table shows the inference speed of the different models. The inference speed is measured in words per second (WPS) and is measured on a Apple M1 Pro 16Gb running macOS 13.3.1 (i.e. high-end consumer laptop). The models are tested on the test set of DaNE.\n",
    "\n",
    "```{admonition} GPU Acceleration\n",
    ":class: note\n",
    "\n",
    "These benchmarks does not use GPU acceleration. If you were to use GPU acceleration the inference speed would be much higher, similarly larger models would benefit more from this acceleration.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dane (test): Loading prediction for saattrupdan/nbailab-base-ner-scandi\n",
      "dane (test): Loading prediction for da_dacy_large_trf-0.2.0\n",
      "dane (test): Loading prediction for da_dacy_medium_trf-0.2.0\n",
      "dane (test): Loading prediction for da_dacy_small_trf-0.2.0\n",
      "dane (test): Loading prediction for da_dacy_large_ner_fine_grained-0.1.0\n",
      "dane (test): Loading prediction for da_dacy_medium_ner_fine_grained-0.1.0\n",
      "dane (test): Loading prediction for da_dacy_small_ner_fine_grained-0.1.0\n",
      "dane (test): Loading prediction for alexandrainst/da-ner-base\n",
      "dane (test): Loading prediction for da_core_news_trf-3.5.0\n",
      "dane (test): Loading prediction for da_core_news_lg-3.5.0\n",
      "dane (test): Loading prediction for da_core_news_md-3.5.0\n",
      "dane (test): Loading prediction for da_core_news_sm-3.5.0\n"
     ]
    }
   ],
   "source": [
    "dane = {}\n",
    "for mdl_name, model_getter in MODELS.items():\n",
    "    mdl_results = apply_models(mdl_name, model_getter, dataset=\"dane\", splits=[\"test\"])\n",
    "    dane[mdl_name] = mdl_results[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "n_words = None\n",
    "for mdl_name, model_getter in MODELS.items():\n",
    "    total_time = dane[mdl_name][\"time_in_seconds\"]\n",
    "    if n_words is None:\n",
    "        examples = dane[mdl_name][\"examples\"]\n",
    "        n_words = sum(len(e.y) for e in examples)\n",
    "    wps = n_words / total_time\n",
    "    rows.append({\"Model\": mdl_name, \"Words per second\": wps, \"Total time (sec)\": total_time})\n",
    "\n",
    "speed = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de718_row0_col0, #T_de718_row1_col0, #T_de718_row2_col0, #T_de718_row3_col0, #T_de718_row4_col0, #T_de718_row5_col0, #T_de718_row6_col0, #T_de718_row7_col0, #T_de718_row8_col0, #T_de718_row9_col0, #T_de718_row10_col0, #T_de718_row11_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_de718_row0_col1, #T_de718_row0_col2, #T_de718_row1_col1, #T_de718_row1_col2, #T_de718_row2_col1, #T_de718_row2_col2, #T_de718_row3_col1, #T_de718_row3_col2, #T_de718_row4_col1, #T_de718_row4_col2, #T_de718_row5_col1, #T_de718_row5_col2, #T_de718_row6_col1, #T_de718_row6_col2, #T_de718_row7_col1, #T_de718_row7_col2, #T_de718_row8_col1, #T_de718_row8_col2, #T_de718_row9_col1, #T_de718_row9_col2, #T_de718_row10_col1, #T_de718_row10_col2 {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_de718_row11_col1, #T_de718_row11_col2 {\n",
       "  font-weight: bold;\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de718\">\n",
       "  <caption>Inference speed on DANE test set</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_de718_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_de718_level0_col1\" class=\"col_heading level0 col1\" >Words per second</th>\n",
       "      <th id=\"T_de718_level0_col2\" class=\"col_heading level0 col2\" >Total time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row0_col0\" class=\"data row0 col0\" >saattrupdan/nbailab-base-ner-scandi</td>\n",
       "      <td id=\"T_de718_row0_col1\" class=\"data row0 col1\" >1438.8</td>\n",
       "      <td id=\"T_de718_row0_col2\" class=\"data row0 col2\" >6.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row1_col0\" class=\"data row1 col0\" >da_dacy_large_trf-0.2.0</td>\n",
       "      <td id=\"T_de718_row1_col1\" class=\"data row1 col1\" >353.3</td>\n",
       "      <td id=\"T_de718_row1_col2\" class=\"data row1 col2\" >28.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row2_col0\" class=\"data row2 col0\" >da_dacy_medium_trf-0.2.0</td>\n",
       "      <td id=\"T_de718_row2_col1\" class=\"data row2 col1\" >770.2</td>\n",
       "      <td id=\"T_de718_row2_col2\" class=\"data row2 col2\" >13.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row3_col0\" class=\"data row3 col0\" >da_dacy_small_trf-0.2.0</td>\n",
       "      <td id=\"T_de718_row3_col1\" class=\"data row3 col1\" >2024.6</td>\n",
       "      <td id=\"T_de718_row3_col2\" class=\"data row3 col2\" >4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row4_col0\" class=\"data row4 col0\" >da_dacy_large_ner_fine_grained-0.1.0</td>\n",
       "      <td id=\"T_de718_row4_col1\" class=\"data row4 col1\" >567.9</td>\n",
       "      <td id=\"T_de718_row4_col2\" class=\"data row4 col2\" >17.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row5_col0\" class=\"data row5 col0\" >da_dacy_medium_ner_fine_grained-0.1.0</td>\n",
       "      <td id=\"T_de718_row5_col1\" class=\"data row5 col1\" >1670.3</td>\n",
       "      <td id=\"T_de718_row5_col2\" class=\"data row5 col2\" >6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row6_col0\" class=\"data row6 col0\" >da_dacy_small_ner_fine_grained-0.1.0</td>\n",
       "      <td id=\"T_de718_row6_col1\" class=\"data row6 col1\" >5717.6</td>\n",
       "      <td id=\"T_de718_row6_col2\" class=\"data row6 col2\" >1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row7_col0\" class=\"data row7 col0\" >alexandrainst/da-ner-base</td>\n",
       "      <td id=\"T_de718_row7_col1\" class=\"data row7 col1\" >1618.7</td>\n",
       "      <td id=\"T_de718_row7_col2\" class=\"data row7 col2\" >6.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row8_col0\" class=\"data row8 col0\" >da_core_news_trf-3.5.0</td>\n",
       "      <td id=\"T_de718_row8_col1\" class=\"data row8 col1\" >1125.1</td>\n",
       "      <td id=\"T_de718_row8_col2\" class=\"data row8 col2\" >8.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row9_col0\" class=\"data row9 col0\" >da_core_news_lg-3.5.0</td>\n",
       "      <td id=\"T_de718_row9_col1\" class=\"data row9 col1\" >31364.7</td>\n",
       "      <td id=\"T_de718_row9_col2\" class=\"data row9 col2\" >0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row10_col0\" class=\"data row10 col0\" >da_core_news_md-3.5.0</td>\n",
       "      <td id=\"T_de718_row10_col1\" class=\"data row10 col1\" >32571.3</td>\n",
       "      <td id=\"T_de718_row10_col2\" class=\"data row10 col2\" >0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_de718_row11_col0\" class=\"data row11 col0\" >da_core_news_sm-3.5.0</td>\n",
       "      <td id=\"T_de718_row11_col1\" class=\"data row11 col1\" >34624.4</td>\n",
       "      <td id=\"T_de718_row11_col2\" class=\"data row11 col2\" >0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a5a6e950>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the table\n",
    "style = speed.style.set_caption(\"Inference speed on DANE test set\")\n",
    "\n",
    "\n",
    "def highlight_min(s):\n",
    "    \"\"\"highlight the minimum in a series with bold\"\"\"\n",
    "    is_min = s == s.min()\n",
    "    return [\"font-weight: bold\" if v else \"\" for v in is_min]\n",
    "\n",
    "def highlight_max(s):\n",
    "    \"\"\"highlight the minimum in a series with bold\"\"\"\n",
    "    is_max = s == s.max()\n",
    "    return [\"font-weight: bold\" if v else \"\" for v in is_max]\n",
    "\n",
    "style= style.apply(highlight_min, axis=0, subset=[\"Total time (sec)\"])\n",
    "style = style.apply(highlight_max, axis=0, subset=[\"Words per second\"])\n",
    "\n",
    "style = style.set_properties(subset=[\"Words per second\", \"Total time (sec)\"], **{\"text-align\": \"right\"})\n",
    "# set decimal places\n",
    "style = style.format({\"Words per second\": \"{:.1f}\", \"Total time (sec)\": \"{:.2f}\"})\n",
    "\n",
    "style = style.hide(axis=\"index\")\n",
    "style = style.set_properties(subset=[\"Model\"], **{\"text-align\": \"left\"})\n",
    "style\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that the `da_dacy_{size}_trf-{version}` models from DaCy and the `da_core_news_{size}-{version}` models from spaCy are multi-task models so performs multiple tasks at once. This means that the inference speed is not directly comparable to the other models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography} references.bib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
