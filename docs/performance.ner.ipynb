{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases\n",
    "\n",
    "To examine the biases in Danish models we use augmentation to replace names in the Danish dataset DaNE {cite}`hvingelby2020dane`, this approach\n",
    "is similar to that introduced in the initial DaCy paper {cite}`enevoldsen2021dacy`.\n",
    "\n",
    "Here is a short example of how the augmentation might look like:\n",
    "\n",
    "\n",
    "````{admonition} Example\n",
    "\n",
    "```{admonition} Original\n",
    ":class: note\n",
    "\n",
    "\n",
    "Peter Schmeichel mener også, at det danske landshold anno 2021 tilhører verdenstoppen og kan vinde den kommende kamp mod England.\n",
    "```\n",
    "\n",
    "```{admonition} Female name augmentation\n",
    ":class: important\n",
    "\n",
    "Anne Østergaard mener også, at det danske landshold anno 2021 tilhører verdenstoppen og kan vinde den kommende kamp mod England.\n",
    "```\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e0e76 .level0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_e0e76_row0_col0, #T_e0e76_row1_col0, #T_e0e76_row2_col0, #T_e0e76_row3_col0, #T_e0e76_row4_col0, #T_e0e76_row5_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e0e76_row1_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e0e76\">\n",
       "  <caption>F1 scores for the different models and augmenters</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_e0e76_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e0e76_level1_col0\" class=\"col_heading level1 col0\" >Model</th>\n",
       "      <th id=\"T_e0e76_level1_col1\" class=\"col_heading level1 col1\" >Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e0e76_row0_col0\" class=\"data row0 col0\" >alexandrainst/da-ner-base</td>\n",
       "      <td id=\"T_e0e76_row0_col1\" class=\"data row0 col1\" >70.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0e76_row1_col0\" class=\"data row1 col0\" >saattrupdan/nbailab-base-ner-scandi</td>\n",
       "      <td id=\"T_e0e76_row1_col1\" class=\"data row1 col1\" >86.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0e76_row2_col0\" class=\"data row2 col0\" >spaCy (da_core_news_lg)</td>\n",
       "      <td id=\"T_e0e76_row2_col1\" class=\"data row2 col1\" >74.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0e76_row3_col0\" class=\"data row3 col0\" >spaCy (da_core_news_md)</td>\n",
       "      <td id=\"T_e0e76_row3_col1\" class=\"data row3 col1\" >71.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0e76_row4_col0\" class=\"data row4 col0\" >spaCy (da_core_news_sm)</td>\n",
       "      <td id=\"T_e0e76_row4_col1\" class=\"data row4 col1\" >64.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e0e76_row5_col0\" class=\"data row5 col0\" >spaCy (da_core_news_trf)</td>\n",
       "      <td id=\"T_e0e76_row5_col1\" class=\"data row5 col1\" >78.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17566bfd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import dacy\n",
    "from dacy.datasets import dane\n",
    "from ner_biases_utils import apply_models, create_table, get_augmenters\n",
    "import spacy_wrap\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# augmenters = get_augmenters()\n",
    "augmenters = []\n",
    "\n",
    "# if csv already exists, load it\n",
    "save_path = Path('./tables/ner_bias_results.csv')\n",
    "if save_path.exists():\n",
    "    result_df = pd.read_csv(save_path)\n",
    "else:\n",
    "    # !spacy download da_core_news_sm\n",
    "    # !spacy download da_core_news_md\n",
    "    # !spacy download da_core_news_lg\n",
    "    # !spacy download da_core_news_trf\n",
    "    sp_sm = spacy.load(\"da_core_news_sm\")\n",
    "    sp_md = spacy.load(\"da_core_news_md\")\n",
    "    sp_lg = spacy.load(\"da_core_news_lg\")\n",
    "    sp_trf = spacy.load(\"da_core_news_trf\")\n",
    "    # dacy_sm = dacy.load(\"da_dacy_small_trf-0.2.0\")\n",
    "    # dacy_md = dacy.load(\"da_dacy_medium_trf-0.2.0\")\n",
    "    # dacy_lg = dacy.load(\"da_dacy_large_trf-0.2.0\")\n",
    "    # dacy_fg_ner_sm = dacy.load('da_dacy_small_ner_fine_grained-0.1.0')\n",
    "    # dacy_fg_ner_md = dacy.load('da_dacy_medium_ner_fine_grained-0.1.0')\n",
    "    # dacy_fg_ner_lg = dacy.load('da_dacy_large_ner_fine_grained-0.1.0')\n",
    "\n",
    "    daner_base = spacy.blank(\"da\")\n",
    "    config = {\"model\": {\"name\": \"alexandrainst/da-ner-base\"}, \"predictions_to\": [\"ents\"]}\n",
    "    daner_base.add_pipe(\"token_classification_transformer\", config=config)\n",
    "\n",
    "    scandiner = spacy.blank(\"da\")\n",
    "    scandiner.add_pipe(\"dacy/ner\")\n",
    "\n",
    "    models = [\n",
    "        (\"spaCy (da_core_news_sm)\", sp_sm),\n",
    "        (\"spaCy (da_core_news_md)\", sp_md),\n",
    "        (\"spaCy (da_core_news_lg)\", sp_lg),\n",
    "        (\"spaCy (da_core_news_trf)\", sp_trf),\n",
    "        # (\"DaCy (da_dacy_small_trf-0.2.0)\", dacy_sm),\n",
    "        # (\"DaCy (da_dacy_medium_trf-0.2.0)\", dacy_md),\n",
    "        # (\"DaCy (da_dacy_large_trf-0.2.0)\", dacy_lg),\n",
    "        # (\"DaCy (da_dacy_small_ner_fine_grained-0.1.0)\", dacy_fg_ner_sm),\n",
    "        # (\"DaCy (da_dacy_medium_ner_fine_grained-0.1.0)\", dacy_fg_ner_md),\n",
    "        # (\"DaCy (da_dacy_large_ner_fine_grained-0.1.0)\", dacy_fg_ner_lg),\n",
    "        (\"alexandrainst/da-ner-base\", daner_base),\n",
    "        (\"saattrupdan/nbailab-base-ner-scandi\", scandiner),\n",
    "    ]\n",
    "\n",
    "    dataset = dane(splits=\"test\")\n",
    "    result_df = apply_models(models, dataset, augmenters, n_rep=20)\n",
    "    # save to csv\n",
    "    result_df.to_csv('ner_results.csv')\n",
    "\n",
    "s = create_table(result_df, augmenters)\n",
    "s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization\n",
    "To examine model generalization, we utilize the [DANSK](https://huggingface.co/datasets/chcaa/DANSK) dataset. This dataset is annotated across many different domains including fiction, web content, social media, wikis, news, legal and conversational data. The original dataset includes annotations corresponding to the ontonotes standard (see [getting started](https://centre-for-humanities-computing.github.io/DaCy/tutorials/basic.html#fine-grained-ner) for the full list). To test the generalization we here convert the annotations to the CoNLL-2003 format using the labels `Person`, `Location`, `Organization`. As CoNLL-2003, `Location` includes cities, roads, mountains, abstract places, specific buildings, and meeting points. Thus the `GPE` (geo-political entity) were converted to `Location`. The `MISC` category in CoNLL-2003 is a diverse category meant to denote all names not in other categories (encapsulating both e.g. events and adjectives such as ”2004 World Cup” and ”Italian”), and is therefore not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install altair\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from typing import List, Optional\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "nlp = spacy.blank(\"da\")\n",
    "\n",
    "def dansk(splits: Optional[List[str]]= None, **kwargs):\n",
    "    if splits is None:\n",
    "        splits = [\"train\", \"dev\", \"test\"]\n",
    "        \n",
    "    if Doc.has_extension(\"meta\"):\n",
    "        warnings.warn(\"Overwriting existing meta extension\")\n",
    "    Doc.set_extension(\"meta\", default={}, force=True)\n",
    "\n",
    "\n",
    "    nlp = spacy.blank(\"da\")\n",
    "    def convert_to_doc(example):\n",
    "        doc = Doc(nlp.vocab).from_json(example)\n",
    "        # set metadata\n",
    "        for k in ['dagw_source', 'dagw_domain', 'dagw_source_full']:\n",
    "            doc._.meta[k] = example[k]\n",
    "        return doc\n",
    "\n",
    "    return_ds = []\n",
    "    for split in splits:\n",
    "        ds = load_dataset(\"chcaa/DANSK\", split=split, **kwargs)\n",
    "        docs = [convert_to_doc(example) for example in ds]\n",
    "        return_ds.append(docs)\n",
    "    return return_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-f6b5c98c643cd000/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-f6b5c98c643cd000/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/Users/au561649/.cache/huggingface/datasets/chcaa___parquet/chcaa--DANSK-f6b5c98c643cd000/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "train, dev, test = dansk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FACILITY',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOCATION',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORGANIZATION',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK OF ART'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([e.label_ for doc in train for e in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Conll-2003 format\n",
    "def convert_to_conll_2003(docs, mapping={\"PERSON\": \"PER\", \"GPE\": \"LOC\", \"LOCATION\": \"LOC\", \"ORGANIZATION\": \"ORG\"}):\n",
    "    for doc in docs:\n",
    "        ents = doc.ents\n",
    "        ents = [e for e in ents if e.label_ in mapping]\n",
    "        # convert GPE\n",
    "        for ent in ents:\n",
    "            ent.label_ = mapping[ent.label_]\n",
    "        doc.ents = ents\n",
    "\n",
    "convert_to_conll_2003(train)\n",
    "convert_to_conll_2003(dev)\n",
    "convert_to_conll_2003(test)\n",
    "\n",
    "dataset = train + dev + test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set([e.label_ for doc in train for e in doc.ents]) == set([\"PER\", \"LOC\", \"ORG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = {}\n",
    "for doc in dataset:\n",
    "    domain = doc._.meta[\"dagw_domain\"]\n",
    "    if domain not in domains:\n",
    "        domains[domain] = []\n",
    "    domains[domain].append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_sm = spacy.load(\"da_core_news_sm\")\n",
    "sp_lg = spacy.load(\"da_core_news_lg\")\n",
    "\n",
    "mdls = [\n",
    "    (\"spaCy (da_core_news_sm)\", sp_sm),\n",
    "    (\"spaCy (da_core_news_lg)\", sp_lg),\n",
    "]\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "scorer = Scorer()\n",
    "\n",
    "def no_misc_getter(doc, attr):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ != \"MISC\":\n",
    "            yield ent\n",
    "\n",
    "def bootstrap(examples, n_rep=100):\n",
    "    scores = []\n",
    "    for i in range(n_rep):\n",
    "        sample = random.choices(examples, k=len(examples))\n",
    "        score = scorer.score_spans(sample, getter=no_misc_getter, attr=\"ents\")\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def compute_mean_and_ci(scores):\n",
    "\n",
    "    ent_f = [score[\"ents_f\"] for score in scores]\n",
    "    per_f = [score[\"ents_per_type\"].get(\"PER\", {\"f\": None})[\"f\"] for score in scores]\n",
    "    loc_f = [score[\"ents_per_type\"].get(\"LOC\", {\"f\": None})[\"f\"] for score in scores]\n",
    "    org_f = [score[\"ents_per_type\"].get(\"ORG\", {\"f\": None})[\"f\"] for score in scores]\n",
    "\n",
    "    nam = [\"Average F1\", \"Person F1\", \"Location F1\", \"Organization F1\"]\n",
    "\n",
    "    d = {}\n",
    "    for n, f in zip(nam, [ent_f, per_f, loc_f, org_f]):\n",
    "        f = [x for x in f if x is not None]\n",
    "        if len(f) == 0:\n",
    "            d[n] = {\n",
    "                \"mean\": None,\n",
    "                \"ci\": None\n",
    "            }\n",
    "            continue\n",
    "        d[n] = {\n",
    "            \"mean\": np.mean(f),\n",
    "            \"ci\": np.percentile(f, [2.5, 97.5])\n",
    "        }\n",
    "    return d\n",
    "\n",
    "\n",
    "all_examples = {}\n",
    "rows= []\n",
    "for mdl_name, mdl in mdls:\n",
    "    all_examples[mdl_name] = []\n",
    "    for domain in domains:\n",
    "        docs = domains[domain]\n",
    "        model_pred = mdl.pipe([doc.text for doc in docs])\n",
    "        examples = [Example(predicted=x, reference=y) for x, y in zip(model_pred, docs)]\n",
    "        all_examples[mdl_name].extend(examples)\n",
    "\n",
    "        bs_score = bootstrap(examples)\n",
    "        score = compute_mean_and_ci(bs_score)\n",
    "\n",
    "\n",
    "        row = {\n",
    "            \"Model\": mdl_name,\n",
    "            \"Domain\": domain,\n",
    "            \"Average F1\": score[\"Average F1\"][\"mean\"],\n",
    "            \"Person F1\": score[\"Person F1\"][\"mean\"],\n",
    "            \"Location F1\": score[\"Location F1\"][\"mean\"],\n",
    "            \"Organization F1\": score[\"Organization F1\"][\"mean\"],\n",
    "            \"Average F1 CI\": score[\"Average F1\"][\"ci\"],\n",
    "\n",
    "            \"Number of docs\": len(docs),\n",
    "            \n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# across domains\n",
    "for mdl in all_examples:\n",
    "    examples = all_examples[mdl]\n",
    "    bs_score = bootstrap(examples)\n",
    "    score = compute_mean_and_ci(bs_score)\n",
    "\n",
    "    row = {\n",
    "        \"Model\": mdl,\n",
    "        \"Domain\": \"All\",\n",
    "        \"Average F1\": score[\"Average F1\"][\"mean\"],\n",
    "        \"Person F1\": score[\"Person F1\"][\"mean\"],\n",
    "        \"Location F1\": score[\"Location F1\"][\"mean\"],\n",
    "        \"Organization F1\": score[\"Organization F1\"][\"mean\"],\n",
    "        \"Average F1 CI\": score[\"Average F1\"][\"ci\"],\n",
    "        \"Number of docs\": len(examples),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# write to file\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"ner_performance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bb89eb5dbe504baa9d5e43ed47eeb7f2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bb89eb5dbe504baa9d5e43ed47eeb7f2.vega-embed details,\n",
       "  #altair-viz-bb89eb5dbe504baa9d5e43ed47eeb7f2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bb89eb5dbe504baa9d5e43ed47eeb7f2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bb89eb5dbe504baa9d5e43ed47eeb7f2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bb89eb5dbe504baa9d5e43ed47eeb7f2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"errorbar\", \"ticks\": false}, \"encoding\": {\"color\": {\"field\": \"Domain\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_67\", \"value\": 1}, \"value\": 0.0}, \"x\": {\"field\": \"Average F1 CI Lower\", \"title\": \"F1\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"Average F1 CI Upper\"}, \"y\": {\"field\": \"Model\", \"type\": \"nominal\"}}, \"name\": \"view_45\"}, {\"mark\": {\"type\": \"point\", \"filled\": true}, \"encoding\": {\"color\": {\"field\": \"Domain\", \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_67\", \"value\": 1}, \"value\": 0.0}, \"size\": {\"condition\": {\"param\": \"param_68\", \"field\": \"Number of docs\"}, \"value\": 100}, \"tooltip\": [{\"field\": \"Model\", \"type\": \"nominal\"}, {\"field\": \"Domain\", \"type\": \"nominal\"}, {\"field\": \"Average F1\", \"type\": \"quantitative\"}, {\"field\": \"Person F1\", \"type\": \"quantitative\"}, {\"field\": \"Location F1\", \"type\": \"quantitative\"}, {\"field\": \"Organization F1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Average F1\", \"title\": \"F1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Model\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-435070586d81bd2a2ba1f9a98543d2da\"}, \"height\": 400, \"params\": [{\"name\": \"param_67\", \"select\": {\"type\": \"point\", \"fields\": [\"Domain\"]}, \"bind\": \"legend\", \"value\": [{\"Domain\": \"All\"}], \"views\": [\"view_45\"]}, {\"name\": \"param_68\", \"bind\": {\"input\": \"checkbox\", \"name\": \"Scale point size by number of documents: \"}}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-435070586d81bd2a2ba1f9a98543d2da\": [{\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"News\", \"Average F1\": 0.49975147729000396, \"Person F1\": 0.5018428893592202, \"Location F1\": 0.6375892681374983, \"Organization F1\": 0.29103867544887185, \"Average F1 CI\": [0.4374832098920412, 0.5611790367849443], \"Number of docs\": 421, \"Average F1 CI Lower\": 0.4374832098920412, \"Average F1 CI Upper\": 0.5611790367849443}, {\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"Conversation\", \"Average F1\": 0.502568801562263, \"Person F1\": 0.24999890599556104, \"Location F1\": 0.8047394682755802, \"Organization F1\": 0.3173999401003263, \"Average F1 CI\": [0.4667983972344437, 0.5376013133423645], \"Number of docs\": 1649, \"Average F1 CI Lower\": 0.4667983972344437, \"Average F1 CI Upper\": 0.5376013133423645}, {\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"Web\", \"Average F1\": 0.29251374337303127, \"Person F1\": 0.3550926849896739, \"Location F1\": 0.3900969171174406, \"Organization F1\": 0.1443801735368168, \"Average F1 CI\": [0.2758999249786238, 0.30863308179998883], \"Number of docs\": 8270, \"Average F1 CI Lower\": 0.2758999249786238, \"Average F1 CI Upper\": 0.30863308179998883}, {\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"Social Media\", \"Average F1\": 0.39001937588209823, \"Person F1\": 0.4508681438615541, \"Location F1\": 0.4632234073409536, \"Organization F1\": 0.17316949535676643, \"Average F1 CI\": [0.3252571769084408, 0.46131080757248977], \"Number of docs\": 554, \"Average F1 CI Lower\": 0.3252571769084408, \"Average F1 CI Upper\": 0.46131080757248977}, {\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"Wiki & Books\", \"Average F1\": 0.33077701463503895, \"Person F1\": 0.26317851797537417, \"Location F1\": 0.47731992899166914, \"Organization F1\": 0.1288789508628137, \"Average F1 CI\": [0.29426887809025587, 0.372542367977371], \"Number of docs\": 1709, \"Average F1 CI Lower\": 0.29426887809025587, \"Average F1 CI Upper\": 0.372542367977371}, {\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"Legal\", \"Average F1\": 0.4983002419145496, \"Person F1\": 0.5431325840925575, \"Location F1\": 0.5266443983629906, \"Organization F1\": 0.4673022856852745, \"Average F1 CI\": [0.46463403644090157, 0.5335796336815358], \"Number of docs\": 2163, \"Average F1 CI Lower\": 0.46463403644090157, \"Average F1 CI Upper\": 0.5335796336815358}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"News\", \"Average F1\": 0.610043311112828, \"Person F1\": 0.6869200400892693, \"Location F1\": 0.6381231699593978, \"Organization F1\": 0.4579545021454189, \"Average F1 CI\": [0.5478543569849414, 0.6772297427343298], \"Number of docs\": 421, \"Average F1 CI Lower\": 0.5478543569849414, \"Average F1 CI Upper\": 0.6772297427343298}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"Conversation\", \"Average F1\": 0.6111519713752657, \"Person F1\": 0.3509411575285554, \"Location F1\": 0.9023380889890414, \"Organization F1\": 0.5237249951633483, \"Average F1 CI\": [0.5667700264183048, 0.6546254159326678], \"Number of docs\": 1649, \"Average F1 CI Lower\": 0.5667700264183048, \"Average F1 CI Upper\": 0.6546254159326678}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"Web\", \"Average F1\": 0.4824765027176919, \"Person F1\": 0.6520457654085348, \"Location F1\": 0.5530083668685876, \"Organization F1\": 0.28271209355831034, \"Average F1 CI\": [0.4617923538515662, 0.5047390245758658], \"Number of docs\": 8270, \"Average F1 CI Lower\": 0.4617923538515662, \"Average F1 CI Upper\": 0.5047390245758658}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"Social Media\", \"Average F1\": 0.5705280045287929, \"Person F1\": 0.6506148661342762, \"Location F1\": 0.649685779259057, \"Organization F1\": 0.31468454468749646, \"Average F1 CI\": [0.5029371273359813, 0.6361298883380903], \"Number of docs\": 554, \"Average F1 CI Lower\": 0.5029371273359813, \"Average F1 CI Upper\": 0.6361298883380903}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"Wiki & Books\", \"Average F1\": 0.5134389421669578, \"Person F1\": 0.4449190945351011, \"Location F1\": 0.70212922773352, \"Organization F1\": 0.2489061006079142, \"Average F1 CI\": [0.47433592017738363, 0.5601155736731118], \"Number of docs\": 1709, \"Average F1 CI Lower\": 0.47433592017738363, \"Average F1 CI Upper\": 0.5601155736731118}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"Legal\", \"Average F1\": 0.5635126948663892, \"Person F1\": 0.7224540381175248, \"Location F1\": 0.7247258141788009, \"Organization F1\": 0.45007690131538847, \"Average F1 CI\": [0.5296146674500348, 0.5965882116193426], \"Number of docs\": 2163, \"Average F1 CI Lower\": 0.5296146674500348, \"Average F1 CI Upper\": 0.5965882116193426}, {\"Model\": \"spaCy (da_core_news_sm)\", \"Domain\": \"All\", \"Average F1\": 0.3405284341736741, \"Person F1\": 0.3601145998213218, \"Location F1\": 0.4594581522386654, \"Organization F1\": 0.2115883098319456, \"Average F1 CI\": [0.32522018123143337, 0.3520208817944178], \"Number of docs\": 15062, \"Average F1 CI Lower\": 0.32522018123143337, \"Average F1 CI Upper\": 0.3520208817944178}, {\"Model\": \"spaCy (da_core_news_lg)\", \"Domain\": \"All\", \"Average F1\": 0.5104815955339242, \"Person F1\": 0.5986342051549545, \"Location F1\": 0.6231570427000457, \"Organization F1\": 0.3296309447198448, \"Average F1 CI\": [0.4945044709229796, 0.525411354921913], \"Number of docs\": 15062, \"Average F1 CI Lower\": 0.4945044709229796, \"Average F1 CI Upper\": 0.525411354921913}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# filter out domains\n",
    "df = df[df[\"Domain\"] != \"danavis\"]\n",
    "df = df[df[\"Domain\"] != \"dannet\"]\n",
    "df = df[df[\"Domain\"].notnull()]\n",
    "\n",
    "df['Average F1 CI Lower'] = df['Average F1 CI'].apply(lambda x: x[0])\n",
    "df['Average F1 CI Upper'] = df['Average F1 CI'].apply(lambda x: x[1])\n",
    "df['Average F1 CI Lower'] = pd.to_numeric(df['Average F1 CI Lower'])\n",
    "df['Average F1 CI Upper'] = pd.to_numeric(df['Average F1 CI Upper'])\n",
    "\n",
    "\n",
    "\n",
    "selection = alt.selection_point(fields=['Domain'], bind='legend', value=[{'Domain': 'All'}]) # does not work\n",
    "\n",
    "bind_checkbox = alt.binding_checkbox(name='Scale point size by number of documents: ')\n",
    "param_checkbox = alt.param(bind=bind_checkbox)\n",
    "\n",
    "base = alt.Chart(df).mark_point(filled=True).encode(\n",
    "    # x='Average F1',\n",
    "    x=alt.X('Average F1', title=\"F1\"),\n",
    "    y='Model',\n",
    "    color='Domain',\n",
    "    size=alt.condition(\n",
    "        param_checkbox,\n",
    "        'Number of docs',\n",
    "        alt.value(100)\n",
    "    ),\n",
    "    tooltip=[\"Model\", \"Domain\", \"Average F1\", \"Person F1\", \"Location F1\", \"Organization F1\"],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.0))\n",
    ")\n",
    "error_bars = alt.Chart(df).mark_errorbar(ticks=False).encode(\n",
    "    # x='Average F1 CI Lower',\n",
    "    x = alt.X('Average F1 CI Lower', title=\"F1\"),\n",
    "    x2='Average F1 CI Upper',\n",
    "    y='Model',\n",
    "    color='Domain',\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.0))\n",
    ")\n",
    "\n",
    "chart = error_bars +base\n",
    "\n",
    "chart.add_params(selection, param_checkbox).properties(\n",
    "    width=800,\n",
    "    height=400\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The F1 in the figure denotes the mean bootstrapped F1 score with a 95% confidence interval. The F1 score is calculated on all of the DANSK dataset.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper [DaCy: A Unified Framework for Danish NLP](https://github.com/centre-for-humanities-computing/DaCy/blob/main/papers/DaCy-A-Unified-Framework-for-Danish-NLP/readme.md) we conduct a series on augmentation on the DaNE test set to estimate the robustness and biases of DaCy and other Danish language processing pipelines. This page represents only parts of the paper. We recommend reading the paper for a more thorough and nuanced overview.\n",
    "\n",
    "Let's start by examining a couple of the augmentations, namely changing out names or introducing plausible keystroke errors.\n",
    "\n",
    "````{admonition} Example\n",
    "\n",
    "```{note} Original\n",
    "\n",
    "Peter Schmeichel mener også, at det danske landshold anno 2021 tilhører verdenstoppen og kan vinde den kommende kamp mod England.\n",
    "```\n",
    "\n",
    "```{important} Female name augmentation\n",
    "\n",
    "Anne Østergaard mener også, at det danske landshold anno 2021 tilhører verdenstoppen og kan vinde den kommende kamp mod England.\n",
    "```\n",
    "````\n",
    "\n",
    "The underlying assumption of making these augmentations is that the tags of the tokens do not change with augmentation. In our case, this includes that \"Anna Østergaard\" is still a person and that \"vonde\" can still be considered a verb based on its context.\n",
    "\n",
    "Based on this, we can assume that if a model performs worse on a certain set of names or with minor spelling variations or errors, we can conclude that the model is vulnerable to such input. For instance, if the model has a hard time when replacing æ, ø, and å with ae, oe, and aa, it might not be ideal to apply to historic texts.\n",
    "\n",
    "As seen in the example above, while text with 5% keystroke is still readable. However, 15% keystroke errors tests the limit of what humans and models can reasonably be expected to comprehend.\n",
    "\n",
    "```{important}\n",
    "**15% keytype errors**\n",
    "\n",
    "Peter Schmeichel mejer ogsp, at ddt danske landshoof anbo 202q tilhårer gerfenatop0en of lan vinde sen kpmkendw lamp mod England.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The following tables show a detailed breakdown of performance for named entity recognition, part-of-speech tagging, and dependency parsing. These show some general trends, some of which include:\n",
    "\n",
    "- Spelling variations and abbreviated first names consistently reduce performance of all models on all tasks.\n",
    "- Even simple replacements of æ, ø, and å with ae, oe, and aa lead to notable performance degradation.\n",
    "- In general, larger models handle augmentations better than small models with DaCy large performing the best.\n",
    "- The BiLSTM-based models (Stanza and Flair) perform competitively under augmentations and are only consistently outperformed by DaCy large.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "```{bibliography}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
