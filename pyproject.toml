[project]
name = "dacy"
version = "2.2.2"
description = "A Danish pipeline trained in SpaCy that has achieved State-of-the-Art performance on all dependency parsing, NER and POS-tagging for Danish"

authors = [{name = "Kenneth Enevoldsen", email = "kennethcenevolsen@gmail.com"}, 
           {name = "Lasse Hansen"}]

classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Environment :: Console",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Operating System :: POSIX :: Linux",
    "Operating System :: MacOS :: MacOS X",
    "Operating System :: Microsoft :: Windows",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
]

keywords = [
    "nlp",
    "danish",
    "spacy-universe",
]

dependencies = [
    "spacy-wrap>=1.0.2,<1.1.0",
    "spacy>=3.2.0,<3.3.0",
    "pandas>=1.0.0,<2.0.0",
    "wasabi>=0.8.2,<0.11.0",
    "tqdm>=4.61.2,<4.62.0",
    "sentencepiece>=0.1.96,<0.2.0",
    "protobuf>=3.17.3,<3.18.0"
]

requires-python = ">=3.7"

[project.urls]
homepage = "https://centre-for-humanities-computing.github.io/DaCy/"
documentation = "https://centre-for-humanities-computing.github.io/DaCy/"
repository = "https://github.com/centre-for-humanities-computing/DaCy"

[project.license]
file = "LICENSE"
name = "Apache License 2.0"

[project.readme]
file = "README.md"
content-type = "text/markdown"

[project.optional-dependencies]
style = [
    "black>=22.3.0,<22.4.0",
    "ruff>=0.0.194,<0.0.195",
    "pre-commit>=2.19.0,<2.20.0",
]
tests = [
    "pytest>=7.1.2,<7.2.0",
    "pytest-cov>=3.0.0,<3.0.1",
]
docs = [
    "Sphinx>=4.5.0,<5.1.0",
    "furo>=2022.6.21,<2022.6.30",
    "sphinxext-opengraph>=0.6.3,<0.7.0",
    "sphinx-copybutton>=0.5.0,<0.6.0",
    "myst-parser>=0.18.0,<0.19.0",
    "ipykernel>=6.15.0,<6.16.0",
    "sphinx_design>=0.2.0,<0.3.0",
]
tutorials = [
    # to run notebooks
    "jupyter",
    # sentiment analysis
    "asent>=0.4.2,<0.7.0",
    "augmenty>=1.0.2,<1.1.0",
    # dacy robustness
    # the @ allows installing using a link
    "NERDA==1.0.0",
    # missing dependency for NERDA
    "scikit-learn",
]

[project.scripts]
emotion = "dacy.sentiment.wrapped_model:make_emotion_transformer"
hatespeech_classification = "dacy.hate_speech.wrapped_model:make_offensive_transformer"

[build-system]
requires = ["setuptools>=61.0.0", "wheel", "setuptools_scm"]
build-backend = "setuptools.build_meta"


[tool.setuptools.package-data]
"*" = ["*.csv"]

[tool.setuptools.packages.find]
where = ["src"]

[tool.coverage.run]
omit = [
    "**/tests/*",
    "**/about.py",
    "**/dev/*",
]

exclude_lines = [
    "pragma: no cover",
    # Don't complain about missing debug-only code:
    "def __unicode__",
    "def __repr__",
    "if self.debug",
    # Don't complain if tests don't hit defensive assertion code:
    "raise AssertionError",
    "raise NotImplementedError",
    # Don't complain if non-runnable code isn't run:
    "if 0:",
    "if __name__ == .__main__.:",
]

[tool.semantic_release]
branch = "main"
build_command = "python -m build"
version_variable = [
    "pyproject.toml:version"
]


[tool.ruff]
exclude = [".venv",
    ".env",
    ".git",
    "__pycache__",
    "dev/**",
    "training/v0.0.0/**",
    "training/v0.1.0/**",
    "training/v0.1.1/**",
    "papers/DaCy-A-Unified-Framework-for-Danish-NLP/**"
]
