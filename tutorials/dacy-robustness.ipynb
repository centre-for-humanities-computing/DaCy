{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Evaluating Robustness\n",
    "This tutorial walks through how to use `Augmenty`/`SpaCy` augmenters to evalutate robustness of any NLP pipeline. As an example we'll start out by evaluating SpaCy small and DaCy small on the test set of [DaNE](https://github.com/alexandrainst/danlp/blob/master/docs/docs/datasets.md#dane). DaNE is the Danish Dependency treebank tagged for part-of-speech tags, dependency relations and named entities. Lastly we will show how to use this framework on any other type of model using [DaNLP's BERT](https://github.com/alexandrainst/danlp/blob/master/docs/docs/tasks/ner.md#-bert-bert) as an example. \n",
    "\n",
    "Let us start of with installing the required packages and loading the models and dataset we wish to test on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing packages\n",
    "\n",
    "To get started we will first need to install a few packages:\n",
    "\n",
    "```bash\n",
    "# install models\n",
    "pip install dacy\n",
    "python -m spacy download da_core_news_sm\n",
    "\n",
    "# install augmentation library\n",
    "pip install \"augmenty>=1.0.2,<1.1.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'da_dacy_medium_trf' (0.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'da_dacy_small_trf' (0.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/spacy_transformers/pipeline_component.py:406: UserWarning: Automatically converting a transformer component from spacy-transformers v1.0 to v1.1+. If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spacy-transformers version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import dacy\n",
    "\n",
    "from dacy.datasets import dane\n",
    "\n",
    "# load the DaNE test set\n",
    "test = dane(splits=[\"test\"])\n",
    "\n",
    "# load models\n",
    "spacy_small = spacy.load(\"da_core_news_sm\")\n",
    "dacy_small = dacy.load(\"small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating performance\n",
    "Evaluating models already in the `SpaCy` framework is very straightforward. Simply call the `score` function on your nlp pipeline and choose which metrics you want to calculate performance for. `score` is a wrapper for `SpaCy.scorer.Scorer` that outputs a nicely formatted dataframe. `score` calculates performance for NER, POS, tokenization, and dependency parsing by default, which can be changed with the score_fn argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/spacy/pipeline/attributeruler.py:150: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n"
     ]
    }
   ],
   "source": [
    "from dacy.score import score\n",
    "\n",
    "spacy_baseline = score(test, apply_fn=spacy_small, score_fn=[\"ents\", \"pos\"])\n",
    "dacy_baseline = score(test, apply_fn=dacy_small, score_fn=[\"ents\", \"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type_MISC_p</th>\n",
       "      <th>ents_per_type_MISC_r</th>\n",
       "      <th>ents_per_type_MISC_f</th>\n",
       "      <th>ents_per_type_LOC_p</th>\n",
       "      <th>ents_per_type_LOC_r</th>\n",
       "      <th>ents_per_type_LOC_f</th>\n",
       "      <th>...</th>\n",
       "      <th>ents_per_type_ORG_f</th>\n",
       "      <th>ents_per_type_PER_p</th>\n",
       "      <th>ents_per_type_PER_r</th>\n",
       "      <th>ents_per_type_PER_f</th>\n",
       "      <th>ents_excl_MISC_ents_p</th>\n",
       "      <th>ents_excl_MISC_ents_r</th>\n",
       "      <th>ents_excl_MISC_ents_f</th>\n",
       "      <th>pos_acc</th>\n",
       "      <th>tag_acc</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.638683</td>\n",
       "      <td>0.720408</td>\n",
       "      <td>0.632616</td>\n",
       "      <td>0.673664</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.737913</td>\n",
       "      <td>0.663616</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.949103</td>\n",
       "      <td>0.949103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wall_time    ents_p    ents_r    ents_f  ents_per_type_MISC_p  \\\n",
       "0   1.638683  0.720408  0.632616  0.673664              0.649485   \n",
       "\n",
       "   ents_per_type_MISC_r  ents_per_type_MISC_f  ents_per_type_LOC_p  \\\n",
       "0              0.520661              0.577982             0.653846   \n",
       "\n",
       "   ents_per_type_LOC_r  ents_per_type_LOC_f  ...  ents_per_type_ORG_f  \\\n",
       "0             0.708333                 0.68  ...             0.551724   \n",
       "\n",
       "   ents_per_type_PER_p  ents_per_type_PER_r  ents_per_type_PER_f  \\\n",
       "0             0.793651             0.833333             0.813008   \n",
       "\n",
       "   ents_excl_MISC_ents_p  ents_excl_MISC_ents_r  ents_excl_MISC_ents_f  \\\n",
       "0               0.737913               0.663616               0.698795   \n",
       "\n",
       "    pos_acc   tag_acc  k  \n",
       "0  0.949103  0.949103  0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type_MISC_p</th>\n",
       "      <th>ents_per_type_MISC_r</th>\n",
       "      <th>ents_per_type_MISC_f</th>\n",
       "      <th>ents_per_type_LOC_p</th>\n",
       "      <th>ents_per_type_LOC_r</th>\n",
       "      <th>ents_per_type_LOC_f</th>\n",
       "      <th>...</th>\n",
       "      <th>ents_per_type_PER_f</th>\n",
       "      <th>ents_per_type_ORG_p</th>\n",
       "      <th>ents_per_type_ORG_r</th>\n",
       "      <th>ents_per_type_ORG_f</th>\n",
       "      <th>ents_excl_MISC_ents_p</th>\n",
       "      <th>ents_excl_MISC_ents_r</th>\n",
       "      <th>ents_excl_MISC_ents_f</th>\n",
       "      <th>pos_acc</th>\n",
       "      <th>tag_acc</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.794494</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.765186</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90027</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.98002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wall_time    ents_p    ents_r    ents_f  ents_per_type_MISC_p  \\\n",
       "0  12.794494  0.774312  0.756272  0.765186                 0.656   \n",
       "\n",
       "   ents_per_type_MISC_r  ents_per_type_MISC_f  ents_per_type_LOC_p  \\\n",
       "0              0.677686              0.666667             0.736364   \n",
       "\n",
       "   ents_per_type_LOC_r  ents_per_type_LOC_f  ...  ents_per_type_PER_f  \\\n",
       "0              0.84375             0.786408  ...              0.90027   \n",
       "\n",
       "   ents_per_type_ORG_p  ents_per_type_ORG_r  ents_per_type_ORG_f  \\\n",
       "0             0.773109             0.571429             0.657143   \n",
       "\n",
       "   ents_excl_MISC_ents_p  ents_excl_MISC_ents_r  ents_excl_MISC_ents_f  \\\n",
       "0               0.809524               0.778032               0.793466   \n",
       "\n",
       "   pos_acc  tag_acc  k  \n",
       "0  0.98002      0.0  0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dacy_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating robustness and biases\n",
    "To obtain performance estimates on augmented data, simply provide a list of augmenters as the `augmenters` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmenty.span.entities import create_per_replace_augmenter_v1\n",
    "from dacy.datasets import female_names\n",
    "from spacy.training.augment import create_lower_casing_augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/au561649/Desktop/Github/DaCy/.venv/lib/python3.9/site-packages/spacy/pipeline/attributeruler.py:150: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lower_aug = create_lower_casing_augmenter(level=1)\n",
    "female_name_dict = female_names()\n",
    "# Augmenter that replaces names with random Danish female names. Keep the format of the name as is (force_pattern_size=False)\n",
    "# but replace the name with one of the two defined patterns\n",
    "\n",
    "patterns = [[\"firstname\"], [\"firstname\", \"lastname\"], [\"firstname\", \"firstname\", \"lastname\"]]\n",
    "female_aug = create_per_replace_augmenter_v1(female_name_dict, patterns, level=0.1)\n",
    "\n",
    "spacy_aug = score(\n",
    "    test,\n",
    "    apply_fn=spacy_small,\n",
    "    score_fn=[\"ents\", \"pos\"],\n",
    "    augmenters=[lower_aug, female_aug],\n",
    ")\n",
    "dacy_aug = score(\n",
    "    test,\n",
    "    apply_fn=dacy_small,\n",
    "    score_fn=[\"ents\", \"pos\"],\n",
    "    augmenters=[lower_aug, female_aug],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type_MISC_p</th>\n",
       "      <th>ents_per_type_MISC_r</th>\n",
       "      <th>ents_per_type_MISC_f</th>\n",
       "      <th>ents_per_type_LOC_p</th>\n",
       "      <th>ents_per_type_LOC_r</th>\n",
       "      <th>ents_per_type_LOC_f</th>\n",
       "      <th>...</th>\n",
       "      <th>ents_per_type_ORG_f</th>\n",
       "      <th>ents_per_type_PER_p</th>\n",
       "      <th>ents_per_type_PER_r</th>\n",
       "      <th>ents_per_type_PER_f</th>\n",
       "      <th>ents_excl_MISC_ents_p</th>\n",
       "      <th>ents_excl_MISC_ents_r</th>\n",
       "      <th>ents_excl_MISC_ents_f</th>\n",
       "      <th>pos_acc</th>\n",
       "      <th>tag_acc</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.638683</td>\n",
       "      <td>0.720408</td>\n",
       "      <td>0.632616</td>\n",
       "      <td>0.673664</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.737913</td>\n",
       "      <td>0.663616</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.949103</td>\n",
       "      <td>0.949103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.679577</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.243728</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.380165</td>\n",
       "      <td>0.502732</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.340081</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.205950</td>\n",
       "      <td>0.311958</td>\n",
       "      <td>0.920288</td>\n",
       "      <td>0.920288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.375843</td>\n",
       "      <td>0.720408</td>\n",
       "      <td>0.632616</td>\n",
       "      <td>0.673664</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.737913</td>\n",
       "      <td>0.663616</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.949103</td>\n",
       "      <td>0.949103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wall_time    ents_p    ents_r    ents_f  ents_per_type_MISC_p  \\\n",
       "0   1.638683  0.720408  0.632616  0.673664              0.649485   \n",
       "0   1.679577  0.673267  0.243728  0.357895              0.741935   \n",
       "0   1.375843  0.720408  0.632616  0.673664              0.649485   \n",
       "\n",
       "   ents_per_type_MISC_r  ents_per_type_MISC_f  ents_per_type_LOC_p  \\\n",
       "0              0.520661              0.577982             0.653846   \n",
       "0              0.380165              0.502732             0.653846   \n",
       "0              0.520661              0.577982             0.653846   \n",
       "\n",
       "   ents_per_type_LOC_r  ents_per_type_LOC_f  ...  ents_per_type_ORG_f  \\\n",
       "0             0.708333             0.680000  ...             0.551724   \n",
       "0             0.354167             0.459459  ...             0.153846   \n",
       "0             0.708333             0.680000  ...             0.551724   \n",
       "\n",
       "   ents_per_type_PER_p  ents_per_type_PER_r  ents_per_type_PER_f  \\\n",
       "0             0.793651             0.833333             0.813008   \n",
       "0             0.626866             0.233333             0.340081   \n",
       "0             0.793651             0.833333             0.813008   \n",
       "\n",
       "   ents_excl_MISC_ents_p  ents_excl_MISC_ents_r  ents_excl_MISC_ents_f  \\\n",
       "0               0.737913               0.663616               0.698795   \n",
       "0               0.642857               0.205950               0.311958   \n",
       "0               0.737913               0.663616               0.698795   \n",
       "\n",
       "    pos_acc   tag_acc  k  \n",
       "0  0.949103  0.949103  0  \n",
       "0  0.920288  0.920288  0  \n",
       "0  0.949103  0.949103  0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat([spacy_baseline, spacy_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type_MISC_p</th>\n",
       "      <th>ents_per_type_MISC_r</th>\n",
       "      <th>ents_per_type_MISC_f</th>\n",
       "      <th>ents_per_type_LOC_p</th>\n",
       "      <th>ents_per_type_LOC_r</th>\n",
       "      <th>ents_per_type_LOC_f</th>\n",
       "      <th>...</th>\n",
       "      <th>ents_per_type_PER_f</th>\n",
       "      <th>ents_per_type_ORG_p</th>\n",
       "      <th>ents_per_type_ORG_r</th>\n",
       "      <th>ents_per_type_ORG_f</th>\n",
       "      <th>ents_excl_MISC_ents_p</th>\n",
       "      <th>ents_excl_MISC_ents_r</th>\n",
       "      <th>ents_excl_MISC_ents_f</th>\n",
       "      <th>pos_acc</th>\n",
       "      <th>tag_acc</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.794494</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.765186</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.980020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.063498</td>\n",
       "      <td>0.727088</td>\n",
       "      <td>0.639785</td>\n",
       "      <td>0.680648</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.645309</td>\n",
       "      <td>0.699752</td>\n",
       "      <td>0.974477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.604465</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.765186</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900270</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.980020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wall_time    ents_p    ents_r    ents_f  ents_per_type_MISC_p  \\\n",
       "0  12.794494  0.774312  0.756272  0.765186              0.656000   \n",
       "0  13.063498  0.727088  0.639785  0.680648              0.614754   \n",
       "0  12.604465  0.774312  0.756272  0.765186              0.656000   \n",
       "\n",
       "   ents_per_type_MISC_r  ents_per_type_MISC_f  ents_per_type_LOC_p  \\\n",
       "0              0.677686              0.666667             0.736364   \n",
       "0              0.619835              0.617284             0.714286   \n",
       "0              0.677686              0.666667             0.736364   \n",
       "\n",
       "   ents_per_type_LOC_r  ents_per_type_LOC_f  ...  ents_per_type_PER_f  \\\n",
       "0              0.84375             0.786408  ...             0.900270   \n",
       "0              0.78125             0.746269  ...             0.805797   \n",
       "0              0.84375             0.786408  ...             0.900270   \n",
       "\n",
       "   ents_per_type_ORG_p  ents_per_type_ORG_r  ents_per_type_ORG_f  \\\n",
       "0             0.773109             0.571429             0.657143   \n",
       "0             0.686869             0.422360             0.523077   \n",
       "0             0.773109             0.571429             0.657143   \n",
       "\n",
       "   ents_excl_MISC_ents_p  ents_excl_MISC_ents_r  ents_excl_MISC_ents_f  \\\n",
       "0               0.809524               0.778032               0.793466   \n",
       "0               0.764228               0.645309               0.699752   \n",
       "0               0.809524               0.778032               0.793466   \n",
       "\n",
       "    pos_acc  tag_acc  k  \n",
       "0  0.980020      0.0  0  \n",
       "0  0.974477      0.0  0  \n",
       "0  0.980020      0.0  0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dacy_baseline, dacy_aug])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second row, we see that `SpaCy small` is very vulnerable to lower casing as NER recall drops from 0.66 to 0.38. `DaCy small` is slightly more robust lower casing, but still suffers. Changing names also leads to a drop in performance for both models. \n",
    "\n",
    "To better estimate the effect of stochastic augmenters such as those changing names or adding keystroke errors we can use the `k` argument in `score` to run the augmenter multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmenty.character.replace import create_keystroke_error_augmenter_v1\n",
    "\n",
    "key_05_aug = create_keystroke_error_augmenter_v1(level=0.5, keyboard=\"da_qwerty.v1\")\n",
    "\n",
    "spacy_key = score(\n",
    "    test, apply_fn=spacy_small, score_fn=[\"ents\", \"pos\"], augmenters=[key_05_aug], k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type_MISC_p</th>\n",
       "      <th>ents_per_type_MISC_r</th>\n",
       "      <th>ents_per_type_MISC_f</th>\n",
       "      <th>ents_per_type_LOC_p</th>\n",
       "      <th>ents_per_type_LOC_r</th>\n",
       "      <th>ents_per_type_LOC_f</th>\n",
       "      <th>...</th>\n",
       "      <th>ents_per_type_ORG_f</th>\n",
       "      <th>ents_per_type_PER_p</th>\n",
       "      <th>ents_per_type_PER_r</th>\n",
       "      <th>ents_per_type_PER_f</th>\n",
       "      <th>ents_excl_MISC_ents_p</th>\n",
       "      <th>ents_excl_MISC_ents_r</th>\n",
       "      <th>ents_excl_MISC_ents_f</th>\n",
       "      <th>pos_acc</th>\n",
       "      <th>tag_acc</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.706608</td>\n",
       "      <td>0.110333</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.111603</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089655</td>\n",
       "      <td>0.162679</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.174807</td>\n",
       "      <td>0.130045</td>\n",
       "      <td>0.132723</td>\n",
       "      <td>0.131370</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.668705</td>\n",
       "      <td>0.118068</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.118174</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.135417</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.160221</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.160665</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.128146</td>\n",
       "      <td>0.128588</td>\n",
       "      <td>0.329741</td>\n",
       "      <td>0.329741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.472808</td>\n",
       "      <td>0.086342</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.092050</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.106280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>0.122549</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.112128</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>0.326347</td>\n",
       "      <td>0.326347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.064881</td>\n",
       "      <td>0.119816</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.146018</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.162562</td>\n",
       "      <td>0.137450</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.146965</td>\n",
       "      <td>0.336281</td>\n",
       "      <td>0.336281</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.583604</td>\n",
       "      <td>0.116239</td>\n",
       "      <td>0.121864</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.054475</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100334</td>\n",
       "      <td>0.179612</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.191710</td>\n",
       "      <td>0.135857</td>\n",
       "      <td>0.139588</td>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.330561</td>\n",
       "      <td>0.330561</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wall_time    ents_p    ents_r    ents_f  ents_per_type_MISC_p  \\\n",
       "0   4.706608  0.110333  0.112903  0.111603              0.040000   \n",
       "1   3.668705  0.118068  0.118280  0.118174              0.080000   \n",
       "2   4.472808  0.086342  0.098566  0.092050              0.038217   \n",
       "3   5.064881  0.119816  0.139785  0.129032              0.060403   \n",
       "4   4.583604  0.116239  0.121864  0.118985              0.051471   \n",
       "\n",
       "   ents_per_type_MISC_r  ents_per_type_MISC_f  ents_per_type_LOC_p  \\\n",
       "0              0.041322              0.040650             0.101852   \n",
       "1              0.082645              0.081301             0.127451   \n",
       "2              0.049587              0.043165             0.099099   \n",
       "3              0.074380              0.066667             0.165289   \n",
       "4              0.057851              0.054475             0.085714   \n",
       "\n",
       "   ents_per_type_LOC_r  ents_per_type_LOC_f  ...  ents_per_type_ORG_f  \\\n",
       "0             0.114583             0.107843  ...             0.089655   \n",
       "1             0.135417             0.131313  ...             0.089744   \n",
       "2             0.114583             0.106280  ...             0.079755   \n",
       "3             0.208333             0.184332  ...             0.101266   \n",
       "4             0.093750             0.089552  ...             0.100334   \n",
       "\n",
       "   ents_per_type_PER_p  ents_per_type_PER_r  ents_per_type_PER_f  \\\n",
       "0             0.162679             0.188889             0.174807   \n",
       "1             0.160221             0.161111             0.160665   \n",
       "2             0.122549             0.138889             0.130208   \n",
       "3             0.146018             0.183333             0.162562   \n",
       "4             0.179612             0.205556             0.191710   \n",
       "\n",
       "   ents_excl_MISC_ents_p  ents_excl_MISC_ents_r  ents_excl_MISC_ents_f  \\\n",
       "0               0.130045               0.132723               0.131370   \n",
       "1               0.129032               0.128146               0.128588   \n",
       "2               0.102083               0.112128               0.106870   \n",
       "3               0.137450               0.157895               0.146965   \n",
       "4               0.135857               0.139588               0.137698   \n",
       "\n",
       "    pos_acc   tag_acc  k  \n",
       "0  0.331013  0.331013  0  \n",
       "1  0.329741  0.329741  1  \n",
       "2  0.326347  0.326347  2  \n",
       "3  0.336281  0.336281  3  \n",
       "4  0.330561  0.330561  4  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this manner, evaluating performance on augmented data for SpaCy pipelines is as easy as defining the augmenters and calling a single function. In the `dacy_paper_replication.py` script you can find the exact script used to evaluate the robustness of Danish NLP models in the [DaCy paper]().\n",
    "\n",
    "# Evaluating custom models\n",
    "Evaluating models not in the `SpaCy` framework requires the user to write an `apply_fn` that takes a series of SpaCy `Example`s as input, and applies their model to it and returns list of examples `Example`. \n",
    "\n",
    "The following shows how to write one for the NERDA model for named entity recognition. Notice that we replace the tokenizer with the spaCy tokenizer (where they use the NLTK) it turns out that this provides a better performance.\n",
    "\n",
    "We will start out by installing the package and downloading the model. Then we will define an apply function which converts the models tags to spacy annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install NERDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device automatically set to: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Model loaded. Please make sure, that you're running the latest version \n",
      "        of 'NERDA' otherwise the model is not guaranteed to work.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from NERDA.precooked import DA_BERT_ML\n",
    "import ssl\n",
    "\n",
    "model = DA_BERT_ML()\n",
    "# to download the danlp and nerda you will have to set up a certificate:\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "model.download_network()\n",
    "model.load_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List\n",
    "from spacy.tokens import Doc, Span\n",
    "from spacy.training import Example\n",
    "\n",
    "# set up a danish tokenization pipeline\n",
    "nlp_da = spacy.blank(\"da\")\n",
    "\n",
    "\n",
    "def add_iob(doc: Doc, iob: List[str]) -> Doc:\n",
    "    \"\"\"A helper function for adding iob tags to Doc\n",
    "\n",
    "    Args:\n",
    "        doc (Doc): A SpaCy doc\n",
    "        iob (List[str]): a list of tokens on the IOB format\n",
    "\n",
    "    Returns:\n",
    "        Doc: A doc with the spans to the new IOB\n",
    "    \"\"\"\n",
    "    ent = []\n",
    "    for i, label in enumerate(iob):\n",
    "\n",
    "        # turn OOB labels into spans\n",
    "        if label == \"O\":\n",
    "            continue\n",
    "        iob_, ent_type = label.split(\"-\")\n",
    "        if (i - 1 >= 0 and iob_ == \"I\" and iob[i - 1] == \"O\") or (\n",
    "            i == 0 and iob_ == \"I\"\n",
    "        ):\n",
    "            iob_ = \"B\"\n",
    "        if iob_ == \"B\":\n",
    "            start = i\n",
    "        if i + 1 >= len(iob) or iob[i + 1].split(\"-\")[0] != \"I\":\n",
    "            ent.append(Span(doc, start, i + 1, label=ent_type))\n",
    "    doc.set_ents(ent)\n",
    "    return doc\n",
    "\n",
    "\n",
    "def apply_nerda(examples: Iterable[Example]) -> List[Example]:\n",
    "    sentences = []\n",
    "    docs_y = []\n",
    "    for example in examples:\n",
    "        # tokenization\n",
    "        # they use NLTK for their tokenization,\n",
    "        # but turns out that the spacy tokenizer provides better results\n",
    "        sentences.append([t.text for t in nlp_da(example.reference.text)])\n",
    "        docs_y.append(example.reference)\n",
    "\n",
    "    # ner\n",
    "    labels = model.predict(sentences=sentences)\n",
    "\n",
    "    examples_ = []\n",
    "    for doc_y, label, words in zip(docs_y, labels, sentences):\n",
    "        if len(label) < len(words):\n",
    "            label += [\"O\"] * (len(words) - len(label))\n",
    "\n",
    "        doc = Doc(nlp_da.vocab, words=words)\n",
    "        doc = add_iob(doc, iob=label)\n",
    "        examples_.append(Example(doc, doc_y))\n",
    "    return examples_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "nerda = score(test, apply_fn=apply_nerda, score_fn=[\"ents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_time</th>\n",
       "      <th>ents_p</th>\n",
       "      <th>ents_r</th>\n",
       "      <th>ents_f</th>\n",
       "      <th>ents_per_type_LOC_p</th>\n",
       "      <th>ents_per_type_LOC_r</th>\n",
       "      <th>ents_per_type_LOC_f</th>\n",
       "      <th>ents_per_type_MISC_p</th>\n",
       "      <th>ents_per_type_MISC_r</th>\n",
       "      <th>ents_per_type_MISC_f</th>\n",
       "      <th>ents_per_type_PER_p</th>\n",
       "      <th>ents_per_type_PER_r</th>\n",
       "      <th>ents_per_type_PER_f</th>\n",
       "      <th>ents_per_type_ORG_p</th>\n",
       "      <th>ents_per_type_ORG_r</th>\n",
       "      <th>ents_per_type_ORG_f</th>\n",
       "      <th>ents_excl_MISC_ents_p</th>\n",
       "      <th>ents_excl_MISC_ents_r</th>\n",
       "      <th>ents_excl_MISC_ents_f</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195.918393</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.790353</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.694215</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.923513</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.57764</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.836186</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wall_time    ents_p    ents_r    ents_f  ents_per_type_LOC_p  \\\n",
       "0  195.918393  0.819231  0.763441  0.790353             0.747826   \n",
       "\n",
       "   ents_per_type_LOC_r  ents_per_type_LOC_f  ents_per_type_MISC_p  \\\n",
       "0             0.895833             0.815166              0.756757   \n",
       "\n",
       "   ents_per_type_MISC_r  ents_per_type_MISC_f  ents_per_type_PER_p  \\\n",
       "0              0.694215              0.724138             0.942197   \n",
       "\n",
       "   ents_per_type_PER_r  ents_per_type_PER_f  ents_per_type_ORG_p  \\\n",
       "0             0.905556             0.923513             0.768595   \n",
       "\n",
       "   ents_per_type_ORG_r  ents_per_type_ORG_f  ents_excl_MISC_ents_p  \\\n",
       "0              0.57764             0.659574               0.836186   \n",
       "\n",
       "   ents_excl_MISC_ents_r  ents_excl_MISC_ents_f  k  \n",
       "0               0.782609               0.808511  0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are in doubt how to create an apply function for your model you can find more inspiration in [`papers/DaCy../apply_fns`](https://github.com/centre-for-humanities-computing/DaCy/tree/main/papers/DaCy-A-Unified-Framework-for-Danish-NLP/apply_fns). This folder contains apply functions for DaNLP's BERT, Flair, NERDA, and Polyglot. Otherwise, feel free to open an issue on the GitHub. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41a0a94681c1d0d7a5ae694864ee715c089937d98d908faa5b8f75504686895e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
