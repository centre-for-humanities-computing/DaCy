{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping a fine-tuned Transformer\n",
    "\n",
    "---\n",
    "This tutorial will briefly take you through how to wrap an already trained transformer for text classification in a SpaCy pipeline. For this example we will use DaNLP's BertTone as an example. However, do note that this approach also works using models directly from Huggingface's model hub.\n",
    "\n",
    "Before we start let us make sure everything is installed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping a Huggingface model\n",
    "---\n",
    "Wrapping a Huggingface model can be done in a single line of code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 971/971 [00:00<00:00, 210kB/s]\n",
      "Downloading: 100%|██████████| 253k/253k [00:00<00:00, 1.19MB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 52.9kB/s]\n",
      "Downloading: 100%|██████████| 316/316 [00:00<00:00, 137kB/s]\n",
      "Downloading: 100%|██████████| 443M/443M [00:18<00:00, 24.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import dacy\n",
    "\n",
    "from dacy.subclasses import add_huggingface_model\n",
    "\n",
    "nlp = spacy.blank(\"da\")  # replace with your desired pipeline\n",
    "nlp = add_huggingface_model(nlp, \n",
    "                      download_name=\"pin/senda\", # the model name on the huggingface hub\n",
    "                      doc_extension=\"senda_trf_data\", # the doc extention for transformer data e.g. including wordpieces\n",
    "                      model_name=\"senda\",  # the name of the model in the pipeline\n",
    "                      category=\"polarity\", # the category type it predicts\n",
    "                      labels=[\"negative\", \"neutral\", \"positive\"], # possible outcome labels\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step\n",
    "---\n",
    "However, one might want to look a bit more into it so let is go through step by step. First of all let us start with the setup. We will here use a downloaded Huggingface transformer from DaNLP.\n",
    "\n",
    "### Setup\n",
    "Let's start off by downloading the model and be sure that it can be loaded in using Huggingface transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bert.polarity exists in /Users/au554730/.danlp/bert.polarity\n"
     ]
    }
   ],
   "source": [
    "from danlp.download import download_model as danlp_download\n",
    "from danlp.download import _unzip_process_func\n",
    "from danlp.download import DEFAULT_CACHE_DIR as DANLP_DIR\n",
    "from transformers import AutoModelForSequenceClassification, BertTokenizer\n",
    "\n",
    "# downloading model and setting a path to its location\n",
    "path_sub = danlp_download(\n",
    "    \"bert.polarity\", DANLP_DIR, process_func=_unzip_process_func, verbose=True\n",
    ")\n",
    "path_sub = os.path.join(path_sub, \"bert.pol.v0.0.1\")\n",
    "\n",
    "# loading it in with transformers\n",
    "berttone = AutoModelForSequenceClassification.from_pretrained(path_sub, num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming this works you are ready to move on. However if you were to do this on your own model I would also test that the forward pass works as intended.\n",
    "\n",
    "## Wrapping the Model\n",
    "\n",
    "---\n",
    "\n",
    "Now we will start wrapping the model. DaCy provides good utility functions for doing precisely this without making more changes than necessary to the transformer class from SpaCy. This should allow you to use the extensive documentation by SpaCy while working with this code.\n",
    "\n",
    "This utilizes SpaCy's config system, which might take a bit of getting used to initially, but it is quite worth the effort. For now I will walk you through it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacy.subclasses import ClassificationTransformer, install_classification_extensions\n",
    "\n",
    "labels=[\"positive\", \"neutral\", \"negative\"]\n",
    "doc_extension = \"berttone_pol_trf_data\"\n",
    "category = \"polarity\"\n",
    "\n",
    "config = {\n",
    "    \"doc_extension_attribute\": doc_extension,\n",
    "    \"model\": {\n",
    "        \"@architectures\": \"dacy.ClassificationTransformerModel.v1\",\n",
    "        \"name\": path_sub,\n",
    "        \"num_labels\": len(labels),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# add the relevant extentsion to the doc\n",
    "install_classification_extensions(\n",
    "    category=category, labels=labels, doc_extension=doc_extension, force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file is an extension of the `Transformers` config in SpaCy, but you will note a few changes:\n",
    "\n",
    "1) `doc_extension_attribute`: This is to make sure that the doc extension can be customized. The doc extension is how you fetch data relevant to your model. The SpaCy transformer uses the `trf_data`, but we don't want to overwrite this in case we are using multiple transformers.\n",
    "2) `num_labels`: The number of labels. This is an argument passed forward when loading the model. Without this, the Huggingface transformers package will raise an error (at least for cases where `num_labels` isn't 2)\n",
    "\n",
    "`name` simply specifies the name of the model. You could potentially change this out for any sequence classification model on Huggingfaces model hub. Lastly the `install_classification_extensions` adds the getter function for the model. Here it would for instance add `doc._.polarity` for extracting the label of the model as well as a `doc._.polarity_prop` for extracting the polarity probabilities for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding it to the NLP pipeline\n",
    "---\n",
    "\n",
    "Now it can simply be added it to the pipeline using `add_pipe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x7fa076a86f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"da\") # dummy nlp\n",
    "\n",
    "clf_transformer = nlp.add_pipe(\n",
    "    \"classification_transformer\", name=\"berttone\", config=config\n",
    ")\n",
    "clf_transformer.model.initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test\n",
    "\n",
    "--- \n",
    "\n",
    "We can then finish off with a final test to see if everything works as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "{'prop': array([0.002, 0.008, 0.99 ], dtype=float32), 'labels': ['positive', 'neutral', 'negative']}\n",
      "positive\n",
      "{'prop': array([0.854, 0.146, 0.001], dtype=float32), 'labels': ['positive', 'neutral', 'negative']}\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Analysen viser, at økonomien bliver forfærdelig dårlig\", \n",
    "         \"Jeg tror alligvel, det bliver godt\"]\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc._.polarity)\n",
    "    print(doc._.polarity_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerData(wordpieces=WordpieceBatch(strings=[['[CLS]', 'jeg', 'tror', 'alli', '##g', '##vel', ',', 'det', 'bliver', 'godt', '[SEP]']], input_ids=array([[    2,   102,  1421,  9682, 31704,  1041,   883,    49,   352,\n",
       "          380,     3]]), attention_mask=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), lengths=[11], token_type_ids=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])), tensors=[array([[ 3.3191876,  1.5510517, -4.0984917]], dtype=float32)], align=Ragged(data=array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]], dtype=int32), lengths=array([1, 1, 3, 1, 1, 1, 1], dtype=int32), data_shape=(-1,), cumsums=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also examine the wordpieces used (and see the entire TransformersData)\n",
    "\n",
    "doc._.berttone_pol_trf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69f6eb96a37a43867553731f8edb0a55a5852b5c9c304e04d7bd7872e5b1c11d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('dacy': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}